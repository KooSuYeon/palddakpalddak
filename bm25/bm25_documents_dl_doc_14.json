[
    {
        "id": null,
        "metadata": {},
        "page_content": "[스파르타코딩클럽] 14. 과적합 방지 기법📘[SCC] 기초가 탄탄한 딥러닝/📚[스파르타코딩클럽] 기초가 탄탄한 딥러닝 - 6주차/📕[스파르타코딩클럽] 14. 과적합 방지 기법Made with📕[스파르타코딩클럽] 14. 과적합 방지 기법[수업 목표]여러 과적합 방지 기법에 대해서 알아봅시다.Pytorch로  과적합 방지 기법에 대한 실습 예시![목차]01.",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "대한 실습 예시![목차]01. 과적화 방지 기법02. 과적합 방지기법 실습(Pytorch)import torch.nn as nn",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "import torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\n​☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 ﻿​PythonCopy# 데이터셋 전처리\ntransform = transforms.Compose([",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n# CIFAR-10 데이터셋 로드",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "# CIFAR-10 데이터셋 로드\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​☑️  드롭아웃과 배치 정규화를 적용한 모델 정의 드롭아웃과 배치 정규화를 적용한 모델 정의 {5px} 드롭아웃과 배치 정규화를 적용한 모델 정의 ﻿​PythonCopyclass CNNWithDropoutAndBatchNorm(nn.Module):\ndef __init__(self):",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "def __init__(self):\nsuper(CNNWithDropoutAndBatchNorm, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(128 * 56 * 56, 256)\n        self.dropout = nn.Dropout(0.5)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "self.fc2 = nn.Linear(256, 10)\ndef forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = torch.max_pool2d(x, 2)\n        x = torch.relu(self.bn2(self.conv2(x)))",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "x = torch.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\nreturn x",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "model = CNNWithDropoutAndBatchNorm()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​nn.Conv2d: 2차원 합성곱 층을 정의합니다. nn.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널 크기, 패딩을 지정.Conv2d(in_channels, out_channels, kernel_size, padding)은 입력 채널 수, 출력 채널 수, 커널",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "채널 수, 출력 채널 수, 커널 크기, 패딩을 지정﻿​nn.BatchNorm2d: 2차원 배치 정규화 층을 정의합니다.nn.Dropout: 드롭아웃 층을 정의합니다. nn.Dropout(p)은 드롭아웃 확률을 지정합니다..Dropout(p)은 드롭아웃 확률을 지정합니다.﻿​torch.max_pool2d: 2차원 최대 풀링을 수행합니다.☑️ 손실 함수와",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "풀링을 수행합니다.☑️ 손실 함수와 최적화 알고리즘 정의손실 함수와 최적화 알고리즘 정의 {5px}손실 함수와 최적화 알고리즘 정의 ﻿​PythonCopycriterion = nn.CrossEntropyLoss()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "optimizer = optim.Adam(model.parameters(), lr=0.001)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​nn.CrossEntropyLoss: 교차 엔트로피 손실 함수를 정의합니다.optim.Adam: Adam 최적화 알고리즘을 정의합니다. lr은 학습률을 지정합니다.은 학습률을 지정합니다.﻿​☑️ 모델 학습모델 학습 {5px}모델 학습 ﻿​PythonCopynum_epochs = 10",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "for i, (inputs, labels) in enumerate(trainloader):\n        inputs, labels = inputs.to(device), labels.to(device)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "running_loss += loss.item()\nif i % 100 == 99: # 매 100 미니배치마다 출력\nprint(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n            running_loss = 0.0",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "print('Finished Training')",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​model.train(): 모델을 학습 모드로 전환합니다.optimizer.zero_grad(): 이전 단계에서 계산된 기울기를 초기화합니다.loss.backward(): 역전파를 통해 기울기를 계산합니다.optimizer.step(): 계산된 기울기를 바탕으로 가중치를 업데이트합니다.☑️ 모델 평가모델 평가 {5px}모델 평가",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "평가모델 평가 {5px}모델 평가 ﻿​PythonCopymodel.eval()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "correct = 0\ntotal = 0\nwith torch.no_grad():\nfor inputs, labels in testloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "_, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​model.eval(): 모델을 평가 모드로 전환합니다.torch.no_grad(): 평가 단계에서는 기울기를 계산할 필요가 없으므로, 이를 비활성화하여 메모리 사용을 줄입니다.torch.max: 텐서의 최대 값을 찾습니다. torch.max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "가장 높은 확률을 가진 클래스를 반환합니다..max(outputs.data, 1)은 각 샘플에 대해 가장 높은 확률을 가진 클래스를 반환합니다.﻿​labels.size(0): 배치 크기를 반환합니다.(predicted == labels).sum().item(): 예측 값과 실제 값이 일치하는 샘플의 수를 계산합니다.2)  데이터 증강을 통한 모델 성능",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "데이터 증강을 통한 모델 성능 향상 실습☑️데이터셋 로드 및 전처리데이터셋 로드 및 전처리 {5px}데이터셋 로드 및 전처리 ﻿​PythonCopy# 데이터 증강 적용",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "transform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomCrop(32, padding=4),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "transform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n# CIFAR-10 데이터셋 로드",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "# CIFAR-10 데이터셋 로드\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "​transforms.RandomHorizontalFlip(): 이미지를 무작위로 수평 반전합니다.transforms.RandomCrop(size, padding): 이미지를 무작위로 자르고, 패딩을 추가합니다.☑️  드롭아웃과 배치 정규화를 적용한 모델 정의첫번째 실습에서 정의한 모델을 그대로 사용합니다. 드롭아웃과 배치 정규화를 적용한 모델 정의",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "배치 정규화를 적용한 모델 정의 {5px} 드롭아웃과 배치 정규화를 적용한 모델 정의 ﻿​PythonCopyclass CNNWithDropoutAndBatchNorm(nn.Module):",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "def __init__(self):\nsuper(CNNWithDropoutAndBatchNorm, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(64)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(128)\n        self.fc1 = nn.Linear(128 * 56 * 56, 256)\n        self.dropout = nn.Dropout(0.5)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "self.fc2 = nn.Linear(256, 10)\ndef forward(self, x):\n        x = torch.relu(self.bn1(self.conv1(x)))\n        x = torch.max_pool2d(x, 2)\n        x = torch.relu(self.bn2(self.conv2(x)))",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "x = torch.max_pool2d(x, 2)\n        x = x.view(x.size(0), -1)\n        x = torch.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\nreturn x",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "model = CNNWithDropoutAndBatchNorm()\n​☑️ 손실 함수와 최적화 알고리즘 정의첫번째 실습에서 정의한 손실함수와 최적화 알고리즘을 그대로 사용합니다.손실 함수와 최적화 알고리즘 정의 {5px}손실 함수와 최적화 알고리즘 정의 ﻿​PythonCopycriterion = nn.CrossEntropyLoss()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "optimizer = optim.Adam(model.parameters(), lr=0.001)\n​☑️ 모델 학습첫번째 실습에서 정의한 모델 학습 코드를 그대로 사용합니다.모델 학습 {5px}모델 학습 ﻿​PythonCopynum_epochs = 10",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(device)\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "for i, (inputs, labels) in enumerate(trainloader):\n        inputs, labels = inputs.to(device), labels.to(device)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "running_loss += loss.item()\nif i % 100 == 99: # 매 100 미니배치마다 출력\nprint(f'[Epoch {epoch + 1}, Batch {i + 1}] loss: {running_loss / 100:.3f}')\n            running_loss = 0.0",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "print('Finished Training')\n​☑️ 모델 평가첫번째 실습에서 정의한 모델 평가 코드를 그대로 사용합니다.모델 평가 {5px}모델 평가 ﻿​PythonCopymodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\nfor inputs, labels in testloader:",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)",
        "type": "Document"
    },
    {
        "id": null,
        "metadata": {},
        "page_content": "correct += (predicted == labels).sum().item()\nprint(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n​Copyright ⓒ TeamSparta All rights reserved.",
        "type": "Document"
    }
]