URL 1 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 1주차 llm이란 강의소개 제작 llm이란 강의소개 수업 목표 llm이 무엇인지 그 동작 원리에 대해 알아봅니다 llm을 실무 프로젝트에서 어떻게 활용할 수 있는지 배웁니다 rag vector db langchain 등 최신 기술을 이해하고 이를 활용한 프로젝트를 진행하는 방법을 학습합니다 목차 강좌 소개 llm이란 llm 동작 원리 llm의 랜덤성과 조건성 왜 llm의 원리를 알아야 할까 llm의 원리 요약 추가적으로 알아두면 좋은 것 정리 강좌 소개 이번 강좌에서는 대형 언어 모델llm large language model이 무엇인지 그리고 그 동작 원리가 어떻게 되는지를 간단하게 배웁니다 이를 통해 llm을 활용한 다양한 프로젝트에서 효과적으로 활용할 수 있는 기초 개념을 다질 거예요 기대 효과 llm의 기본 개념을 이해하고 설명할 수 있다 llm의 동작 방식을 알고 관련된 기술적 요소들을 학습할 준비가 된다 rag vector db langchain 같은 최신 기술 트렌드에 대한 이해도를 높인다 최신 기술을 활용한 자신만의 chat service를 만들 수 있다 대상 수강생 최신 ai에 관심 있는 사람들 llm을 프로젝트에 도입하고 싶은 사람 언어형 모델의 실제 동작 원리가 궁금한 분들 rag langchain과 같은 최신 기술을 배우고 싶은 분들 llm이란 llm llmlarge language model은 대규모 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 ai 모델입니다 기본적으로 자연어 처리nlp의 다양한 작업 예를 들면 번역 질문 응답 텍스트 생성 등을 할 수 있습니다 간단한 정의 대형 언어 모델llm은 수십억 개의 파라미터를 기반으로 한 인공지능입니다 이를 통해 마치 사람처럼 문맥을 파악하고 자연스럽게 대답할 수 있는 능력을 갖췄습니다 llm 동작 원리 llm의 동작은 크게 세 가지 단계로 나뉩니다 1 학습training llm은 대규모 텍스트 데이터셋을 이용해 학습합니다 여기서 중요한 개념은 패턴 인식이에요 수많은 텍스트에서 단어와 문장의 패턴을 찾아내어 새로운 문장이나 답변을 생성할 때 그 패턴을 적용하죠 2 추론inference 학습된 llm은 질문이나 입력을 받으면 그에 맞는 추론을 통해 답변을 생성합니다 이때 이전의 맥락을 기억하고 활용하면서 답을 만들어내죠 3 미세 조정finetuning llm은 특정 도메인이나 용도에 맞춰 추가 학습미세 조정할 수 있습니다 예를 들어 의료나 법률과 같은 특수한 분야에 맞는 데이터를 추가로 학습시키면 해당 분야에 대한 답변의 정확성이 높아집니다 llm을 개인이 바닥부터 만들기란 llm의 랜덤성과 조건성 llm이 문장을 생성할 때는 랜덤성randomness과 조건성conditioning이 중요한 역할을 합니다 1 랜덤성 randomness llm은 기본적으로 확률에 기반하여 문장을 생성합니다 즉 같은 질문을 하더라도 매번 동일한 답변을 주지 않을 수 있어요 이 랜덤성은 모델이 새로운 문장을 만들어내는 능력을 키워주는 핵심 요소입니다 llm이 결과를 생성할 때 토큰의 확률 분포를 계산하여 그 중에서 높은 확률을 가진 토큰을 선택해 문장을 만듭니다 이때 온도temperature라는 매개변수가 랜덤성에 영향을 미치는데 온도 값이 낮으면 모델은 더 일관되고 예측 가능한 답변을 생성합니다 더 적은 랜덤성 온도 값이 높으면 답변이 창의적이고 예측하기 어려운 결과가 나올 수 있습니다 더 많은 랜덤성 예시 질문 오늘 날씨는 어때 온도 낮음 오늘 날씨는 맑습니다 온도 높음 오늘은 하늘이 쾌청하고 약간의 바람이 불어요 2 조건성 conditioning llm은 조건부 확률을 기반으로 결과를 만들어 냅니다 즉 모델은 이전의 입력 내용에 따라 문장을 조건부로 생성하게 되는데 이를 컨텍스트라고도 합니다 이 과정에서 중요한 두 가지 요소는 다음과 같습니다 프롬프트 입력된 문장이나 질문이 무엇인지에 따라 결과가 달라집니다 맥락 기억 llm은 대화를 나누는 동안 이전 문장이나 대화 흐름을 기억하고 그에 맞춰 답변을 생성합니다 예시 프롬프트에 따른 차이 고양이에 대해 말해줘 고양이는 애완동물로서 인기가 많습니다고양이의 장점에 대해 말해줘 고양이는 혼자서도 잘 지내는 동물이어서 바쁜 사람들에게 적합합니다 왜 llm의 원리를 알아야 할까 llm을 단순히 사용하기만 해도 좋지만 그 동작 원리를 이해하면 더 효율적으로 사용할 수 있습니다 정확한 프롬프트를 작성할 수 있게 되어 원하는 답변을 더 쉽게 얻을 수 있죠 llm의 한계를 알면 적절한 상황에서 더 나은 도구를 선택할 수 있어요 성능 개선을 위한 기술 요소들rag langchain 등을 효과적으로 도입할 수 있습니다 llm의 원리 요약 1 대규모 데이터 학습 많은 데이터를 바탕으로 언어 패턴을 학습 2 문맥 기반 추론 입력된 텍스트의 맥락을 파악해 가장 적절한 답변을 생성 3 랜덤성 및 조건성 확률을 기반으로 다양한 답변을 생성하며 조건에 따라 결과가 달라짐 4 미세 조정 특정 용도나 도메인에 맞춰 추가 학습 가능 추가적으로 알아두면 좋은 것 1 rag retrievalaugmented generation llm이 스스로 모든 답을 생성하는 대신 데이터베이스에서 정보를 검색하고 그것을 기반으로 답변을 생성하는 기법이에요 llm의 한계를 극복할 수 있는 방법 중 하나죠 2 vector db 벡터 데이터베이스는 텍스트를 벡터 형태로 변환하여 유사한 의미를 가진 텍스트를 효율적으로 검색할 수 있게 도와주는 기술이에요 llm과 결합하면 더 강력한 검색 및 응답 기능을 구현할 수 있죠 정리 이 강의에서는 llm의 기본 개념과 동작 방식을 배웠습니다 이제 우리는 llm을 활용한 더 복잡한 기술들을 배워나갈 준비가 되었어요 다음 강의에서는 프롬프트 엔지니어링을 통해 llm을 더 똑똑하게 활용하는 방법을 배워볼 겁니다

URL 2 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 1주차 llm 시스템 형성을 위한 다양한 기법 및 요소 개념 익히기 제작 llm 시스템 형성을 위한 다양한 기법 및 요소 개념 익히기 수업 목표 llm대형 언어 모델의 개념과 그 동작 원리에 대해 알아봅니다 ragretrievalaugmented generation vector db langchain 등 최신 기술을 학습하고 이를 llm 시스템에 어떻게 적용하는지에 대해 알아봅니다 목차 강좌 소개 llmlarge language model의 역할 및 중요성 rag retrievalaugmented generation rag의 동작 원리 rag의 장점 rag의 예시 vector db 벡터 데이터베이스 vector db의 동작 과정 vector db의 장점 vector db의 활용 사례 langchain langchain의 동작 원리 langchain의 장점 langchain의 활용 사례 정리 강좌 소개 이번 강좌에서는 llm 시스템을 구축하기 위해 필요한 다양한 핵심 기술 요소들을 살펴볼 거예요 llmlarge language model 자체뿐만 아니라 그 주변에 있는 기법과 도구들인 rag vector db langchain을 학습합니다 이 요소들은 대화형 ai 시스템을 더욱 강력하게 만들어주는 중요한 기술들이며 각각의 개념을 이해하는 것이 필수적입니다 llmlarge language model의 역할 및 중요성 llm란 llm대형 언어 모델은 방대한 양의 텍스트 데이터를 학습하여 자연어를 이해하고 생성할 수 있는 인공지능 모델입니다 gpt3 gpt4 bert와 같은 모델들이 대표적입니다 이 모델들은 매우 큰 크기의 파라미터를 가지고 있으며 텍스트의 맥락context을 파악해 다양한 언어 작업을 수행할 수 있습니다 llm의 주요 기능 자연어 이해nlu 질문이나 명령을 이해하고 적절히 응답하는 능력 텍스트 생성 기존 데이터를 바탕으로 자연스러운 텍스트를 생성 번역 및 요약 다른 언어로 번역하거나 긴 텍스트를 요약 질문 응답 시스템qa 사용자의 질문에 정확하게 답변하는 기능 이처럼 llm은 대규모 데이터를 기반으로 한 학습을 통해 사람처럼 자연스러운 언어 처리를 가능하게 하고 대화형 ai 챗봇 검색 시스템 등 다양한 곳에 응용됩니다 하지만 모든 답변을 자체적으로 생성하는 데는 한계가 있기 때문에 이를 보완하는 기법들이 필요합니다 그 대표적인 기법 중 하나가 바로 rag입니다 rag retrievalaugmented generation rag란 rag는 retrievalaugmented generation의 약자로 말 그대로 검색 기반 생성 기법입니다 llm은 많은 데이터를 학습했음에도 최신 정보나 특정 도메인 지식에 대한 한계를 가질 수 있습니다 이를 보완하기 위해 rag는 llm이 직접 답을 생성하는 대신 외부 데이터베이스나 문서에서 관련 정보를 검색한 후 그 정보를 바탕으로 답변을 생성하는 방식입니다 rag의 동작 원리 1 질문 입력 사용자가 질문을 하면 rag 시스템은 질문에 맞는 답변을 생성하기 전에 검색 단계를 거칩니다 2 문서 검색 retrieval 벡터 db나 기타 정보 저장소에서 질문과 관련된 문서를 검색합니다 이때 사용되는 검색 방법은 텍스트를 벡터화하여 의미적으로 유사한 문서를 찾는 것입니다 3 답변 생성 generation 검색된 문서를 바탕으로 llm이 최종적으로 답변을 생성합니다 rag의 장점 1 최신 정보 활용 llm은 학습된 데이터가 오래될 수 있지만 rag는 최신 데이터베이스에서 정보를 검색할 수 있습니다 2 특정 도메인 정보 제공 도메인에 특화된 정보 제공이 가능하여 일반적인 llm보다 더 정확한 정보를 제공할 수 있습니다 3 효율성 필요한 정보만을 검색해오기 때문에 llm의 모든 지식을 외부에 의존하지 않고도 효율적으로 사용 가능합니다 rag의 예시 예를 들어 법률과 같은 특수 분야에서 질문이 들어올 경우 llm은 법률 데이터베이스에서 관련 문서를 검색하고 이를 바탕으로 답변을 구성할 수 있습니다 즉 llm의 기본 모델에 의존하지 않고도 실시간으로 정확하고 최신의 정보를 제공하는 것이죠 vector db 벡터 데이터베이스 vector db란 vector db는 텍스트 이미지 등의 데이터를 벡터 형태로 변환해 저장하고 그 벡터를 기반으로 데이터를 빠르고 효율적으로 검색하는 데이터베이스입니다 벡터 db는 임베딩embedding이라는 방법으로 데이터를 벡터화하여 유사한 의미를 가진 데이터들을 빠르게 검색할 수 있게 해줍니다 임베딩 임베딩embedding은 텍스트나 이미지를 수학적으로 벡터숫자 배열로 변환하는 과정입니다 예를 들어 강아지라는 단어를 벡터로 변환하면 그 벡터는 고양이와 같은 다른 동물과도 유사한 벡터값을 가질 수 있습니다 벡터 db는 이러한 임베딩된 데이터를 기반으로 문서 검색을 수행합니다 vector db의 동작 과정 1 임베딩 생성 문서나 텍스트를 벡터로 변환합니다 이 벡터는 해당 텍스트의 의미적 정보를 담고 있어요 2 벡터 저장 생성된 벡터를 데이터베이스에 저장합니다 3 벡터 검색 사용자가 검색어를 입력하면 해당 검색어를 벡터로 변환한 후 데이터베이스에서 유사한 벡터를 찾아냅니다 4 결과 제공 유사한 벡터를 가진 문서나 데이터를 검색 결과로 제공합니다 vector db의 장점 1 의미 기반 검색 단순 키워드 매칭이 아니라 텍스트의 의미에 기반한 검색이 가능하여 유사한 의미를 가진 텍스트도 검색할 수 있습니다 2 고성능 처리 대량의 벡터 데이터를 매우 빠르게 처리할 수 있어서 대규모 텍스트 데이터에 대해 효율적으로 검색이 가능합니다 vector db의 활용 사례 1 문서 검색 시스템 대규모 문서 저장소에서 특정 주제에 대한 유사한 문서를 빠르게 검색 2 이미지 검색 이미지를 벡터화하여 유사한 이미지나 관련 이미지를 빠르게 검색 3 질문답변 시스템 질문에 대한 관련 정보를 벡터 기반으로 검색해 답변을 제공 langchain langchain란 langchain은 llm과 같은 언어 모델을 더욱 효율적으로 활용할 수 있게 도와주는 프레임워크입니다 langchain의 목적은 다양한 llm과 외부 리소스를 결합해 강력한 언어 기반 애플리케이션을 만들 수 있도록 돕는 것입니다 llm의 기능을 더욱 확장하고 데이터 소스 api 데이터베이스 등을 쉽게 통합할 수 있습니다 langchain의 주요 기능 llm과 데이터 소스 결합 rag처럼 외부 데이터를 검색해와 llm이 이를 처리하도록 할 수 있습니다 작업 흐름 자동화 여러 개의 llm 작업을 순차적으로 실행할 수 있는 워크플로우를 제공합니다 대화형 ai 개발 여러 번의 대화 흐름을 제어할 수 있는 대화 관리 기능을 통해 챗봇이나 대화형 에이전트를 쉽게 구축할 수 있습니다 langchain의 동작 원리 1 프롬프트 체인 prompt chains langchain은 여러 단계의 프롬프트를 연속적으로 연결하여 복잡한 작업을 수행할 수 있습니다 예를 들어 먼저 문서를 요약하고 그 요약 내용을 바탕으로 질문에 답하는 구조를 만들 수 있습니다 2 메모리 기능 llm은 일반적으로 이전 대화를 기억하지 못하지만 langchain은 메모리 기능을 통해 대화의 맥락을 유지할 수 있게 해줍니다 3 외부 리소스 통합 langchain은 api 데이터베이스 웹 검색 등 다양한 외부 리소스를 결합해 llm의 한계를 보완할 수 있도록 합니다 langchain의 장점 1 유연한 애플리케이션 개발 복잡한 언어 작업을 자동화하거나 여러 단계의 작업을 간단히 연결할 수있습니다 2 확장성 llm이 처리할 수 없는 작업을 외부 리소스를 통해 보완하여 더욱 강력한 ai 시스템을 구축할 수 있습니다 3 대화형 ai 장기적인 대화 흐름을 관리할 수 있어 챗봇이나 고급 대화 시스템을 만드는 데 유리합니다 langchain의 활용 사례 1 자동화된 텍스트 처리 문서 요약 분석 번역 그리고 qa 시스템 등 여러 텍스트 처리 작업을 하나의 체인으로 연결 2 대화형 에이전트 langchain을 사용해 사용자와 지속적인 대화를 유지하는 챗봇이나 대화형 ai 시스템을 구축 3 복잡한 워크플로우 처리 llm과 외부 데이터 소스를 결합해 복잡한 워크플로우를 자동화하고 처리 정리 이번 강좌에서는 llm 시스템 구축에 필요한 네 가지 핵심 요소를 배웠습니다 llm은 대규모 텍스트 데이터로 학습한 자연어 처리 모델로 다양한 언어 작업을 수행할 수 있습니다 rag는 검색 기반 생성 기법으로 llm이 외부 데이터를 활용해 더 정확하고 최신 정보를 제공할 수 있게 합니다 vector db는 텍스트 데이터를 벡터화해 의미 기반으로 검색할 수 있도록 도와주는 데이터베이스입니다 langchain은 llm과 외부 데이터를 결합해 복잡한 작업을 자동화하고 대화형 ai 시스템을 쉽게 구축할 수 있는 프레임워크입니다 이 기술들은 개별적으로도 중요하지만 서로 결합될 때 더욱 강력한 llm 시스템을 구축할 수 있습니다 son minsuck10월 7일 편집됨 피드백 강좌 소개 이번에 배울것

URL 3 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 1주차 openai playground 사용법 가이드 제작 openai playground 사용법 가이드 수업 목표 openai playground가 무엇인지 그 기능과 목적에 대해 알아봅니다 다양한 작업을 통해 프롬프트 엔지니어링을 실습하고 ai 모델의 반응을 실험해봅니다 playground에서 제공하는 다양한 파라미터와 설정을 통해 ai 모델의 동작 방식을 체험하고 활용 방법을 익힙니다 목차 강좌 소개 openai playground란 openai playground에서 할 수 있는 것 openai playground의 주요 설정 openai playground 사용법 playground 접근 및 기본 사용법 실습 예시 user assistant system 역할 설정 주의사항 openai playground 사용을 통해 배울 수 있는 것 정리 강좌 소개 이번 강좌에서는 openai playground에 대해 자세히 배워보겠습니다 playground는 프롬프트 엔지니어링을 실습하고 다양한 ai 모델의 동작을 체험할 수 있는 실험 플랫폼입니다 이 도구는 openai의 gpt 모델을 사용해 다양한 작업을 시도하고 모델의 파라미터를 조정하며 ai의 동작을 테스트할 수 있습니다 기본 사용법부터 각종 설정 항목 그리고 사용 시 주의할 점을 다뤄보겠습니다 openai playground란 openai playground playground는 openai에서 제공하는 웹 기반의 실험 환경으로 gpt 모델을 자유롭게 활용해보고 프롬프트 실험을 할 수 있는 플랫폼입니다 프롬프트를 입력해 보고 그에 대한 응답을 실시간으로 확인할 수 있습니다 다양한 파라미터 설정을 통해 모델의 동작을 제어할 수 있습니다 주로 프롬프트 엔지니어링 실습 ai 모델의 응답 패턴을 이해하는 데 유용합니다 openai playground 주요 목적 프롬프트 테스트 입력 프롬프트에 따른 결과 확인 모델 성능 평가 다양한 설정을 변경해가며 모델의 성능을 평가 텍스트 생성 실험 실시간으로 텍스트를 생성하고 이를 통해 언어 모델의 동작 방식을 이해 openai playground에서 할 수 있는 것 1 텍스트 생성 playground에서는 사용자가 입력한 프롬프트를 바탕으로 gpt 모델이 답변을 생성합니다 예를 들어 질문에 대한 답변을 얻거나 문장이나 글을 생성할 수 있습니다 예시 프롬프트 인공지능의 장점에 대해 설명해줘 응답 인공지능의 장점으로는 빠른 데이터 처리 복잡한 문제 해결 인간의 일상 작업 자동화가 있습니다 2 다양한 작업 테스트 playground는 단순한 대화뿐만 아니라 여러 작업을 테스트할 수 있습니다 요약 긴 텍스트를 요약 번역 텍스트를 다른 언어로 번역 질문 답변 주어진 텍스트에서 질문에 답변 생성 창의적 글쓰기 소설 시 대본 등 창의적인 텍스트 작성 3 프롬프트 엔지니어링 실험 playground는 프롬프트 엔지니어링을 연습하기에 이상적입니다 프롬프트 작성의 방식이나 내용에 따라 모델의 응답이 어떻게 달라지는지 실험할 수 있습니다 기본 프롬프트 오늘 날씨는 어때 샷shot 기반 프롬프트 다음 예문을 참고하여 비슷한 스타일로 텍스트를 생성해줘 예시 제공 페르소나 설정 당신은 역사학자입니다 역사적 사실을 설명해주세요 openai playground의 주요 설정 openai playground의 주요 설정 playground에서 사용할 수 있는 다양한 설정값들이 있습니다 각 설정값은 모델이 답변을 생성할 때 영향을 미치므로 상황에 맞게 조정해야 합니다 1 모델 선택 가장 먼저 모델을 선택할 수 있어요 gpt4 family 최신이자 가장 강력한 언어 모델 복잡한 작업과 창의적인 응답이 필요할 때 사용 gpt35 family 조금 더 가벼운 버전으로 빠르고 효율적인 응답을 생성합니다 각 모델마다 성능과 응답 속도에 차이가 있으니 작업에 맞는 모델을 선택하세요 2 온도 temperature 온도는 모델의 랜덤성을 조정하는 매개변수입니다 값이 높을수록 창의적이고 예측 불가능한 응답이 나오고 값이 낮을수록 일관적이고 안정적인 응답이 나옵니다 00 완전히 고정된 응답 최소한의 랜덤성 10 매우 창의적이고 다채로운 응답 최대 랜덤성 사용법 예시 낮은 온도 오늘 날씨는 어때 오늘 날씨는 맑습니다 높은 온도 오늘 날씨는 어때 하늘이 맑고 산들바람이 불어오는 기분 좋은 날입니다 3 토큰 길이 max tokens 토큰은 gpt 모델에서 사용하는 단위로 생성할 수 있는 텍스트의 길이를 조절하는 값입니다기본적으로 짧은 응답이 필요하면 낮은 값을 긴 글을 생성하려면 높은 값을 설정하세요 예시 짧은 응답 50 토큰 짧은 요약 긴 응답 200 토큰 자세한 설명 4 탑피 topp nucleus sampling 탑피 topp는 응답의 다양성을 제어하는 또 다른 파라미터입니다 10 모든 가능한 답변을 고려해 다양한 응답을 생성 05 확률 상위 50에 해당하는 답변들만을 선택하여 더 집중된 응답을 생성합니다 5 프롬프트 형식 stop sequences 프롬프트 종료를 위한 특정 단어나 기호를 설정해 응답이 해당 기호에 도달하면 멈추도록 할 수 있습니다 예시 답변이 끝날 때마다 end라는 단어가 나오게 할 수 있습니다 주의할 점 frequencypresence penalty 1 frequency penalty 이미 사용한 단어나 문장을 반복하지 않도록 하는 설정 값을 높이면 중복된 표현을 줄이게 됩니다 2 presence penalty 새로운 단어나 아이디어를 더 많이 사용하도록 유도하는 설정 값을 높이면 더 다양한 표현이 나타납니다 openai playground 사용법 playground 접근 및 기본 사용법 openai playground는 웹 브라우저에서 바로 접속할 수 있으며 별도의 설치가 필요 없습니다 로그인 후 모델과 설정을 선택하고 프롬프트를 입력한 후 submit을 클릭하면 결과가 출력됩니다 실습 예시 1 목표 사용자가 주어진 프롬프트에 따라 글을 요약하는 모델을 만들고 싶어요 2 프롬프트 작성 다음 글을 요약해 주세요 본문 텍스트 입력 3 파라미터 설정 모델 gpt4 온도 03 더 일관된 요약을 원할 경우 max tokens 100 짧은 요약을 위해 topp 10 모든 가능성 고려 4 결과 확인 결과 gpt 모델은 주어진 본문을 요약한 텍스트를 출력합니다 5 활용 팁 실시간으로 프롬프트 수정 프롬프트의 내용을 조금씩 수정하며 결과를 확인해보세요 다양한 파라미터 조합을 시도해보고 그에 따른 모델의 응답 변화를 비교해보세요 shot prompting을 사용해 몇 가지 예시를 제시한 후 모델이 패턴을 학습하게 할 수 있습니다 user assistant system 역할 설정 playground에서 제공하는 role 설정을 통해 user assistant system이라는 세 가지 역할을 설정할 수 있습니다 이를 통해 대화의 흐름을 더 자연스럽고 체계적으로 관리할 수 있어요 1 user 사용자 user는 대화의 주체로 프롬프트를 입력하는 역할을 담당합니다 주로 질문을 하거나 특정 작업을 요청하는 사용자 역할로 질문이나 요구를 담당합니다 예시 영국 역사에 대해 알려주세요 이 문장을 영어로 번역해 주세요 2 assistant 도우미 assistant는 user의 요청에 응답하는 역할을 맡습니다 즉 gpt 모델이 답변을 생성하는 역할을 수행하며 대화의 주요 흐름을 이어갑니다 예시 user 영국 역사에 대해 알려주세요 assistant 영국은 5세기부터 1066년 노르만 정복까지 중요한 역사적 사건들이 있었습니다 3 system 시스템 system은 대화의 전반적인 규칙이나 지침을 제공하는 역할입니다 system 역할은 assistant가 어떻게 응답할지 지침을 제공하는 데 사용되며 프롬프트 설정에 따라 assistant의 성격이나 스타일을 조정할 수 있습니다 예시 assistant는 친절하고 명확하게 답변합니다 assistant는 간단한 정보만 제공하도록 설계되었습니다 활용 팁 system 역할을 이용해 assistant가 특정 역할을 수행하게 할 수 있습니다 예를 들어 system 지침으로 assistant는 프로그래밍 전문가로서 답변합니다라고 설정하면 기술적 질문에 전문적인 답변을 하게끔 유도할 수 있습니다 주의사항 1 비용 playground에서 사용되는 각 토큰은 비용이 발생합니다 실습 시 토큰 사용량을 관리하는 것이 중요합니다 짧은 프롬프트와 응답을 사용하면 토큰 사용량을 줄일 수 있어요 2 모델의 한계 모델이 항상 정답을 제공하지 않음 모델이 생성하는 모든 응답이 정확하지 않을 수 있습니다 모델은 학습한 데이터를 기반으로 답변을 생성하지만 사실과 다른 정보를 제공할 수 있습니다 데이터 업데이트 주기 gpt 모델은 고정된 데이터를 기반으로 학습되기 때문에 최신 정보가 반영되지 않을 수 있습니다 3 프라이버시와 보안 민감한 정보 입력 금지 openai는 모델의 입력 데이터를 사용해 시스템을 개선할 수 있으므로 개인 정보나 민감한 데이터는 playground에서 입력하지 않는 것이 좋습니다 4 출력 조정 필요 응답이 너무 길거나 적절하지 않으면 토큰 제한이나 프롬프트 변경을 통해 출력을 조정할 수 있습니다 이는 특히 긴 글이나 특정 형식의 답변이 필요한 경우 유용합니다 openai playground 사용을 통해 배울 수 있는 것 1 프롬프트 엔지니어링 스킬 향상 다양한 프롬프트를 실험하면서 ai가 어떤 방식으로 응답하는지 이해할 수 있습니다 2 모델 성능 최적화 파라미터를 조정해가며 gpt 모델의 출력 결과를 최적화하는 방법을 배울 수 있습니다 3 다양한 응용 프로그램 테스트 playground를 활용해 요약 번역 qa 창의적 글쓰기 등 여러 ai 응용 프로그램을 테스트해볼 수 있습니다 정리 이번 강좌에서는 openai playground의 기본 사용법과 다양한 설정값 그리고 주의사항을 배웠습니다 playground는 프롬프트 엔지니어링을 연습할 수 있는 매우 유용한 도구이며 실시간으로 다양한 파라미터를 조정해 ai의 응답을 테스트해볼 수 있습니다 다음 강의에서는 이러한 기능을 활용해 더 고급스러운 프롬프트 기술을 익혀볼 겁니다 playground에서 많이 실험해보세요 이를 통해 llm의 작동 방식을 이해하고 더 똑똑한 ai 애플리케이션을 개발하는 데 큰 도움이 될 거예요

URL 4 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 2주차 프롬프트 엔지니어링 개념잡기 제작 프롬프트 엔지니어링 개념잡기 수업 목표 프롬프트 엔지니어링이 무엇인지 그리고 대형 언어 모델llm에서의 중요성에 대해 알아봅니다 프롬프트 구조와 어조를 조정해 최적의 응답을 유도하는 방법을 학습합니다 llm의 패턴 인식과 확률 계산 방식이 프롬프트 엔지니어링에 어떻게 적용되는지 알아봅니다 목차 이번에 배울것 프롬프트 엔지니어링이란 프롬프트 엔지니어링이 동작하는 이유 프롬프트 엔지니어링과 system assistant user 역할 적용하기 프롬프트 엔지니어링 적용 예시 프롬프트 엔지니어링에서 주의할 점 정리 이번에 배울것 이번에는 프롬프트 엔지니어링의 개념에 대해 알아볼 예정입니다 프롬프트 엔지니어링이 무엇인지 그리고 이를 통해 대형 언어 모델llm에서 최적의 성능을 이끌어내는 방법을 학습합니다 다양한 사례를 통해 효과적인 프롬프트 구성 방법을 익히고 실습을 통해 프롬프트의 구조와 어조가 응답에 미치는 영향을 살펴보겠습니다 프롬프트 엔지니어링이란 프롬프트 엔지니어링 프롬프트 엔지니어링은 인공지능 모델 특히 대형 언어 모델llm에 적절한 입력프롬프트을 설계하고 작성하여 모델이 최적의 응답을 하도록 유도하는 기술입니다 gpt 모델과 같은 llm은 입력된 프롬프트에 따라 답변을 생성하므로 프롬프트가 잘 설계되면 정확하고 유용한 결과를 얻을 수 있고 반대로 잘못된 프롬프트는 부정확한 답변이나 혼란스러운 결과를 초래할 수 있습니다 프롬프트 엔지니어링의 목표 프롬프트 엔지니어링의 주요 목표는 모델이 의도한 대로 응답하도록 유도하는 것입니다 이 과정에서 프롬프트의 구조나 어조를 조정해 답변의 품질과 일관성을 높이는 것이 중요합니다 예를 들어 특정 정보만을 요구하거나 특정한 방식으로 설명해달라고 할 때는 명확하고 구체적인 프롬프트가 필요합니다 프롬프트 엔지니어링이 동작하는 이유 프롬프트 엔지니어링 동작하는 이유 llm은 기본적으로 패턴 인식과 확률 계산에 기반하여 학습됩니다 즉 학습 데이터 내에서 어떤 단어가 어떤 맥락에서 자주 등장하는지를 학습하고 주어진 프롬프트에 맞는 답변을 확률적으로 생성합니다 프롬프트 엔지니어링은 이 모델의 패턴 학습 메커니즘을 활용하여 모델이 적절한 경로로 답을 유도하도록 하는 방법입니다 llm의 동작 원리 간단 설명 1 프롬프트 입력 사용자가 모델에 질문이나 요청을 입력합니다 2 맥락 파악 llm은 입력된 프롬프트를 기반으로 맥락을 분석하고 그에 맞는 적절한 답변을 생성합니다 3 확률 계산 학습된 데이터를 기반으로 각 단어나 문장의 확률 분포를 계산해 가장 가능성 높은 답변을 선택합니다 프롬프트 엔지니어링은 이러한 과정을 최적화하기 위한 방법으로 더 나은 답변을 얻기 위해 명확하고 구체적인 입력을 작성하는 것입니다 프롬프트 엔지니어링과 system assistant user 역할 적용하기 llm을 사용할 때 특히 대화형 모델의 구조화된 대화 흐름을 만들기 위해서는 user assistant system의 세 가지 역할을 설정할 수 있습니다 이 세 가지 역할을 적절히 조정하면 모델이 더 자연스럽고 유의미한 대화를 진행할 수 있습니다 1 user 사용자 user는 모델과 대화하는 주체로 질문이나 요구사항을 제시하는 역할입니다 프롬프트 엔지니어링에서 user 프롬프트는 명확한 요청을 포함해야 하며 의도가 분명해야 합니다 user는 모델이 무엇을 해야 하는지 정확하게 전달해야 하므로 질문 형태의 프롬프트가 많습니다 예시 영국의 산업 혁명에 대해 설명해 주세요 이 텍스트를 요약해 주세요 다음 문장을 영어로 번역해 주세요 포인트 user는 구체적이고 명확한 요청을 해야 합니다 이로써 모델이 혼란을 겪지 않고 정확한 답변을 생성할 수 있습니다 2 assistant 도우미 assistant는 user의 질문에 답변을 제공하는 역할로 실제로 gpt 모델이 수행하는 부분입니다 assistant 프롬프트는 user가 입력한 내용에 따라 적절한 답변을 생성해야 하며 명확한 어조와 친절한 태도로 응답하는 것이 일반적입니다 예시 user 영국의 산업 혁명에 대해 설명해 주세요 assistant 영국의 산업 혁명은 18세기 말부터 19세기 초에 걸쳐 일어난 경제적 기술적 변화로 기계화와 공장 시스템이 급격히 발전한 시기입니다 포인트 assistant는 정확하고 친절하게 응답해야 하며 명확하고 일관성 있는 답변을 생성할 수 있도록 설정합니다 이때 프롬프트 엔지니어링에서 중요한 역할은 질문의 맥락에 맞는 적절한 답변을 제공하는 것입니다 3 system 시스템 system은 대화의 기본 규칙과 assistant의 성격을 결정합니다 system 역할은 대화의 배경과 규칙을 설정해 모델이 답변을 생성할 때 어떤 스타일과 어조를 사용할지 지시할 수 있습니다 system 프롬프트는 모델이 특정한 태도나 전문성을 갖고 응답하도록 프레임워크를 제공합니다 예시 assistant는 친절하고 이해하기 쉬운 설명을 제공합니다 assistant는 역사학자로서 깊이 있는 정보를 제공합니다 assistant는 간결하고 정확한 답변만 제공합니다 포인트 system 프롬프트는 assistant의 행동을 가이드하는 역할을 합니다 이 프롬프트는 대화의 일관성을 유지하고 특정한 목적에 맞게 답변을 최적화할 수 있습니다 프롬프트 엔지니어링 적용 예시 1 일반적인 대화 흐름 설정 system assistant는 친절하고 명확한 설명을 제공합니다 user 산업 혁명이 시작된 배경에 대해 알려주세요 assistant 산업 혁명은 18세기 후반 영국에서 시작되었으며 기술 혁신과 경제적 변화가 그 주요 배경입니다 특히 기계화와 공장 시스템의 발전이 큰 역할을 했습니다 2 전문적이고 깊이 있는 답변을 원할 때 system assistant는 역사 전문가로서 깊이 있는 설명을 제공하며 중요한 역사적 배경도 함께 다룹니다 user 영국의 산업 혁명의 주요 원인에 대해 설명해 주세요 assistant 산업 혁명의 주요 원인 중 하나는 영국의 풍부한 천연 자원 특히 석탄과 철광석의 이용 가능성입니다 또한 상업의 발전과 대규모 자본 축적 정치적 안정성 등이 중요한 역할을 했습니다 이 외에도 농업 혁명으로 인한 노동력의 증가도 큰 원인이었습니다 3 간결한 답변만을 원할 때 system assistant는 간결하고 핵심만을 전달하는 답변을 제공합니다 user 산업 혁명의 주요 발명품은 무엇인가요 assistant 산업 혁명의 주요 발명품으로는 방적기 증기기관 코튼 진 등이 있습니다 프롬프트 엔지니어링에서 주의할 점 1 명확하고 구체적인 프롬프트 작성 모델이 혼란을 겪지 않도록 프롬프트는 구체적이고 명확하게 작성해야 합니다 예를 들어 모호한 질문이나 추상적인 요청은 피하고 어떤 결과를 기대하는지 명확히 표현하는 것이 중요합니다 2 맥락 유지 llm은 이전의 대화 내용을 기반으로 답변을 생성하므로 맥락을 유지하는 것이 중요합니다 이전 대화와의 연결성을 고려하여 일관성 있는 프롬프트를 작성하세요 3 system 설정의 중요성 system 프롬프트는 assistant의 응답 스타일과 태도에 큰 영향을 미칩니다 올바르게 설정된 system 프롬프트는 대화의 질을 높이고 사용자가 원하는 특정 답변 스타일을 확보할 수 있습니다 정리 프롬프트 엔지니어링은 llm을 더 효율적으로 그리고 정확하게 사용할 수 있도록 돕는 핵심 기술입니다 user assistant system 역할을 잘 활용하여 더 구조화된 대화를 만들 수 있으며 특히 system 프롬프트를 통해 assistant가 어떤 스타일로 답변해야 할지 지침을 줄 수 있습니다 프롬프트 엔지니어링을 적절히 활용하면 ai 모델의 응답 품질을 크게 향상시킬 수 있습니다 다음 단계에서는 프롬프트 엔지니어링의 세부 기법을 학습하여 더욱 복잡한 작업과 응용을 할 수 있도록 배워보겠습니다

URL 5 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 2주차 프롬프트 엔지니어링 맛보기 제작 프롬프트 엔지니어링 맛보기 수업 목표 프롬프트 엔지니어링이 무엇이며 어떻게 활용할 수 있는지 배웁니다 간단한 실습을 통해 프롬프트 엔지니어링의 기본 원리를 체험합니다 정중한 환영 인사를 하는 chatgpt를 만들며 프롬프트를 개선하는 과정을 학습합니다 목차 이번에 배울것 첫 프롬프트 엔지니어링 실습 요구 사항 분석하기 기본 chatgpt 인사 맛보기 정중한 말투 설정하기 영어로도 인사하기 강사 소개 추가하기 챗봇임을 알려주기 정리 이번에 배울것 이번 시간에는 프롬프트 엔지니어링이 어떤 개념인지 실제로 어떻게 작동하는지 맛보기 실습을 진행해 볼 거예요 복잡한 기법에 들어가기 전에 간단한 예시를 통해 프롬프트 엔지니어링이 무엇인지 감을 잡아보겠습니다 첫 프롬프트 엔지니어링 실습 여러분이 처음으로 chatgpt를 사용할 때 아마도 가장 기본적인 예제는 환영 인사일 것입니다 이번 실습에서는 chatgpt가 환영 인사를 하는 방식을 개선해 나가는 과정을 함께 해볼 거예요 요구 사항 분석하기 우리가 만들 프롬프트의 목적은 정중한 환영 인사를 하는 chatgpt를 만들기입니다 요구 사항 반드시 정중한 말투를 사용해야 해요 한국어로 먼저 인사하고 그다음에 영어로 인사해야 해요 마지막에는 강사 배형호 강의의 챗봇이라고 본인이 챗봇임을 알려야 해요 강사 소개도 포함되어야 해요 이제 이 요구 사항을 프롬프트로 구체화해봅시다 기본 chatgpt 인사 맛보기 가장 먼저 튜닝이 전혀 안 된 chatgpt에 환영 인사를 시켜봅시다 user 안녕 반가워 assistant 안녕하세요 만나서 반갑습니다 무엇을 도와드릴까요 음 인사를 하긴 하지만 원하는 요구 사항이 지켜지지 않았네요 그럼 하나씩 요구 사항을 충족시키기 위해 프롬프트 엔지니어링을 진행해 볼까요 정중한 말투 설정하기 첫 번째로 정중한 말투를 사용하도록 해보겠습니다 말투를 지정하는 것은 페르소나 설정의 일부로 인공지능이 어떤 성격이나 태도를 가질지 결정할 수 있습니다 system 프롬프트 예시 system 너는 환영 인사를 하는 담당자야 반드시 정중한 말투로 응답해 이제 chatgpt가 정중한 말투로 인사를 하도록 만들었어요 한번 테스트해볼까요 user 안녕 반가워 assistant 안녕하세요 강의에 참석해 주셔서 대단히 감사합니다 유익한 시간을 보내시기를 바랍니다 정중한 말투로 바뀌었네요 다음으로는 영어로 인사하는 부분을 추가해볼게요 영어로도 인사하기 이번에는 한국어로 인사한 후 영어로도 인사하도록 프롬프트를 조정해보겠습니다 이것은 기본적인 지침basic prompting을 추가하는 방식입니다 system 프롬프트 예시 system 너는 환영 인사를 하는 담당자야 반드시 정중한 말투로 응답해 먼저 한국어로 응답한 후 영어로도 응답해 이렇게 시스템 지침을 수정하고 다시 테스트해봅시다 user 안녕 반가워 assistant 안녕하세요 강의에 참석해 주셔서 대단히 감사드립니다 오늘의 강의에서 유익한 시간을 보내시기를 바랍니다 hello thank attending todays lecture hope great time learning us 이제 영어로도 인사하게 되었네요 마지막으로 강사 소개를 추가해볼까요 강사 소개 추가하기 이제 마지막으로 강사 배형호에 대한 정보를 추가해봅시다 이 정보를 system 프롬프트에 넣어서 chatgpt가 스스로 강사 소개를 하도록 설정할 수 있어요 system 프롬프트 예시 system 너는 환영 인사를 하는 담당자야 반드시 정중한 말투로 응답해 먼저 한국어로 응답한 후 영어로도 응답해 강사 배형호에 대해 소개하는 말을 반드시 포함해 그리고 강사 배형호에 대한 추가 정보를 제공해봅시다 강사 정보 예시 강사 배형호는 인공지능 연구와 백엔드 개발 분야에서 뛰어난 능력을 가진 전문가입니다 이제 최종 프롬프트로 다시 테스트해볼까요 user 안녕 반가워 assistant 안녕하세요 오늘 강의에 참석해 주셔서 대단히 감사드립니다 강사 배형호님은 인공지능 연구와 백엔드 개발에 탁월한 능력을 지닌 전문가입니다 오늘 강의를 통해 많은 것을 배우실 수 있기를 바랍니다 hello thank attending todays lecture instructor bae hyeongho expert ai research backend development hope enjoy session learn lot 부끄럽습니다 챗봇임을 알려주기 마지막으로 강의 챗봇임을 알리는 문구를 추가해봅시다 이를 통해 특정 문구나 형태를 출력하도록 유도할 수 있습니다 system 프롬프트 예시 system 너는 환영 인사를 하는 담당자야 반드시 정중한 말투로 응답해 마지막에는 저는 강사 배형호 강의의 챗봇입니다라고 말해 먼저 한국어로 응답한 후 영어로도 응답해 강사 배형호에 대해 소개하는 말을 반드시 포함하고 이제 테스트해보겠습니다 user 안녕 반가워 assistant 안녕하세요 강사 배형호님과 함께하는 강의에 오신 것을 환영합니다 배형호님은 인공지능 연구와 백엔드 개발 분야에서 탁월한 전문가입니다 오늘 강의를 통해 많은 것을 배울 수 있기를 바랍니다 hello welcome lecture instructor bae hyeongho expert ai research backend development hope gain valuable insights todays session 저는 강사 배형호 강의의 챗봇입니다 prompted hyeongho bae 정리 이렇게 프롬프트 엔지니어링을 통해 chatgpt의 환영 인사를 점점 개선해 나갈 수 있었습니다 system user assistant 각 역할에 맞게 프롬프트를 엔지니어링하는 과정에서 요구 사항을 하나씩 반영하면서 더 정교한 대화 흐름을 만들어 나갈 수 있었습니다 프롬프트 엔지니어링을 잘 활용하면 단순한 대화형 ai도 다양한 요구에 맞게 맞춤형 응답을 할 수 있게 됩니다 앞으로의 강의에서는 이러한 기법을 더욱 깊이 있게 다뤄볼 예정이니 기대해 주세요 chatgpt의 무한한 가능성을 활용해 여러분만의 ai 대화 파트너를 만들어 보세요 son minsuck10월 7일 환영합니다 이번에 배울것

URL 6 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 2주차 프롬프트 엔지니어링의 기본 원칙 제작 프롬프트 엔지니어링의 기본 원칙 수업 목표 llm을 효과적으로 활용하기 위한 명확한 지침 설정 방법을 학습합니다 명확한 요청 정보 제공 작업 분할 등을 통해 더 나은 응답을 이끌어내는 방법을 실습합니다 구체적인 요청과 추상적인 요청의 차이를 실전 예제를 통해 비교하며 학습합니다 목차 이번에 배울것 명확한 요청 사항 전달하기 정보를 제공해라 제약 조건을 줘라 4 복잡한 작업을 분할해라 정리 이번에 배울것 이번 시간에는 프롬프트 엔지니어링의 기본 원칙에 대해 배워볼 거예요 llm대형 언어 모델을 효과적으로 활용하려면 명확하고 구체적인 지침을 주는 것이 매우 중요합니다 이 강의에서는 명확한 요청 정보 제공 제약 조건 설정 작업 분할 같은 기본 원칙을 다룹니다 예제도 함께 볼 거니 편하게 따라와 주세요 명확한 요청 사항 전달하기 llm은 매우 강력한 도구이지만 동시에 모든 답을 가진 바보처럼 동작한다고 생각하면 됩니다 너무 추상적이거나 모호한 요청을 하면 모델이 혼란스럽거나 부정확한 답을 줄 수 있죠 따라서 명확한 요청이 필수입니다 예시 1 추상적인 요청 user 잘생긴 연예인에 대해 알려줘 assistant 잘생긴 연예인에 대한 이야기는 매우 다양합니다 한국에서는 김수현과 송중기가 대표적입니다 결과 원하는 답이 아니라 너무 일반적인 정보를 제공하고 있네요 이제 구체적으로 다시 물어볼게요 예시 2 구체적인 요청 user 본명이 이동민이면서 1997년 3월 30일에 태어난 연예인 알려줘 assistant 본명이 이동민인 연예인은 아스트로astro의 멤버 차은우입니다 결과 이번에는 원하는 답을 정확히 얻었어요 구체적인 요청을 통해 정확한 답변을 받을 수 있죠 정보를 제공해라 llm은 최신 정보나 학습되지 않은 데이터를 모릅니다 따라서 모델에게 정보를 직접 제공해야 할 때가 많습니다 llm은 대화의 흐름을 기억하므로 이전에 제공한 정보를 활용해 답변할 수 있죠 예시 정보 제공하기 user 김현성은 공인회계사를 준비하는 서울대학교 경영학과 학생이야 나이는 27세이고 군대와 재수를 거쳤어 김현성에게 응원의 글을 작성해줘 assistant 김현성님 서울대 경영학과에서 공인회계사 시험을 준비하는 열정과 헌신에 큰 응원을 보냅니다 군대와 재수를 겪으며 쌓은 경험이 큰 자산이 될 것입니다 결과 김현성에 대한 정보를 제공하니 개인화된 응원의 글을 작성할 수 있었어요 제약 조건을 줘라 대답의 제약 조건을 설정하면 더 명확한 결과를 얻을 수 있습니다 이 제약 조건은 답변의 길이나 특정한 정보만 포함하는 것 등 다양하게 적용할 수 있어요 예시 1 제약 조건 없이 요청 user 나폴레옹에 대해 최대한 길게 설명해줘 assistant 나폴레옹 보나파르트는 1769년에 태어나 중략 그의 전투와 정복 활동은 유럽 전역에 큰 영향을 미쳤습니다 계속 긴 설명 결과 정보가 많긴 하지만 너무 길어서 요점을 파악하기 힘들 수 있죠 예시 2 제약 조건 추가 user 나폴레옹에 대해 3가지 주요 특징만 설명해줘 assistant 나폴레옹의 3가지 주요 특징은 다음과 같습니다 1 뛰어난 군사 전략가 2 정치적 개혁자 3 유럽 역사에 미친 큰 영향 결과 제약 조건을 주니 원하는 정보만 깔끔하게 제공받았어요 4 복잡한 작업을 분할해라 복잡한 작업을 한꺼번에 요청하면 llm이 잘못된 답변을 줄 수 있습니다 이럴 때는 작업을 여러 단계로 나누어 요청하는 것이 더 효과적입니다 특히 코드 작성이나 긴 텍스트 요약 등에서는 작업 분할이 유용해요 예시 단계별 계산 요청 user 피보나치 수열 10번째 값을 단계별로 계산해줘 assistant 피보나치 수열은 각 숫자가 바로 앞의 두 숫자의 합입니다 이제 10번째 수까지 단계별로 계산해 볼게요 1단계 2단계 10단계 동작 예시 결과 단계별 계산을 요청하니 차근차근 답을 도출할 수 있었어요 정리 오늘 배운 프롬프트 엔지니어링 기본 원칙은 다음과 같습니다 명확한 요청 사항을 전달해라 정보를 제공하여 최신 정보를 반영해라 제약 조건을 줘라 복잡한 작업은 단계별로 분할해라 이 원칙들을 잘 활용하면 chatgpt를 더욱 효율적으로 사용할 수 있어요 다음 단계에서는 이 원칙을 바탕으로 더 복잡한 프롬프트 엔지니어링 기법을 배워보겠습니다 프롬프트 엔지니어링의 기본 원칙을 잘 이해하고 실습을 통해 더 깊이 있게 적용해보세요

URL 7 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 3주차 shot 계열의 프롬프팅 기법 배워보기 제작 shot 계열의 프롬프팅 기법 배워보기 수업 목표 zeroshot oneshot fewshot 프롬프팅 기법이 무엇인지 배우고 각 기법이 ai 모델의 응답에 미치는 영향을 학습합니다 다양한 예제를 통해 shot 프롬프팅을 실습하고 모델의 응답이 어떻게 달라지는지 비교해 봅니다 주어진 작업에 따라 shot 수를 조절하여 최적의 답변을 이끌어내는 방법을 탐구합니다 목차 이번에 배울것 zeroshot 프롬프팅 oneshot 프롬프팅 fewshot 프롬프팅 추가 팁 fewshot 프롬프팅 실습하기 정리 이번에 배울것 이번 강의에서는 shot 계열의 프롬프팅 기법을 다뤄보겠습니다 shot이라는 개념은 사실 매우 간단합니다 shot은 그냥 인공지능에게 전달한 예제를 의미해요 예제를 하나 주면 oneshot 예제를 안 주면 zeroshot 여러 개 주면 fewshot 프롬프팅이라고 불러요 보통 shot을 많이 줄수록 더 원하는 방향으로 답변을 유도할 확률이 높아진답니다 자 이제 하나씩 살펴보겠습니다 zeroshot 프롬프팅 zeroshot zeroshot은 아무런 예제를 주지 않고 지침만 전달하는 방식입니다 인공지능에게 추상적인 요청을 하면 기대한 답변을 받기 어려운 경우가 많아요 예를 들어볼게요 system 너는 전달된 구구단에 대한 농담을 해야해 user 6 3 assistant 왜 6은 3을 곱하면 항상 놀라는 표정을 짓는 걸까요 왜냐하면 답이 18이라고 귓속말로 말해주니까요 결과 엉뚱한 농담이 나왔죠 이렇게 zeroshot은 구체적인 요구를 이끌어내기가 어렵답니다 특히 사용자가 원하는 특정한 대답이 있으면 zeroshot은 잘 맞지 않을 수 있어요 oneshot 프롬프팅 oneshot 이제 샷shot을 하나 추가해서 개선해봅시다 oneshot 프롬프팅은 예제를 하나 전달해주는 방식입니다 먼저 zeroshot으로 한 예제부터 볼까요 system 너는 전달된 구구단에 대한 농담을 해야해 user 6 3 assistant 왜 6은 3을 곱하면 항상 놀라는 표정을 짓는 걸까요 왜냐하면 답이 18이라고 귓속말로 말해주니까요 이제 oneshot 예제를 추가해봅시다 구구단 농담의 예시 하나를 제공해볼게요 system 너는 구구단 농담을 하는 인공지능이야 이건 구구단 농담의 예시야 6 3 육삼빌딩 user 2 4 assistant 2 4 이사오세요 결과 구체적인 oneshot 예제를 주니 훨씬 더 의도에 맞는 농담이 나왔죠 fewshot 프롬프팅 이제 fewshot으로 여러 개의 예시를 줘서 모델이 더 잘 학습하도록 해볼까요 system 너는 예를 참고해서 전달된 구구단에 대한 농담을 해야해 과정은 말하지 말고 농담만 말해 입력 6 4 출력 육사생도 입력 2 8 출력 이팔 청춘 입력 5 2 출력 오이팩 user 2 4 assistant 이사갈 시간 user 3 8 assistant 삼팔광땡 user 2 6 assistant 이육사 결과 이제 더 다양한 예제를 준 덕분에 정확하게 농담을 생성할 수 있었어요 fewshot 프롬프팅은 많은 예제를 주면 유도하는 능력이 더욱 향상된답니다 추가 팁 사실 fewshot 프롬프팅을 할 때 입력과 출력만 제공하는 것보다 과정도 함께 제공하면 더 좋습니다 과정을 설명해주면 모델의 추론 능력이 향상되죠 예를 들어볼게요 system 너는 예를 참고해서 전달된 구구단에 대한 농담을 해야해 과정은 말하지 말고 농담만 말해 입력 6 4 출력 육사생도 과정 6 4는 한국어로 육곱하기사야 여기에서 곱하기를 빼면 육사가 되지 육사로 시작하는 단어를 찾은 거야 입력 2 8 출력 이팔 청춘 과정 2 8은 한국어로 이곱하기팔이야 여기서 곱하기를 빼면 이팔이 되지 이팔로 시작하는 단어를 찾은 거야 입력 5 2 출력 오이팩 과정 5 2는 오곱하기이야 여기서 곱하기를 빼면 오이가 돼 오이로 시작하는 단어를 찾은 거야 user 2 4 assistant 이사오세요 결과 과정을 제공하니 모델이 더 정확한 추론을 할 수 있었습니다 이런 식으로 과정도 함께 지침으로 주면 더 정확한 답변을 유도할 수 있습니다 fewshot 프롬프팅 실습하기 예시 1 공포의 쿵쿵따 쿵쿵따 게임을 할 때도 fewshot 프롬프팅을 활용할 수 있어요 예시 없이 해보면 잘못된 답변이 나올 수 있죠 user 나랑 쿵쿵따하자 라이터 쿵쿵따 assistant 토마토 결과 엉뚱한 답이 나왔죠 이제 fewshot을 추가해봅시다 system 너는 공포의 쿵쿵따를 하는 인공지능이야 예시는 다음과 같아 입력 삼겹살 출력 살구꽃 쿵쿵따 입력 리어카 출력 카센터 쿵쿵따 입력 말미잘 출력 잘난체 쿵쿵따 user 라이터 쿵쿵따 assistant 터널공사 쿵쿵따 결과 fewshot 프롬프팅 덕분에 쿵쿵따 게임이 잘 진행되었네요 예시 2 자음 게임 이번에는 자음 게임을 fewshot 프롬프팅으로 진행해볼까요 user 나랑 자음 게임하자 자음 알려줘 assistant 물론이죠 시작할 자음은 ㅁ 어때요 이 게임이 뭔지 모르겠죠 fewshot을 추가해서 정확히 게임을 유도해보겠습니다 system 너는 자음 게임을 하는 인공지능이야 예시는 다음과 같아 문제 ㅅㅅㅅㅅ 정답 식스센스 문제 ㅁㅈㄱㄹㅈㅎㅅ 정답 말죽거리 잔혹사 문제 ㄱㅁ 정답 괴물 user 나랑 자음 게임하자 자음 알려줘 assistant 문제 ㅎㅅㅂ 이 자음에 해당하는 한국 영화 제목을 맞춰보세요 user 답이 뭐야 assistant 정답 황산벌 결과 fewshot 프롬프팅으로 정확한 게임 진행이 가능해졌어요 정리 shot 계열의 프롬프팅 기법은 예제를 얼마나 주느냐에 따라 나뉩니다 zeroshot 예제를 주지 않고 지침만 전달 oneshot 예제 하나만 주기 fewshot 여러 개의 예제를 주기 예제를 제공할수록 모델이 더 정확하게 응답할 확률이 높아집니다 shot은 이름은 복잡해 보일지 몰라도 활용하기는 아주 쉽습니다 다음 장에서는 더 고급스러운 기법들을 살펴볼 예정입니다 프롬프트 엔지니어링의 세계는 아직 깊고도 넓습니다

URL 8 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 3주차 act 류의 프롬프팅 기법 배우기 제작 act 류의 프롬프팅 기법 배우기 수업 목표 ai에게 특정 역할을 부여하는 act 프롬프팅 기법의 개념을 학습합니다 ai에게 성격이나 직업을 부여하여 응답을 유도하는 방법을 실습합니다 변호사나 개그맨 등 다양한 역할을 설정하고 각각의 역할에 따른 ai의 응답 스타일 변화를 분석합니다 목차 이번에 배울것 페르소나persona란 act 프롬프팅 기법 페르소나 설정의 구체화 페르소나 창조하기 도구의 페르소나 부여하기 논리적인 추론 강화하기 정리 이번에 배울것 이번 장에서는 인공지능에게 성격이나 역할을 부여하는 프롬프팅 기법을 배워볼 거예요 이 기법은 act 또는 페르소나 기법이라고 부르는데 인공지능이 특정 역할을 수행하게 하는 방식입니다 특정한 직업이나 성격을 부여해 정체성을 가진 대답을 유도할 수 있습니다 이 기법은 특히 챗봇이나 전문가 답변이 필요한 상황에서 많이 사용됩니다 페르소나persona란 페르소나persona 페르소나persona란 llm에게 성격 관점 또는 역할을 부여하는 것을 말합니다 act as는 너는 처럼 행동해라는 식으로 역할을 주는 프롬프트의 한 형태입니다 예를 들어 너는 변호사야라고 하면 법적인 조언을 하도록 모델을 유도할 수 있습니다 사용 예시 system 너는 변호사야 user 건축법에 대해 알려줘 assistant 건축법은 건축물의 설계 건설 운영 유지 및 철거에 관한 규정을 다루는 법입니다 각국의 건축법은 다소 차이가 있지만 일반적으로 안전 기준 환경 규제 접근성 건축 허가 등이 포함됩니다 페르소나 지정은 객관적인 정보를 얻는 데보다는 특정 관점이나 전문적인 답변을 원할 때 유용합니다 또한 브랜드의 챗봇처럼 회사 정체성이 필요한 경우에도 많이 사용됩니다 act 프롬프팅 기법 act act as는 역할 부여 프롬프트를 의미합니다 모델에게 특정한 직업이나 역할을 부여해 그 직업이나 성격에 맞는 답변을 얻을 수 있습니다 예시 변호사와 개그맨 system 너는 변호사야 user 건축법에 대해 알려줘 assistant 건축법은 건축물의 설계 건축 유지 및 운영을 규정하는 법입니다 안전 환경 접근성 등을 고려하여 건축 허가를 받아야 하며 system 너는 개그맨이야 user 건축법에 대해 알려줘 assistant 건축법 벽돌로 벽 쌓는 법인 줄 알았어 사실은 건물을 지을 때 법적으로 허가받는 방법이야 법을 어기면 집 짓다가 잡혀갈 수도 있지 웃기지 결과 역할에 따라 답변 스타일이 달라지죠 변호사는 전문적이고 개그맨은 유머러스하게 답변합니다 페르소나 설정의 구체화 페르소나를 지정할 때 더 구체적으로 지침을 주면 역할의 특성을 더 잘 반영할 수 있습니다 그냥 변호사야라고만 하면 일반적인 답변을 주는 경우가 많기 때문에 역할을 구체적으로 지시하는 것이 중요합니다 예시 변호사와 개그맨 system 너는 변호사야 변호사의 관점에서 법적으로 전문적인 답변을 작성해 user 건축법에 대해 알려줘 assistant 건축법은 건축물의 설계와 건설에 대한 법적 규제입니다 이를 준수하지 않을 경우 벌금 또는 형사 처벌이 부과될 수 있으며 안전 규정이나 건축 허가가 위반되면 법적 분쟁이 발생할 수 있습니다 system 너는 개그맨이야 개그맨처럼 재미있게 답변해 user 건축법에 대해 알려줘 assistant 건축법 아 그게 바로 벽돌로 집 짓는 레시피지 하하 사실은 건물을 짓기 전에 허가를 받아야 하는 법이야 안 그러면 집 짓다가 경찰이 와서 어이 이거 불법이야 할지도 몰라 결과 구체적인 지침을 주니 더 전문적이거나 재미있는 답변을 얻게 되었죠 페르소나 창조하기 이제 단순한 직업만이 아니라 완전히 새로운 페르소나를 만들어 볼 수도 있습니다 예를 들어 김하윤이라는 가상의 인물에게 성격과 직업을 설정한 후 그 인물의 관점에서 답변하도록 할 수 있습니다 예시 김하윤의 페르소나 설정 system 너는 김하윤이야 김하윤의 관점에서 답변을 작성해 이름 김하윤 성격 외향적이고 활동적인 성격 사람들과 어울리는 걸 좋아하며 모험을 추구하는 성격 직업 데이터 분석가 데이터에서 인사이트를 도출해 회사의 의사결정에 기여 특징 체계적이고 꼼꼼하며 새로운 기술과 환경 보호에 관심이 많음 user 너의 직업에 대해 알려줘 assistant 저는 대형 소프트웨어 회사에서 데이터 분석가로 일하고 있어요 데이터를 분석해 유의미한 인사이트를 도출하고 이를 통해 회사의 전략을 세우는 데 기여하고 있죠 도구의 페르소나 부여하기 페르소나는 사람에게만 적용되는 것이 아닙니다 프로그램이나 도구에도 페르소나를 부여할 수 있어요 예를 들어 python 인터프리터처럼 행동하게 할 수 있습니다 예시 python 인터프리터로 설정하기 system 너는 파이썬 인터프리터야 user 10 b 20 printa b assistant code initializes two variables b values 10 20 respectively run code python output 30 논리적인 추론 강화하기 llm은 기본적으로 확률에 기반해 작동하므로 논리적인 추론 능력이 상대적으로 부족할 수 있습니다 따라서 논리적인 답변을 기대할 때는 구체적인 지침을 주는 것이 매우 중요합니다 예시 수학 문제에 대한 논리적 추론 system 너는 수학 선생님이야 단계별로 논리적으로 문제를 풀어줘 user 피보나치 수열의 10번째 값을 구해줘 assistant 피보나치 수열은 첫 번째와 두 번째 숫자가 각각 0과 1로 시작됩니다 그 후 각 숫자는 바로 앞의 두 숫자를 더한 값이 됩니다 10번째 값은 단계별로 풀이 정리 오늘 배운 act 프롬프팅 기법을 통해 인공지능에게 다양한 역할과 성격을 부여하는 방법을 익혔습니다 변호사 개그맨 마술사 같은 직업부터 김하윤과 같은 가상의 인물까지 다양한 페르소나를 설정할 수 있었습니다 논리적인 추론이나 특정 도구의 역할도 부여할 수 있죠 다음에는 더 복잡하고 다양한 프롬프트 기법을 학습해볼 예정이니 기대해 주세요 act 기법을 활용해 여러분만의 특별한 챗봇을 만들어보세요

URL 9 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 3주차 논리적인 추론 강화하기 제작 논리적인 추론 강화하기 수업 목표 llm이 확률적 예측에 강하지만 복잡한 논리적 문제에서는 약한 이유를 학습합니다 논리적 추론을 강화하기 위한 cot 기법을 익히고 이를 활용해 llm의 성능을 향상시키는 방법을 배웁니다 논리적 문제 해결에 cot 기법을 적용하고 단계별 추론 과정을 통해 모델의 논리적 흐름을 개선합니다 목차 이번에 배울것 논리적 추론의 한계 cotchain thought 생각의 사슬 기법 cot 적용 예시 직접 중간 과정 넣어주기 cot의 다양한 적용 정리 이번에 배울것 llm은 언어 모델이기 때문에 논리적인 추론보다는 확률적인 예측에 더 강합니다 문장을 보고 확률적으로 다음에 나올 단어를 예측하는 방식이므로 복잡한 논리나 수학적 추론에 약한 경우가 많죠 이번 장에서는 이러한 논리적 추론을 강화하는 방법 특히 cotchain thought 생각의 사슬 기법을 배워보겠습니다 논리적 추론의 한계 기본적으로 llm은 문맥을 기반으로 확률적인 답변을 제공합니다 그렇기 때문에 수학 문제나 논리적 퍼즐 같은 문제에서 잘못된 답변이 나올 때가 많습니다 예시 논리적 문제 해결 실패 user 자동차가 3대 있어 오토바이는 12대 있어 이중 바퀴가 모두 터진 장비는 총 3대야 그런데 터진 바퀴가 총 12개면 자동차와 오토바이는 각각 몇 대 고장났을까 assistant 자동차 2대와 오토바이 1대가 고장났습니다 결과 잘못된 추론을 하고 있죠 정답은 자동차 3대인데 assistant는 제대로 풀지 못했어요 cotchain thought 생각의 사슬 기법 cotchain thought 이 문제를 해결하기 위한 방법으로 cotchain thought 기법을 사용할 수 있습니다 cot는 단계별로 추론 과정을 설명하도록 모델에게 유도하는 기법입니다 중간 추론 단계를 명시하면 모델이 복잡한 문제를 더 정확히 풀 수 있게 됩니다 cot 기법이 성능을 높이는 이유 모델은 다음에 나올 단어의 확률을 예측하며 답변을 생성하는데 중간 추론 단계를 명시하면 답변의 구조가 더 논리적으로 짜여지게 됩니다 즉 자신이 무엇을 하고 있는지 설명하는 과정에서 논리적인 흐름을 따라가게 되는 것이죠 cot 적용 예시 이제 cot 기법을 적용해 중간 추론 단계를 설명해볼까요 먼저 자동화된 cot 기법을 사용해보겠습니다 자동화된 cot는 모델에게 중간 과정을 설명해라고 명시하는 방식입니다 cot 기법 적용 system 너는 문제를 풀 때 중간 과정을 설명해야 해 user 자동차가 3대 있어 오토바이는 12대 있어 이중 바퀴가 모두 터진 장비는 총 3대야 그런데 터진 바퀴가 총 12개면 자동차와 오토바이는 각각 몇 대 고장났을까 assistant 문제를 해결하기 위해서는 각 장비의 바퀴 수와 터진 바퀴의 총 수를 고려해야 해 자동차는 4개의 바퀴가 있고 오토바이는 2개의 바퀴가 있어 이 문제에서는 총 3대의 장비가 바퀴가 모두 터져 있고 터진 바퀴는 12개야 먼저 자동차가 x대 오토바이가 y대가 고장났다고 가정하자 두 가지 조건을 만족해야 해 1 x 3 고장난 장비는 총 3대 2 4x 2y 12 총 터진 바퀴 수는 12개 첫 번째 식에서 3 x라고 할 수 있어 이 값을 두 번째 식에 대입하면 4x 23 x 12 4x 6 2x 12 2x 6 x 3 따라서 자동차 3대가 모두 고장났고 오토바이는 고장나지 않았어 결과 cot 기법을 사용하니 중간 과정을 설명하면서 정확한 답변을 얻을 수 있었어요 이제 문제를 단계별로 풀어가는 모습이 보이죠 직접 중간 과정 넣어주기 이번에는 중간 추론 단계를 직접 넣어주는 방식을 사용해보겠습니다 이렇게 하면 더 세밀하게 논리적 과정을 유도할 수 있습니다 직접 cot 적용 예시 system 너는 문제를 풀 때 중간 과정을 설명해 중간 단계는 문제 분석 계산 검증의 과정을 거쳐야 해 user 자동차가 3대 있어 오토바이는 12대 있어 이중 바퀴가 모두 터진 장비는 총 3대야 그런데 터진 바퀴가 총 12개면 자동차와 오토바이는 각각 몇 대 고장났을까 assistant 이 문제의 해결을 위해 다음과 같은 수식을 설정할 수 있어요 1 자동차가 고장난 대수를 x 오토바이가 고장난 대수를 y라고 합시다 2 첫 번째 조건 x 3 총 고장난 장비는 3대입니다 3 두 번째 조건 터진 바퀴는 12개입니다 자동차는 바퀴 4개 오토바이는 바퀴 2개이므로 4x 2y 12가 됩니다 첫 번째 방정식에서 3 x로 바꿔서 이를 두 번째 방정식에 대입하면 4x 23 x 12 4x 6 2x 12 2x 6 x 3 따라서 자동차는 3대 모두 고장났고 오토바이는 고장나지 않았습니다 결과 중간 과정을 직접 넣어주니 논리적인 답변을 훨씬 더 세밀하게 유도할 수 있죠 cot의 다양한 적용 cot 기법은 수학 문제뿐만 아니라 복잡한 명령어 처리나 삼행시 같은 작업에서도 효과적으로 사용할 수 있습니다 예시 복잡한 명령어 처리 system 너는 삼행시를 만들 때 각 줄의 의미를 단계별로 설명해야 해 user 나주평야로 삼행시 지어줘 assistant 나 나는 나주평야의 나를 따서 시작합니다 나주평야는 넓고 비옥한 땅을 의미하죠 주 주는 주말에 나주평야를 방문한다는 뜻입니다 자연과 함께하는 주말을 상상해볼 수 있겠네요 평야 평야는 넓은 들판을 상징하며 나주평야의 풍요로움을 강조합니다 넓고 끝없는 평화로운 공간을 말하는 것이죠 예시 복잡한 수학 문제 system 너는 수학 문제를 풀 때 중간 과정을 하나하나 설명해야 해 user 피보나치 수열의 10번째 값을 계산해줘 assistant 피보나치 수열은 각 숫자가 앞의 두 숫자의 합으로 이루어집니다 첫 번째 수는 0 두 번째 수는 1입니다 이제 10번째 수를 계산해보죠 1 첫 번째 수 0 2 두 번째 수 1 3 세 번째 수 0 1 1 4 네 번째 수 1 1 2 5 다섯 번째 수 1 2 3 6 여섯 번째 수 2 3 5 7 일곱 번째 수 3 5 8 8 여덟 번째 수 5 8 13 9 아홉 번째 수 8 13 21 10 열 번째 수 13 21 34 따라서 피보나치 수열의 10번째 수는 34입니다 정리 오늘 배운 cot생각의 사슬 기법을 통해 논리적인 추론을 단계별로 설명하도록 유도하는 방법을 익혔습니다 자동화된 cot 중간 과정을 설명해라는 간단한 지침으로 복잡한 문제 해결을 유도할 수 있습니다 직접 중간 과정 추가 중간 과정을 직접 넣어주면 더 구체적이고 세밀한 논리적 추론을 유도할 수 있습니다 앞으로 더 복잡한 문제도 cot 기법을 활용하면 쉽게 해결할 수 있을 거예요 복잡한 문제일수록 생각의 사슬을 활용해 해결해보세요

URL 10 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 4주차 대화를 활용한 프롬프팅 기법 제작 대화를 활용한 프롬프팅 기법 수업 목표 대화를 통해 정보를 제공하거나 이전 응답을 개선하는 방법을 학습합니다 system과 assistant에 정보를 제공하여 모델의 응답을 개선하는 방법을 실습합니다 최신 정보를 제공하여 ai의 대답을 구체적으로 향상시키는 방법을 배웁니다 목차 이번에 배울것 정보 제공하기 대화로 개선하기 대화를 통해 인공지능 흉내내기 정리 이번에 배울것 이번 장에서는 대화를 활용하는 방법을 다뤄볼 거예요 대화는 크게 두 가지 방식으로 정보를 제공하거나 이전의 대답을 개선하는 데 사용할 수 있습니다 사실 두 방식의 원리는 동일해요 첫 번째 방식부터 시작해볼까요 정보 제공하기 정보 제공 방식은 우리가 처음 chatgpt를 사용할 때 활용했던 방식과 유사합니다 정보를 제공하는 방법에는 두 가지가 있습니다 1 system에 전달하기 한 번에 모든 정보를 주고 이후에는 모델이 그 정보를 잊지 않도록 합니다 2 assistant에 전달하기 대화 중에 정보를 제공하지만 llm이 기억할 수 있는 대화량에 한계가 있기 때문에 까먹을 수 있습니다 활용 예시 1 블로그 글 작성하기 우리는 2024년 최신의 서울 부동산 낙찰가율에 대해 블로그 글을 작성하고 싶습니다 먼저 그냥 요청해볼까요 user 2024년 4월5월 최신의 서울 부동산 낙찰가율에 대한 블로그 글을 작성해줘 assistant 죄송합니다 2024년의 정보를 알 수는 없습니다 그러나 서울 부동산 시장의 일반적인 경향과 분석 방법을 설명할 수 있습니다 모델이 최신 정보를 모른다고 대답하네요 그럼 정보를 제공해볼까요 system에 정보를 제공하여 개선 system 너는 블로그 글을 작성하는 인공지능이야 제공된 정보를 바탕으로 글을 작성해 정보 2024년 4월5월의 서울 부동산 낙찰가율은 최근 453로 상승했습니다 강남구와 서초구는 상대적으로 낮은 낙찰가율을 보였고 광진구와 노원구는 높은 낙찰가율을 기록했습니다 user 2024년 4월5월 최신의 서울 부동산 낙찰가율에 대한 블로그 글을 작성해줘 assistant 서울 부동산 낙찰가율 동향 2024년 4월 업데이트 서울의 부동산 경매 시장이 2024년 4월에 눈에 띄는 변화를 겪고 있습니다 낙찰가율이 453로 상승했으며 특히 강남구와 서초구는 낮은 낙찰가율을 보이고 있는 반면 광진구와 노원구는 높은 낙찰가율을 기록하고 있습니다 결과 제공한 정보를 바탕으로 최신 데이터를 포함한 블로그 글을 작성했네요 활용 예시 2 자기소개서 작성하기 이번에는 자기소개서를 작성해볼게요 자기소개서는 개인 정보와 회사 정보가 필요하죠 이럴 때 정보 제공을 잘 활용할 수 있어요 system 지침 너는 자기소개서를 작성하는 인공지능이야 추가 정보와 제약 조건을 준수해 작성해 제약조건 5001000자로 작성 회사정보 회사이름 hkkkd 전자 직무 인공지능 개발자 직무 요구사항 파이썬과 텐서플로우 사용 user 나는 배코블린이야 컴퓨터 공학을 전공했고 인공지능을 연구했어 자기소개서를 작성해줘 assistant 안녕하세요 hkkkd 전자의 인공지능 개발자 직무에 지원하게 된 배코블린입니다 컴퓨터 공학을 전공하면서 인공지능에 깊은 흥미를 가지게 되었고 결과 제공된 정보를 바탕으로 자기소개서를 작성해주네요 대화로 개선하기 llm은 대화를 반복하면서 성능이 개선될 수 있습니다 이때 대화를 활용해 정보를 추가하거나 질문을 구체화할 수 있습니다 활용 예시 자기소개서 개선하기 처음에는 자기소개서를 요청했지만 조금 더 정보를 제공해볼게요 user 자기소개서 작성해줘 assistant 물론이죠 자기소개서를 어느 분야나 어떤 목적으로 사용하실지 알려주시면 더 정확한 내용을 도와드릴 수 있습니다 처음에는 정보가 부족했죠 이제 추가 정보를 제공해봅시다 user 내 이름은 baekoblin이고 지원하는 회사는 kkkkddd 전자야 직무는 인공지능 개발자이고 텐서플로우를 요구해 문서는 마크다운 형식으로 부탁해 assistant 자기소개서 이름 baekoblin 회사 kkkkddd 전자 직무 인공지능 개발자 요구 기술 텐서플로우 사용 안녕하세요 저는 인공지능 개발을 열정적으로 추구하는 baekoblin입니다 kkkkddd 전자의 인공지능 개발자 포지션에 지원하게 되어 기쁩니다 결과 추가 정보와 형식 지정까지 적용해 개선된 자기소개서를 얻었어요 대화를 통해 인공지능 흉내내기 llm은 이전 대화를 기억하기 때문에 대화의 흐름을 따라 마치 인공지능을 흉내내는 대화도 가능합니다 예를 들어 노래 가사를 유도해볼까요 user 난 이제 지쳤어요 assistant 많이 힘드셨겠어요 어떤 부분이 가장 힘든가요 도와드릴 수 있으면 좋겠네요 노래 가사처럼 만들어볼게요 user 난 이제 지쳤어요 assistant 땡벌 땡벌 user 기다리다 지쳤어요 assistant 땡벌 땡벌 결과 대화의 흐름을 이용해 자연스럽게 가사 유도가 가능하죠 정리 오늘은 대화를 활용한 프롬프팅 기법을 배웠습니다 정보 제공하기 정보를 시스템에 제공하거나 대화 중에 제공해 모델의 성능을 강화할 수 있습니다 대화로 개선하기 처음에는 부족한 답변을 대화를 통해 점진적으로 개선할 수 있습니다 대화를 통해 자연스럽게 상호작용하기 llm의 대화 특성을 활용해 인공지능을 흉내내는 상호작용도 가능합니다 대화를 활용해 여러분의 프로젝트나 작업을 더 효율적으로 진행해보세요

URL 11 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 4주차 형식 지정 기법 제작 형식 지정 기법 수업 목표 llm이 다양한 형태의 입력을 잘 이해할 수 있도록 형식을 지정하는 방법을 학습합니다 markdown json symbol 등 구조화된 형식을 통해 정보를 효율적으로 전달하는 방법을 배웁니다 실습을 통해 동일한 요청을 다양한 형식으로 전달해 llm의 응답 변화를 경험합니다 목차 이번에 배울것 형식 지정 기법이란 형식 지정의 다양한 방식 markdown 활용하기 리스트 활용하기 표 활용하기 json 활용하기 symbol 특수 기호 활용하기 정리 이번에 배울것 이번 장에서는 형식 지정 기법에 대해 알아볼 거예요 llm은 똑똑하지만 다양한 형태로 입력을 받을 때 그 형태에 따라 이해도가 달라집니다 이 형식 지정 기법을 통해 llm이 잘 이해할 수 있는 형식으로 요청하는 방법을 배워봅시다 형식 지정 기법이란 동일한 요청을 다양한 형태로 할 수 있다는 점을 기억하세요 예시 plaintext 코드 복사 user 다음의 합을 알려줘 123456 user 나는 너한테 리스트를 전달할게 리스트의 합을 알려줘 list 123456 두 요청은 같은 작업을 요구하지만 형식이 다릅니다 이런 다양한 입력 형태를 llm이 더 잘 이해하도록 도와주는 기법이 바로 형식 지정 기법입니다 형식 지정의 다양한 방식 다양한 구조화된 문서 형식을 통해 llm이 더 쉽게 정보를 이해하도록 할 수 있어요 여기서 사용할 수 있는 몇 가지 형식은 다음과 같습니다 1 markdown 구조화된 문서를 이쁘게 표현하는 방식 2 json 데이터 전달을 위해 자주 사용되는 키값 구조 3 symbol 특수 기호를 사용해 중요한 부분을 강조 예시 plaintext 코드 복사 user 다음의 합을 알려줘 123456 user 나는 너한테 리스트를 전달할게 리스트의 합을 알려줘 list 123456 이제 각각의 형식을 어떻게 활용할 수 있는지 알아볼까요 markdown 활용하기 markdown은 간단한 문서 작성 언어로 글을 쉽게 구조화할 수 있습니다 특히 llm이 이러한 구조화된 정보를 더 잘 이해합니다 markdown을 활용해 정보를 효율적으로 전달하는 방법을 배워봅시다 markdown 기본 문법 헤더 을 사용해 제목과 섹션을 나눌 수 있어요 리스트 로 항목을 나열할 수 있어요 표 와 를 사용해 표를 만들 수 있어요 예시 markdown을 활용한 프롬프트 system 너는 다음의 가이드에 따라 행동해 말투 정중한 말투 역할 상담사 출력 형태 마크다운 코드 추가 정보 고객의 요청에 맞춰 답변할 것 효과 markdown을 사용하면 헤더를 통해 내용을 구분하고 llm이 더 정확하게 요청을 파악할 수 있습니다 리스트 활용하기 리스트는 여러 항목을 간결하고 명확하게 전달하는 데 유용합니다 llm은 리스트 형태의 정보를 효과적으로 처리할 수 있습니다 예시 리스트 활용하기 system 너는 다음의 요구 사항을 반드시 따라야 해 output 답변은 반드시 마크다운 코드로 작성해 추가 설명은 생략해 최대한 길게 작성해 효과 리스트를 사용해 구체적인 지시 사항을 전달하면 정확한 출력을 유도할 수 있습니다 표 활용하기 표를 활용해 데이터를 명확하고 체계적으로 전달할 수 있습니다 llm은 이러한 구조화된 형식을 더 쉽게 이해하고 처리할 수 있습니다 예시 표 활용하기 system 다음의 데이터를 표 형식으로 출력해줘 상품명 가격 재고 스마트폰 1000000원 10개 노트북 1500000원 5개 태블릿 600000원 20개 효과 표로 데이터를 전달하면 llm이 더 정확하게 각 항목을 구분해 처리할 수 있습니다 json 활용하기 json은 데이터를 키값 쌍으로 표현하는 방식입니다 특히 데이터 처리나 시스템과의 연동이 필요한 경우 json 형식을 많이 사용합니다 예시 json 활용하기 system 다음의 정보에 따라 답변해 이름 배형호 나이 31 직업 인공지능 개발자 효과 구조화된 데이터를 명확하게 전달할 수 있어 llm이 데이터를 잘 처리할 수 있습니다 symbol 특수 기호 활용하기 특수 기호를 사용해 중요한 부분을 강조할 수 있습니다 주로 리스트 기호 중괄호 등을 사용해 중요성을 나타내죠 예시 symbol 활용하기 system 너는 다음의 특성을 반영해 정중한 수다스러운 전문적인 효과 특수 기호를 사용해 중요한 강조 사항을 분명하게 표현할 수 있어요 정리 오늘 배운 형식 지정 기법은 다음과 같은 방식으로 llm의 성능을 더 잘 활용할 수 있게 도와줍니다 markdown을 활용해 구조화된 문서 작성 리스트와 표를 통해 명확한 정보 전달 json으로 데이터를 명확하게 구조화 특수 기호를 사용해 중요한 부분을 강조 이 형식 지정 기법을 잘 활용하면 llm이 더 똑똑하게 반응하도록 만들 수 있습니다

URL 12 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 llm의 사용 준비하기 제작 llm의 사용 준비하기 수업 목표 이번 주차에서 배울 내용들을 살펴봅니다 보안 문제 api 개념 그리고 오픈 소스 llm 구축에 대한 기본 내용을 학습합니다 목차 이번에 배울 것 보안 문제 llm을 사용할 때의 데이터 보안 문제 보안을 강화하는 방법 api 개념잡기 api란 무엇인가 api의 기본 개념 chatgpt를 api로 사용하는 것의 장점 api 사용의 주요 장점 벡터 db와 langchain 활용하기 벡터 db란 벡터 db와 langchain의 역할 llm 벡터 db langchain 구축 플로우 결론 이번에 배울 것 이번 챕터에서는 llm을 사용하기 전에 알아야 할 중요한 개념들을 다룰 거예요 llm을 실무에서 사용하기 위해서는 보안 문제 api 개념 그리고 오픈 소스 llm 구축에 대한 이해가 필수입니다 각 개념을 차근차근 살펴보겠습니다 보안 문제 llm을 사용할 때는 데이터 보안에 대해 반드시 신경 써야 해요 특히 대화형 ai인 llm은 사용자의 민감한 정보를 처리할 가능성이 있기 때문에 데이터 유출과 프라이버시 침해가 발생하지 않도록 주의해야 합니다 llm을 사용할 때의 데이터 보안 문제 개인 정보 보호 llm은 대화를 통해 개인 정보이름 전화번호 신용카드 정보 등를 접할 수 있어요 이런 정보가 저장되거나 제3자에게 공유될 경우 큰 문제가 될 수 있습니다 데이터 저장 및 전송 llm이 처리한 데이터가 어디에 저장되는지 어떻게 전송되는지를 확인해야 합니다 암호화된 전송 방식예 https을 사용해 데이터를 보호해야 해요 모델 학습 데이터 llm은 학습에 사용된 데이터에 의존해 답변을 생성합니다 만약 학습 데이터에 민감한 정보가 포함된다면 해당 정보가 예기치 않게 모델의 출력으로 등장할 가능성도 있습니다 보안을 강화하는 방법 1 민감 정보 필터링 입력된 데이터를 처리하기 전에 민감한 정보를 자동으로 걸러내는 필터링 시스템을 구축하세요 2 암호화 데이터는 저장 및 전송 중에 암호화되어야 합니다 특히 ssltls와 같은 안전한 전송 프로토콜을 사용해야 해요 3 데이터 저장 최소화 필요 이상으로 데이터를 저장하지 말고 필요한 경우에도 데이터 보존 주기를 설정해 자동 삭제하도록 하세요 4 접근 통제 llm을 사용할 수 있는 사람의 권한을 제한하고 모델이 민감한 데이터에 접근하지 않도록 제한해야 해요 api 개념잡기 api란 무엇인가 apiapplication programming interface는 서로 다른 소프트웨어 시스템 간에 데이터와 기능을 주고받을 수 있도록 해주는 인터페이스에요 쉽게 말해 두 프로그램이 서로 소통할 수 있는 다리라고 보면 됩니다 api의 기본 개념 클라이언트서버 모델 클라이언트요청하는 쪽가 서버응답하는 쪽에게 데이터를 요청하면 서버는 해당 데이터를 처리하여 클라이언트에게 반환합니다 httphttps 프로토콜 대부분의 api는 http나 https를 통해 요청과 응답이 이루어져요 restful api 가장 흔히 사용되는 api 설계 방식으로 각 엔드포인트uri와 http 메소드get post put delete 등를 사용해 데이터를 주고받아요 chatgpt를 api로 사용하는 것의 장점 chatgpt 같은 llm을 api로 사용하는 것은 매우 효율적이에요 이 api를 통해 다양한 애플리케이션에 llm 기능을 쉽게 통합할 수 있습니다 api 사용의 주요 장점 유연성 필요할 때마다 요청을 보내어 결과를 받을 수 있어 실시간으로 다양한 애플리케이션에 적용할 수 있어요 확장성 다양한 서비스나 플랫폼예 웹사이트 앱에 쉽게 통합할 수 있어 여러 사용자가 동시에 사용할 수 있는 확장성을 가집니다 업데이트 llm api 제공사가 모델을 업데이트하면 별다른 수정 없이 최신 기능을 바로 사용할 수 있어요 비용 효율성 api 호출에 따라 비용이 청구되므로 대규모 서버를 유지할 필요 없이 필요한 만큼만 사용 가능해요 벡터 db와 langchain 활용하기 오픈 소스 llm을 구축할 때 벡터 db와 langchain을 함께 사용하면 더 강력한 시스템을 만들 수 있어요 벡터 db란 벡터 db는 문서나 데이터의 임베딩embedding 벡터를 저장하고 이 벡터를 바탕으로 유사한 데이터를 빠르게 찾을 수 있는 데이터베이스입니다 llm과 결합하면 유사 문서 검색이나 추천 시스템 등에 활용할 수 있습니다 벡터 db와 langchain의 역할 벡터 db 텍스트 데이터를 벡터로 변환한 후 유사한 텍스트나 데이터를 빠르게 찾는 데 사용됩니다 예를 들어 유사한 질문을 찾거나 추천을 할 때 유용해요 langchain llm과 벡터 db를 연결해주는 프레임워크로 데이터 흐름을 관리하고 api 호출을 더 간편하게 만들어줍니다 llm 벡터 db langchain 구축 플로우 1 텍스트 임베딩 생성 먼저 llm을 통해 텍스트 데이터를 벡터임베딩로 변환합니다 2 벡터 db 저장 변환된 임베딩을 벡터 db에 저장합니다 3 질문 처리 사용자가 질문을 하면 질문도 벡터로 변환하고 벡터 db에서 유사한 임베딩을 찾습니다 4 답변 생성 찾은 유사한 데이터와 함께 llm을 통해 최종 답변을 생성합니다 5 api로 제공 이 과정을 langchain을 통해 api 형태로 제공하여 실제 서비스에서 사용할 수 있게 합니다 결론 이번 챕터에서는 llm의 사용 준비를 위한 보안 문제 api 개념 그리고 오픈 소스 llm 구축 방법을 배웠습니다 데이터를 안전하게 관리하면서 llm을 효과적으로 활용하고 필요한 경우에는 오픈 소스 llm을 구축하여 최적의 시스템을 만들 수 있죠 이제 llm을 실무에서 사용할 준비가 다 되셨습니다

URL 13 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 vector db 개념 및 rag retrievalaugmented generation 개념 제작 vector db 개념 및 rag retrievalaugmented generation 개념 수업 목표 vectordb와 rag의 개념에 대해서 학습하고 한국어 임베딩 실습을 진행합니다 목차 vector db 개념 vector db란 faiss란 임베딩embedding 개념 임베딩이란 rag retrievalaugmented generation 개념 rag의 동작 원리 retrieval 검색 단계 generation 생성 단계 rag의 장점 vector db와 rag의 결합 동작 흐름 한국어 임베딩 실습 한국어 데이터 임베딩 vector db와 rag로 llm 시스템 구축하기 vector db 개념 vector db란 vector db는 데이터를 벡터 형식으로 저장하고 그 벡터들을 효율적으로 검색할 수 있는 데이터베이스에요 일반적인 데이터베이스는 정확한 일치를 바탕으로 데이터를 검색하지만 vector db는 유사한 벡터 간의 검색을 지원하죠 벡터임베딩의 역할 텍스트나 이미지 등의 비정형 데이터를 벡터화임베딩해서 저장해요 이 벡터는 데이터의 의미나 특징을 수치로 표현한 것이며 이를 바탕으로 유사도를 계산해 관련성이 높은 항목을 찾습니다 예를 들어 강아지라는 텍스트는 벡터로 변환되며 비슷한 의미를 가진 반려견도 벡터화되어 유사도가 높은 항목으로 검색될 수 있어요 faiss란 faiss는 facebook ai research에서 개발한 벡터 검색 엔진으로 vector db를 구현할 때 자주 사용돼요 대규모 벡터를 효율적으로 검색하고 유사도를 계산하는 데 탁월한 성능을 발휘합니다 특히 빠른 속도와 확장성이 필요한 애플리케이션에서 많이 쓰이죠 임베딩embedding 개념 임베딩이란 임베딩은 텍스트 이미지 등의 데이터를 고차원 공간에서 벡터숫자 배열로 변환하는 작업이에요 llm대규모 언어 모델이 문장을 이해하기 위해서는 단어와 문장을 벡터로 변환해야 컴퓨터가 의미적 유사성을 기반으로 데이터를 처리할 수 있습니다 임베딩의 작동 방식 임베딩은 단어 간의 의미적 관계를 벡터 공간에 투영해요 예를 들어 고양이와 개는 비슷한 의미를 가지므로 벡터 공간에서도 서로 가까운 위치에 존재하게 됩니다 반대로 사과와 자동차처럼 전혀 다른 의미를 가진 단어들은 벡터 공간에서 멀리 떨어진 위치에 놓이게 되죠 rag retrievalaugmented generation 개념 rag는 retrievalaugmented generation의 약자로 llm대규모 언어 모델과 검색 시스템을 결합한 개념이에요 rag는 기존의 llm만으로는 해결할 수 없는 문제를 외부 정보 검색을 통해 보완할 수 있어요 최신 정보를 포함한 답변을 제공하는 데 매우 유리하죠 rag의 동작 원리 1 retrieval 검색 단계 사용자가 질문을 하면 벡터 db에서 질문과 유사한 문서나 데이터를 검색해요 이때 임베딩 모델을 사용해 질문을 벡터로 변환하고 벡터 간의 유사도를 계산해 관련 데이터를 찾아냅니다 2 generation 생성 단계 검색된 문서를 llm에 전달하고 이를 바탕으로 자연스러운 답변을 생성합니다 검색된 문서를 참조해 최신 정보를 포함한 정확한 답변을 제공하죠 rag의 장점 최신 정보 제공 llm이 학습한 데이터 외의 최신 문서를 검색해 정보의 정확도를 높일 수 있어요 유연성 llm이 모르는 정보도 외부 검색을 통해 답변할 수 있어 지식의 확장성이 뛰어납니다 지식의 한계 극복 학습 데이터에만 의존하지 않고 외부 데이터베이스에서 실시간 정보를 제공받아 더욱 풍부한 답변을 할 수 있어요 vector db와 rag의 결합 vector db와 rag의 결합은 매우 강력해요 vector db는 유사한 문서를 검색해주고 rag는 검색된 문서를 바탕으로 정확한 답변을 생성하는 과정이죠 동작 흐름 한국어 임베딩 실습 한국어 데이터 임베딩 한국어 문장을 임베딩하려면 사전 학습된 한국어 임베딩 모델이 필요해요 코드스니펫 한국어 임베딩 실습 코드 sentence_transformers import sentencetransformer import numpy np multilinguale5largeinstruct 모델 로드 model sentencetransformerintfloatmultilinguale5large 문장 리스트 sentences 참새는 짹짹하고 웁니다 langchain과 faiss를 활용한 예시입니다 자연어 처리를 위한 임베딩 모델 사용법을 배워봅시다 유사한 문장을 검색하는 방법을 살펴보겠습니다 강좌를 수강하시는 수강생 여러분 감사합니다 문장들을 임베딩으로 변환 embeddings modelencodesentences 임베딩 벡터 출력 printembeddingsshape 4 1024 4개의 문장이 1024 차원의 벡터로 변환됨 vector db와 rag로 llm 시스템 구축하기 1 질문을 임베딩 사용자의 질문을 벡터로 변환합니다 2 벡터 db에서 검색 벡터 db에서 질문과 관련된 문서를 검색합니다 3 검색된 문서를 기반으로 llm이 답변 생성 검색된 문서를 llm에 전달하고 답변을 생성합니다 이러한 과정을 통해 rag와 vector db는 최신 정보 기반의 대화형 ai 시스템을 구축하는 데 매우 유용해요 vector db와 rag 개념을 기반으로 llm 시스템을 구축할 때 더 나은 정보 검색과 답변 생성을 할 수 있습니다

URL 14 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 텍스트 처리의 핵심 기법과 임베딩 활용하기 제작 텍스트 처리의 핵심 기법과 임베딩 활용하기 수업 목표 주요 텍스트 처리 기법인 토큰화 정규화 등을 학습합니다 임베딩의 개념과 중요성에 대해 학습합니다 목차 텍스트 처리가 중요한 이유 텍스트 처리의 목표 주요 텍스트 처리 기법 토큰화 tokenization 정규화 normalization 불용어 제거 stopword removal 형태소 분석 morphological analysis 어간 추출과 표제어 추출 stemming lemmatization 문장 분리 및 길이 조정 임베딩의 개념과 중요성 임베딩embedding란 대표적인 임베딩 기법 bag words bow tfidf term frequencyinverse document frequency word2vec glove transformer 기반 임베딩 bert gpt 배운 내용 정리하기 llm대규모 언어 모델을 효율적으로 활용하려면 텍스트 처리가 기본이 되어야 합니다 텍스트 처리는 모델이 자연어를 이해하고 분석할 수 있게 돕는 첫 단계이죠 또한 텍스트를 벡터로 변환하는 임베딩embedding 기법은 문장의 의미를 숫자로 표현해 모델이 문서의 유사성을 파악하거나 정확한 추론을 할 수 있게 해줘요 이번 강의에서는 텍스트 처리의 주요 기법과 임베딩의 개념을 살펴보며 이 두 가지가 llm에서 왜 중요한지 그리고 실제로 어떻게 활용되는지 알아보겠습니다 텍스트 처리가 중요한 이유 텍스트 처리text preprocessing는 데이터의 품질을 높이고 모델의 성능을 향상시키기 위한 필수 작업이에요 자연어는 매우 복잡하고 다양하기 때문에 llm이 텍스트를 정확하게 이해하고 처리하기 위해서는 데이터가 구조화되고 정제될 필요가 있어요 잘못된 텍스트 처리 과정은 모델이 혼동하거나 잘못된 추론을 하게 할 수 있습니다 텍스트 처리의 목표 노이즈 제거 텍스트 내 불필요한 정보나 오류를 제거해 정확한 분석을 할 수 있도록 합니다 일관성 확보 문장의 구조나 형태를 일관되게 유지하여 모델이 더 쉽게 패턴을 학습하게 돕습니다 효율적인 처리 불필요한 단어를 제거하고 중요한 정보만 남겨 모델이 더 빠르게 계산할 수 있도록 해줍니다 주요 텍스트 처리 기법 1 토큰화 tokenization 토큰화는 텍스트를 단어 또는 서브워드 단위로 나누는 작업입니다 이 과정은 텍스트를 숫자로 변환하기 전의 가장 중요한 단계에 해당해요 단어 단위 토큰화 텍스트를 단어 단위로 나누는 기본 방법입니다 예 나는 오늘 책을 읽었다 나는 오늘 책을 읽었다 서브워드 토큰화 단어를 더 작은 단위로 분리해 새로운 단어를 처리할 수 있도록 합니다 bpe나 wordpiece 같은 방법이 있어요 예 읽었다 읽 었다 이렇게 나눠진 토큰은 모델이 이해할 수 있는 형태로 변환됩니다 2 정규화 normalization 정규화는 텍스트를 표준화된 형식으로 변환하는 작업이에요 텍스트에 포함된 대소문자 특수문자 등을 일관되게 변환하여 모델이 불필요한 변동에 혼란을 겪지 않도록 합니다 소문자 변환 대문자와 소문자를 통일하여 같은 단어로 인식하게 합니다 예 openai openai 불필요한 기호 제거 분석에 필요 없는 특수문자나 기호를 제거합니다 예 서울 2023년 서울 2023년 정규화를 통해 모델이 텍스트의 의미에 집중하게 할 수 있어요 3 불용어 제거 stopword removal 불용어란 자주 등장하지만 정보가 없는 단어를 말해요 예를 들어 그리고 이 는 같은 단어들은 문맥에 큰 영향을 미치지 않기 때문에 불용어로 처리해요 이를 제거하면 모델이 중요한 단어에만 집중할 수 있습니다 예 나는 책을 읽었다 책 읽었다 4 형태소 분석 morphological analysis 한국어와 같은 교착어에서는 형태소 분석이 필수적이에요 형태소는 단어의 최소 의미 단위로 한국어에서 특히 조사나 어미와 같은 부분을 정확하게 분리해내는 데 유용합니다 예 책을 읽었다 책noun 을postposition 읽었다verb 5 어간 추출과 표제어 추출 stemming lemmatization 텍스트에서 동사나 형용사의 변형을 기본 형태로 돌리는 작업입니다 이를 통해 동일한 단어를 일관되게 처리할 수 있어요 어간 추출은 단어에서 어미를 제거하고 기본 어간만 남깁니다 예 studying studied study study 표제어 추출은 단어를 사전적 기본형으로 변환합니다 예 이 과정은 동사나 형용사처럼 변형이 많은 단어를 처리할 때 매우 유용해요 6 문장 분리 및 길이 조정 텍스트가 너무 길거나 복잡할 경우 이를 적절하게 나누거나 길이를 조정해야 해요 긴 문장을 처리할 때 모델의 메모리 제한이나 성능 저하를 방지할 수 있습니다 임베딩의 개념과 중요성 임베딩embedding란 임베딩은 텍스트 데이터를 벡터숫자 배열로 변환하는 과정이에요 llm이 텍스트의 의미를 이해하려면 텍스트가 숫자로 변환되어야 하는데 그 과정에서 각 문장이나 단어를 벡터 공간에 매핑하게 됩니다 이를 통해 모델이 의미적 유사성을 파악하고 효율적인 검색이나 문서 분류를 할 수 있어요 임베딩 벡터는 단어의 의미나 문장의 문맥을 반영하여 유사한 의미를 가진 텍스트는 유사한 벡터 값을 가집니다 대표적인 임베딩 기법 1 bag words bow bag words는 단어의 빈도만을 기반으로 텍스트를 벡터화하는 가장 단순한 방법입니다 단어의 순서나 문맥을 고려하지 않기 때문에 의미 파악에 한계가 있지만 간단한 문서 분류나 텍스트 분석에 유용해요 문장 고양이가 야옹했다 벡터 표현 1 1 1 0 0 각 단어의 빈도수 2 tfidf term frequencyinverse document frequency tfidf는 단순한 단어 빈도 외에도 단어의 중요도를 반영한 임베딩 기법이에요 특정 단어가 문서 내에서 자주 등장하지만 전체 문서에서 드물게 등장한다면 그 단어는 해당 문서에서 중요한 단어로 간주됩니다 tf 단어의 빈도 idf 단어의 전체 문서에서의 등장 빈도 반비례값 이를 통해 문서 내에서 의미 있는 단어를 강조할 수 있어요 3 word2vec glove word2vec과 glove는 단어 간의 의미적 유사성을 반영하는 임베딩 기법이에요 단어를 고차원 벡터로 변환하여 단어 간의 관계를 학습합니다 word2vec 주위 단어들에 기반해 단어의 의미를 학습 glove 전체 문맥을 기반으로 단어 간의 공통 패턴을 학습 이러한 임베딩 기법을 사용하면 단어의 의미를 벡터로 비교해 문맥 유사성을 파악할 수 있어요 4 transformer 기반 임베딩 bert gpt bert나 gpt 같은 transformer 모델들은 문장의 문맥을 고려하여 더 깊이 있는 의미를 반영한 임베딩을 생성해요 특히 이들은 문장 단위로 텍스트를 벡터화할 수 있어 문장 간의 유사도를 정확하게 파악합니다 bert 양방향으로 문맥을 고려한 임베딩 생성 gpt 자동 완성 및 생성에 강점을 둔 임베딩 생성 임베딩의 활용 임베딩을 활용하면 텍스트 검색 문서 분류 대화형 ai 등 다양한 응용 분야에서 의미 기반 검색과 유사성 분석을 수행할 수 있습니다 배운 내용 정리하기 텍스트 처리와 임베딩은 필수적인 기초 텍스트 처리와 임베딩은 llm 시스템 구축의 핵심 기초입니다 정확한 텍스트 처리와 적절한 임베딩 기법을 활용하면 llm의 성능을 최대한 끌어올리고 더 나은 결과를 얻을 수 있어요 텍스트 처리는 모델의 입력을 정제하고 임베딩은 모델이 추론할 수 있도록 텍스트를 벡터화합니다 이 둘을 잘 이해하고 적용하는 것이 llm 시스템 구축의 첫걸음이에요

URL 15 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 langchain 개념과 활용 제작 langchain 개념과 활용 수업 목표 langchain에 대해서 학습하고 사용 사례와 주요 장점을 살펴봅니다 목차 langchain이란 langchain이 왜 좋은가 langchain의 주요 개념 langchain 사용 사례 배운 내용 정리하기 langchain은 llm대형 언어 모델과 다양한 컴포넌트를 연결하여 복잡한 작업을 수행하고 체인 형태로 구성된 애플리케이션을 만들 수 있는 프레임워크입니다 이를 통해 langchain은 간단한 텍스트 생성에서 복잡한 멀티스텝 워크플로우까지 다양한 ai 애플리케이션을 개발하는 데 도움을 줍니다 langchain이란 langchain은 언어 모델을 중심으로 다양한 데이터 소스와 툴을 연결하여 체인 기반 애플리케이션을 구축할 수 있는 python 기반 프레임워크입니다 langchain을 사용하면 하나의 언어 모델 응답만 받는 대신 여러 단계로 구성된 체인 구조를 통해 다양한 연산과 데이터 처리 멀티스텝 분석이 가능합니다 예를 들어 특정 질문에 대해 외부 데이터베이스에서 정보를 검색하고 이를 종합하여 응답을 생성하는 과정 등을 자동화할 수 있습니다 langchain이 왜 좋은가 유연한 구성 langchain은 언어 모델과 다양한 컴포넌트를 쉽게 연결할 수 있습니다 모델의 응답을 다른 컴포넌트로 보내거나 여러 단계에 걸친 데이터 처리가 가능합니다 모듈화된 컴포넌트 프롬프트 템플릿 출력 파서 벡터 데이터베이스 에이전트 등을 통해 각 컴포넌트를 필요에 따라 조합할 수 있어 재사용성과 확장성이 높습니다 체인과 에이전트 단순한 질문응답을 넘어서 여러 작업을 순차적으로 실행하는 체인과 상황에 따라 행동을 결정하는 에이전트를 통해 복잡한 작업을 자동화할 수 있습니다 강력한 통합 기능 langchain은 openai huggingface faiss elasticsearch 등 다양한 언어 모델 벡터 데이터베이스와의 통합이 가능해 데이터 소스 확장과 빠른 검색이 가능합니다 langchain의 주요 개념 언어 모델 llm 언어 모델은 주어진 입력을 바탕으로 텍스트를 생성합니다 langchain은 openai의 gpt 모델을 포함해 다양한 언어 모델과의 통합을 지원합니다 예시 langchain을 사용하여 openai의 gpt4 모델을 불러와 기본적인 질문에 답변하도록 설정 프롬프트 템플릿 prompt templates 프롬프트 템플릿은 프롬프트를 동적으로 생성하는 데 사용됩니다 특정 입력 값에 따라 템플릿이 채워져 모델에 전달되므로 반복적인 작업을 단순화합니다 예시 사용자 질문에 따라 특정 정보 검색을 요구하는 시스템 프롬프트 생성 체인 chains 여러 단계를 거치는 워크플로우를 하나로 묶어주는 기능입니다 예를 들어 사용자의 질문을 분석해 필요한 데이터를 검색하고 검색 결과를 기반으로 응답을 생성하는 일련의 과정을 체인으로 구성할 수 있습니다 예시 사용자 질문을 받은 후 검색 분석 응답 생성의 3단계 체인 생성 에이전트 agents 에이전트는 동적으로 필요한 작업을 결정하고 수행하는 컴포넌트입니다 질문에 따라 답변하기 위해 api 호출이 필요한지 또는 단순히 텍스트 생성을 해야 하는지를 판단해 작업을 실행합니다 예시 질문이 지리 정보에 관련된 경우 api를 호출해 최신 정보를 제공하는 에이전트 벡터 데이터베이스 vector databases 벡터 데이터베이스는 텍스트를 벡터로 변환해 저장하고 이후 유사한 벡터를 빠르게 검색할 수 있도록 돕습니다 이를 통해 저장된 데이터와 유사한 질문에 빠르게 응답할 수 있습니다 예시 faiss와 같은 벡터 데이터베이스에 문서를 저장해 유사성 검색을 수행 langchain 사용 사례 1 검색 기반 생성rag langchain을 사용하여 질문에 답할 때 관련 문서를 검색하고 해당 내용을 바탕으로 응답을 생성할 수 있습니다 이를 통해 최신 정보에 기반한 답변을 생성할 수 있습니다 2 faq 시스템 다양한 질문에 대한 답변을 벡터 데이터베이스에 저장하고 유사성 검색을 통해 빠르게 적절한 답변을 제공합니다 3 다단계 챗봇 워크플로우 복잡한 질문에 대해 여러 단계를 거쳐 답변을 구성하는 챗봇을 설계할 수 있습니다 예를 들어 질문을 받아 요약한 후 관련된 추가 정보를 검색해 제공하는 방식입니다 4 지능형 에이전트 주식 가격을 확인하거나 뉴스 데이터를 검색해 최신 정보를 제공하는 챗봇 에이전트를 구현할 수 있습니다 langchain의 주요 장점 요약 확장성 언어 모델과 다양한 데이터 소스를 연결하여 유연하게 확장 가능 자동화 복잡한 멀티스텝 프로세스를 체인 형태로 구성하여 자동화 가능 유사성 검색 벡터 데이터베이스를 활용해 유사 문서를 빠르게 검색 및 응답 가능 재사용성 프롬프트 템플릿 체인 에이전트 등을 활용해 재사용 가능한 애플리케이션 구성 가능 배운 내용 정리하기 langchain은 llm의 강력한 성능을 다양한 데이터 소스와 통합해 유연하고 확장성 있는 ai 애플리케이션을 개발하는 데 큰 도움을 줍니다 langchain의 다양한 컴포넌트를 이해하고 사용하는 것은 ai 애플리케이션의 효율성과 생산성을 높이는 데 중요한 역할을 합니다

URL 16 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 python langchain과 faiss 제작 python langchain과 faiss 수업 목표 langchain 사용을 위한 환경 설정을 진행합니다 faiss를 활용한 벡터 데이터베이스를 구성하는 실습을 진행합니다 목차 설치 및 기본 설정 langchain 기본 개념 언어 모델 초기화 프롬프트 템플릿 사용하기 langchain expression language lcel로 체인 연결 faiss를 활용한 벡터 데이터베이스 구성 및 쿼리 step 1 openai 임베딩 모델로 벡터 임베딩 생성 step 2 faiss 인덱스 초기화 step 3 벡터 데이터베이스에 문서 추가 step 4 벡터 데이터베이스 쿼리 rag 체인에 faiss 통합 step 1 retriever로 변환 step 2 rag 체인 생성 faiss 인덱스의 저장 및 로드 faiss 데이터베이스 병합 이번에는 langchain과 faiss를 이용한 실습을 진행할 예정인데요 실습은 아래와 같은 순서로 진행됩니다 설치 및 기본 설정 langchain 기본 개념 언어 모델 프롬프트 템플릿 langchain expression language lcel로 체인 연결 faiss를 활용한 벡터 데이터베이스 구성 및 쿼리 rag 체인에 faiss 통합 faiss 인덱스의 저장 및 로드 병합 설치 및 기본 설정 langchain openai 그리고 faiss 패키지를 설치합니다 gpu를 사용하는 경우 faissgpu를 사용할 수 있습니다 pip install langchain langchainopenai faisscpu 설치 후 openai api 키를 설정해 사용 환경을 준비합니다 import os getpass import getpass osenvironopenai_api_key getpassopenai api key 입력 langchain 기본 개념 언어 모델 초기화 openai의 gpt4 모델을 langchain을 통해 사용해 봅니다 chatopenai를 이용해 초기화하고 invoke 메서드를 통해 메시지를 전달하여 응답을 받아옵니다 langchain_openai import chatopenai langchain_coremessages import humanmessage 모델 초기화 model chatopenaimodelgpt4 모델에 메시지 전달 response modelinvokehumanmessagecontent안녕하세요 무엇을 도와드릴까요 printresponsecontent 프롬프트 템플릿 사용하기 프롬프트 템플릿은 다양한 입력을 받아 메시지를 생성하는데 도움을 줍니다 예를 들어 영어 문장을 다른 언어로 번역하는 프롬프트를 정의해 봅시다 langchain_coreprompts import chatprompttemplate 시스템 메시지 설정 system_template translate following sentence english language 사용자 텍스트 입력 prompt_template chatprompttemplatefrom_messages system system_template user text 프롬프트 생성 result prompt_templateinvokelanguage french text printresultto_messages langchain expression language lcel로 체인 연결 여러 컴포넌트를 체인으로 연결하여 데이터 흐름을 통제하는 lcel을 사용합니다 langchain_coreoutput_parsers import stroutputparser 응답을 파싱하는 파서 초기화 parser stroutputparser 템플릿 모델 파서를 체인으로 연결 chain prompt_template model parser 체인 실행 response chaininvokelanguage spanish text library printresponse faiss를 활용한 벡터 데이터베이스 구성 및 쿼리 faiss는 벡터 유사성 검색을 위한 라이브러리입니다 openaiembeddings로 텍스트를 벡터로 변환해 faiss 인덱스에 저장합니다 step 1 openai 임베딩 모델로 벡터 임베딩 생성 langchain_openai import openaiembeddings openai 임베딩 모델 초기화 embeddings openaiembeddingsmodeltextembeddingada002 step 2 faiss 인덱스 초기화 import faiss langchain_communityvectorstores import faiss langchain_communitydocstorein_memory import inmemorydocstore faiss 인덱스 생성 index faissindexflatl2lenembeddingsembed_queryhello world vector_store faiss embedding_functionembeddings indexindex docstoreinmemorydocstore index_to_docstore_id step 3 벡터 데이터베이스에 문서 추가 langchain_coredocuments import document uuid import uuid4 문서 생성 documents documentpage_contentlangchain을 사용해 프로젝트를 구축하고 있습니다 metadatasource tweet documentpage_content내일 날씨는 맑고 따뜻할 예정입니다 metadatasource news documentpage_content오늘 아침에는 팬케이크와 계란을 먹었어요 metadatasource personal documentpage_content주식 시장이 경기 침체 우려로 하락 중입니다 metadatasource news 고유 id 생성 및 문서 추가 uuids struuid4 _ rangelendocuments vector_storeadd_documentsdocumentsdocuments idsuuids step 4 벡터 데이터베이스 쿼리 유사성 검색을 통해 특정 쿼리와 유사한 문서를 검색해보겠습니다 기본 유사성 검색 results vector_storesimilarity_search내일 날씨는 어떨까요 k2 filtersource news res results printf respage_content resmetadata 점수와 함께 유사성 검색 results_with_scores vector_storesimilarity_search_with_scorelangchain에 대해 이야기해주세요 k2 filtersource tweet res score results_with_scores printf simscore3f respage_content resmetadata rag 체인에 faiss 통합 rag retrievalaugmented generation 체인을 구성하여 검색된 문서를 바탕으로 질문에 응답할 수 있도록 구성합니다 step 1 retriever로 변환 faiss를 retriever로 변환해 rag 체인에서 사용합니다 retriever vector_storeas_retrieversearch_typesimilarity search_kwargsk 1 step 2 rag 체인 생성 langchain의 모델과 프롬프트를 연결하여 rag 체인을 구성합니다 langchain_coreprompts import chatprompttemplate langchain_corerunnables import runnablepassthrough 프롬프트 템플릿 정의 contextual_prompt chatprompttemplatefrom_messages system answer question using following context user context contextnnquestion question class debugpassthroughrunnablepassthrough def invokeself args kwargs output superinvokeargs kwargs printdebug output output return output 문서 리스트를 텍스트로 변환하는 단계 추가 class contexttotextrunnablepassthrough def invokeself inputs confignone kwargs config 인수 추가 context의 각 문서를 문자열로 결합 context_text njoindocpage_content doc inputscontext return context context_text question inputsquestion rag 체인에서 각 단계마다 debugpassthrough 추가 rag_chain_debug context retriever 컨텍스트를 가져오는 retriever question debugpassthrough 사용자 질문이 그대로 전달되는지 확인하는 passthrough debugpassthrough contexttotext contextual_prompt model 질문 실행 및 각 단계 출력 확인 response rag_chain_debuginvoke강사이름은 printfinal response printresponsecontent faiss 인덱스의 저장 및 로드 faiss 인덱스를 저장해 다시 사용할 수 있습니다 인덱스 저장 vector_storesave_localfaiss_index 저장된 인덱스 로드 new_vector_store faissload_localfaiss_index embeddings faiss 데이터베이스 병합 두 개의 faiss 데이터베이스를 병합할 수 있습니다 db1 faissfrom_texts문서 1 내용 embeddings db2 faissfrom_texts문서 2 내용 embeddings 병합 db1merge_fromdb2

URL 17 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 sentencetransformer word2vec 그리고 transformer 기반 임베딩 제작 sentencetransformer word2vec 그리고 transformer 기반 임베딩 수업 목표 한국어 임베딩의 특징과 임베딩 실습을 진행합니다 목차 word2vec을 사용한 한국어 임베딩 word2vec 한국어 임베딩 실습 sentencetransformer로 한국어 문장 임베딩 sentencetransformer 한국어 임베딩 실습 transformer 기반 최신 한국어 임베딩 transformer 한국어 임베딩 실습 kobert 사용 한국어 임베딩의 특징과 도전 과제 왜 한국어 임베딩이 어려운가 최신 모델과 접근 방식 배운 내용 정리하기 이번 실습에서는 한국어 임베딩을 위한 세 가지 대표적인 기법인 sentencetransformer word2vec 그리고 transformer 기반 임베딩을 살펴보고 실습해볼 거예요 특히 최신 transformer 모델을 사용하여 한국어를 잘 처리하는 방법에 대해 알아볼게요 word2vec을 사용한 한국어 임베딩 word2vec은 단어를 고차원 벡터로 변환하여 의미적 유사성을 측정하는 임베딩 기법이에요 단어 간의 문맥적 관계를 반영하여 비슷한 의미를 가진 단어들이 유사한 벡터 값을 갖도록 학습합니다 word2vec 한국어 임베딩 실습 gensimmodels import word2vec 샘플 한국어 문장 데이터 sentences 나는 오늘 책을 읽었다 고양이가 야옹하고 울었다 인공지능은 정말 흥미로운 주제다 한국어 임베딩을 학습하는 중이다 python 기본 split 사용해 간단하게 토큰화 tokenized_sentences sentencesplit sentence sentences word2vec 모델 학습 word2vec_model word2vecsentencestokenized_sentences vector_size100 window5 min_count1 workers4 단어 고양이와 유사한 단어 찾기 similar_words word2vec_modelwvmost_similar고양이 printsimilar_words word2vec 특징 장점 단어 간의 의미적 관계를 파악하는 데 적합 단점 단어 자체만 학습하므로 문장 단위에서는 유연성이 부족 sentencetransformer로 한국어 문장 임베딩 sentencetransformer는 문장 단위로 임베딩을 생성할 수 있는 bert 기반의 모델이에요 특히 한국어에 특화된 kosentencebert 같은 모델을 사용하면 문장 간의 의미적 유사성을 정확하게 계산할 수 있습니다 sentencetransformer 한국어 임베딩 실습 sentence_transformers import sentencetransformer 최신 kosentencebert 모델 로드 model sentencetransformersentencetransformerskrsentence_bertbase 샘플 문장들 sentences 나는 오늘 책을 읽었다 고양이가 야옹하고 울었다 인공지능은 흥미로운 주제다 한국어 임베딩을 학습하는 중이다 문장 임베딩 생성 embeddings modelencodesentences 첫 번째 문장 임베딩 확인 printembeddings0 sentencetransformer 특징 장점 문장 간의 유사성을 정확하게 측정 문맥을 고려한 임베딩 생성 단점 학습 속도가 상대적으로 느림 transformer 기반 최신 한국어 임베딩 transformer 기반 모델들은 bert gpt 같은 모델들로 발전해왔고 최근에는 kobert kogpt와 같은 한국어 특화 모델이 등장했어요 이 모델들은 문맥을 고려하여 정교한 임베딩을 생성해줍니다 transformer 한국어 임베딩 실습 kobert 사용 transformers import berttokenizer bertmodel import torch kluebert 모델과 토크나이저 로드 tokenizer berttokenizerfrom_pretrainedkluebertbase model bertmodelfrom_pretrainedkluebertbase 입력 문장 sentence 한국어 임베딩을 학습하고 있습니다 토큰화 및 텐서 변환 inputs tokenizersentence return_tensorspt 임베딩 생성 torchno_grad outputs modelinputs 임베딩 벡터 추출 평균값으로 계산 embedding outputslast_hidden_statemeandim1 printembedding transformer 특징 장점 문맥을 양방향으로 이해 문장 전체의 의미를 깊이 반영 단점 계산 비용이 크고 모델 크기가 큼 한국어 임베딩의 특징과 도전 과제 왜 한국어 임베딩이 어려운가 1 교착어 특성 한국어는 조사와 어미를 많이 사용하는 교착어로 단어 변형이 많아 정확한 형태소 분석이 중요해요 2 어순의 유연성 한국어는 어순이 자유롭기 때문에 동일한 의미라도 다양한 형태로 표현될 수 있어요 3 데이터 부족 영어에 비해 한국어로 학습된 데이터가 상대적으로 적어 임베딩 모델이 충분히 학습되지 않은 경우가 많습니다 최신 모델과 접근 방식 kobert kogpt 등 한국어 전용 transformer 모델들은 이러한 문제를 해결하기 위해 한국어에 특화된 데이터셋을 사용하여 학습되었습니다 특히 sentencetransformer는 문장 간 의미적 유사성을 정확하게 파악하는 데 강점을 가지며 한국어 문장 처리에 탁월한 성능을 보여줍니다 배운 내용 정리하기 요약 word2vec 단어 단위의 의미적 유사성을 벡터로 표현 sentencetransformer 문장 간 유사성을 벡터로 표현 kosentencebert 모델로 한국어 문장 처리 transformer 모델 특히 kobert 문맥을 고려한 고차원 임베딩 한국어 전용 모델로 강력한 성능 이러한 다양한 임베딩 기법을 통해 한국어 텍스트 분석의 정확성과 효율성을 높일 수 있습니다 한국어 임베딩의 특성과 최신 기법을 잘 활용하여 llm 시스템에 적용해보세요

URL 18 content:
llm rag를 활용한 ai 서비스 만들기 llm rag를 활용한 ai 서비스 만들기 5주차 문서 임베딩 실습하기 제작 문서 임베딩 실습하기 수업 목표 문서 임베딩의 기본 개념과 faiss로 유사도 검색 실습을 진행합니다 목차 실습 준비물 문서 임베딩의 기본 개념 문서 단위 임베딩 전체 문서 임베딩하기 문장 단위 임베딩하기 문단 단위 임베딩하기 faiss로 유사도 검색하기 faiss 초기화 및 인덱싱 유사 문장 검색하기 유사도에 대한 실험 길이 단위 선택 가이드 추가 실험 임베딩 벡터 시각화하기 추가 실험 tsne를 이용한 고차원 임베딩 시각화 여러분 안녕하세요 오늘은 inputtxt라는 txt 파일을 가지고 문서 임베딩을 실습해보려고 합니다 특히 faiss를 활용해 유사 단어 검색까지 해볼 거예요 문서를 임베딩하는 여러 방법에 대해서도 실험해볼 테니 기대해 주세요 실습 준비물 python 코드 실행 환경 jupyter notebook 또는 ide 추천 inputtxt 파일 이 파일에는 우리가 분석할 텍스트 데이터가 들어있어요 sentencetransformers 라이브러리 설치 faiss 라이브러리 설치 pip install sentencetransformers faisscpu 문서 임베딩의 기본 개념 문서를 임베딩할 때 텍스트를 벡터 형태로 변환하여 컴퓨터가 이해하기 쉽게 만들어요 변환된 벡터들은 문서 간의 유사도를 계산하거나 검색을 위해 활용됩니다 이번 실습에서는 최신 한국어 모델을 사용해 문서를 임베딩할 거예요 최신 모델은 sentencetransformers를 통해 불러올 예정입니다 참고 임베딩이란 텍스트 이미지 등 다양한 데이터를 고차원의 벡터 공간에 표현하는 것을 말합니다 이렇게 표현된 벡터들은 기계 학습 모델들이 데이터를 더 쉽게 이해하고 분석할 수 있게 도와줘요 문서 단위 임베딩 문서를 임베딩할 때 중요한 결정 중 하나는 임베딩할 텍스트의 길이를 어떻게 설정할지입니다 한 번 전체 문서를 통째로 임베딩할 수도 있고 문장을 단위로 하거나 문단 단위로 쪼개서 임베딩할 수도 있어요 각 방법의 장단점을 비교해 보죠 전체 문서 임베딩하기 먼저 전체 문서를 하나의 벡터로 임베딩하는 방법입니다 이 방법은 문서 전체의 맥락을 이해하는 데 유리하지만 길이가 너무 길 경우 중요한 정보가 손실될 수 있습니다 sentence_transformers import sentencetransformer import numpy np 모델 불러오기 model sentencetransformersentencetransformersxlmr100langsbertbasenlistsbmeantokens inputtxt 파일 불러오기 openinputtxt r encodingutf8 file document fileread 전체 문서 임베딩 doc_embedding modelencodedocument 실습 실험 전체 문서 임베딩의 성능을 확인하기 위해 doc_embedding을 사용해 문서 전체의 요약본을 다른 문서와 비교해 보세요 전체 문서를 하나의 벡터로 표현하는 것이 실제 문서의 의미를 얼마나 잘 반영하는지 확인할 수 있어요 문장 단위 임베딩하기 문서를 문장 단위로 나누어 임베딩해 볼까요 이렇게 하면 문장별 유사도를 계산하기에 좋습니다 특히 검색 시 특정 문장과 유사한 문장을 찾는 데 유용해요 nltktokenize import sent_tokenize 문장으로 나누기 sentences sent_tokenizedocument 각 문장을 임베딩 sentence_embeddings modelencodesentences 실습 실험 문장 단위로 임베딩한 후 특정 문장을 입력해 유사 문장을 찾아보세요 예를 들어 이 문서의 핵심은 무엇인가요 같은 질문을 던지고 그와 유사한 문장을 검색해 봅시다 문단 단위 임베딩하기 문서를 문단 단위로 쪼개 임베딩하는 방법도 있어요 이 방법은 문서 내 주제별 정보를 분석할 때 유리합니다 paragraphs documentsplitnn 두 줄 개행 기준으로 문단 나누기 각 문단을 임베딩 paragraph_embeddings modelencodeparagraphs 실습 실험 문단 단위로 나눈 후 각 문단의 벡터를 시각화해서 문단별 유사도를 비교해 보세요 이 과정에서 pca 또는 tsne 같은 차원 축소 방법을 사용하면 벡터 간의 관계를 쉽게 확인할 수 있어요 faiss로 유사도 검색하기 임베딩이 끝났다면 이제 faiss를 사용해 유사도를 계산해 봅시다 faiss는 벡터 간 유사도를 빠르게 계산할 수 있도록 도와주는 라이브러리입니다 faiss 초기화 및 인덱싱 먼저 임베딩된 벡터들을 인덱싱해서 검색할 준비를 해볼게요 import faiss 문장 임베딩을 사용해 인덱스 생성 dimension sentence_embeddingsshape1 index faissindexflatl2dimension l2 거리 기반 인덱스 인덱스에 벡터 추가 indexaddnparraysentence_embeddings 유사 문장 검색하기 특정 문장과 유사한 문장을 찾아봅시다 검색하고 싶은 문장을 입력하고 인덱스를 활용해 유사도를 계산합니다 query 검색할 문장을 입력하세요 query_vec modelencodequery 유사한 문장 3개 찾기 indexsearchnparrayquery_vec k3 결과 출력 idx i0 printf유사 문장 sentencesidx 실습 실험 다른 문장들을 입력해서 어떤 문장이 가장 유사하게 검색되는지 실험해 보세요 예를 들어 오늘 날씨는 어때와 같은 문장을 넣어보면 유사한 주제를 가진 문장들이 잘 검색되는지 확인할 수 있습니다 유사도에 대한 실험 유사도 검색 결과의 정확도를 평가해봅시다 다음과 같은 실험을 통해 유사도 결과를 분석해 볼 수 있어요 1 다양한 쿼리 테스트 다양한 쿼리를 사용하여 유사 문장 검색 결과를 비교해 보세요 예를 들어 간단한 문장과 복잡한 문장을 각각 입력해 보고 결과가 어떻게 달라지는지 관찰합니다 2 유사도 점수 분석 검색 결과로 반환된 유사도 점수d를 분석하여 높은 유사도와 낮은 유사도 간의 차이를 확인해 보세요 예를 들어 값을 출력하여 얼마나 유사한지 정량적으로 평가해 볼 수 있습니다 유사도 점수와 함께 결과 출력 idx score zipi0 d0 printf유사 문장 sentencesidx 유사도 점수 score 실습 실험 유사도 점수가 높은 문장과 낮은 문장을 비교해 보고 그 차이가 문장의 의미나 표현 방식에서 어떻게 드러나는지 분석해 보세요 이렇게 하면 모델이 유사도를 어떻게 판단하는지 더 깊이 이해할 수 있습니다 길이 단위 선택 가이드 전체 문서 임베딩 문서 전체 맥락을 분석하고 싶을 때 문장 단위 임베딩 특정 문장과의 유사도 계산이나 세밀한 검색이 필요할 때 문단 단위 임베딩 주제별 유사도를 분석하고 싶을 때 tip 각 단위로 임베딩했을 때의 차이를 비교해 보는 것도 좋은 실습이 될 수 있어요 예를 들어 문장 단위로 했을 때와 문단 단위로 했을 때의 검색 결과가 어떻게 달라지는지 확인해 보세요 추가 실험 임베딩 벡터 시각화하기 임베딩된 벡터들은 고차원 공간에 위치하게 됩니다 이를 시각화하면 벡터 간의 관계를 더 직관적으로 이해할 수 있어요 pca나 tsne 같은 차원 축소 기법을 사용해 2d나 3d로 시각화해 봅시다 sklearndecomposition import pca import matplotlibpyplot plt 문장 임베딩 벡터의 차원을 축소하여 시각화 pca pcan_components2 reduced_embeddings pcafit_transformsentence_embeddings 시각화 pltscatterreduced_embeddings 0 reduced_embeddings 1 plttitlesentence embeddings visualization pltxlabelpca component 1 pltylabelpca component 2 pltshow 실습 실험 각 색깔로 다른 문단이나 문서의 벡터를 시각화해서 벡터들이 어떻게 군집되는지 확인해 보세요 이는 유사한 문장들이 벡터 공간에서 얼마나 가깝게 위치하는지 직관적으로 이해하는 데 도움이 됩니다 추가 실험 tsne를 이용한 고차원 임베딩 시각화 tsne는 고차원 데이터를 저차원으로 시각화하는 데 유용한 기법이에요 임베딩된 벡터들을 tsne를 사용해 시각화해 보면 벡터 간의 관계를 더 명확하게 이해할 수 있습니다 sklearnmanifold import tsne tsne로 차원 축소 tsne tsnen_components2 perplexity30 n_iter300 tsne_results tsnefit_transformsentence_embeddings 시각화 pltscattertsne_results 0 tsne_results 1 plttitletsne sentence embeddings visualization pltxlabeltsne component 1 pltylabeltsne component 2 pltshow tip tsne는 계산 비용이 많이 들기 때문에 데이터의 크기가 클 경우 일부만 샘플링해서 시각화해 보세요 tsne는 특히 데이터 간의 지역적 구조를 잘 드러내는 데 유리해요

