8강 지도학습  회귀모델 SCC 바닥부터 시작하는 머신러닝 바닥부터 시작하는 머신러닝  3주차 8강 지도학습  회귀모델 제작 8강 지도학습  회귀모델 수업 목표다양한 회귀 모델에 대해서 배워봅시다회귀Regression모델은 연속적인 값을 예측하는 문제입니다회귀Regression모델은 연속적인 값을 예측하는 문제입니다회귀Regression모델은 연속적인 값을 예측하는 문제입니다 오늘은 선형회귀다항회귀리지회귀라쏘회귀 를 다뤄볼 예정입니다오늘은 선형회귀다항회귀리지회귀라쏘회귀 를 다뤄볼 예정입니다오늘은 선형회귀다항회귀리지회귀라쏘회귀 를 다뤄볼 예정입니다목차01 회귀모델 01 회귀모델다양한 회귀 모델선형회귀다항회귀리지회귀라쏘회귀에 대해서 알아보고 실습해 봅시다1 선형 회귀 선형 회귀선형회귀는 종속 변수와 하나 이상의 독립 변수 간의 선형 관계를 모델링 하는 방법입니다독립변수의 수에 따라 단순 선형회귀와 다중 선형회귀로 나뉩니다 단순 선형 회귀 VS 다중 선형 회귀ALT단순 선형 회귀  하나의 독립 변수와 하나의 종속 변수 간의 관계를 모델링다중 선형 회귀  여러 독립 변수와 하나의 종속 변수 간의 관계를 모델링선형 회귀의 기본 수식은 다음과 같습니다선형 회귀의 기본 수식은 다음과 같습니다선형 회귀의 기본 수식은 다음과 같습니다 yβ0β1x1β2x2βnxnϵyβ0β1x1β2x2βnxnϵyβ0β1x1β2x2βnxnϵ 여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다  단순 선형 회귀일경우 gray 단순 선형 회귀일경우  단순 선형 회귀일경우  yβ0β1xϵgrayyβ0β1xϵyβ0β1xϵ Scikitlearn 을 사용한 선형 회귀 모델 구현 및 평가선형 회귀 모델 구현 및 평가 989C9E선형 회귀 모델 구현 및 평가 EAE9FE270px5px선형 회귀 모델 구현 및 평가 Python복사import numpy as np import pandas as pd from sklearnmodel_selection import train_test_split from sklearnlinear_model import LinearRegression from sklearnmetrics import mean_squared_error r2_score  데이터 생성 X  nparray1 1 2 2 3 3 4 4 5 566 y  nparray1 2 3 4 5 6  데이터 분할 훈련 데이터와 테스트 데이터 X_train X_test y_train y_test  train_test_splitX y test_size02 random_state42  선형 회귀 모델 생성 및 학습 model  LinearRegression modelfitX_train y_train  예측 y_pred  modelpredictX_test  모델 평가 mse  mean_squared_errory_test y_pred r2  r2_scorey_test y_pred printfMean Squared Error mse printfR2 Score r2 2 다항 회귀 다항 회귀다항 회귀Polynomial Regression는 종속 변수와 독립 변수 간의 비선형 관계를 모델링하는 방법독립변수의 다항식을 사용하여 관계를 모델링 합니다다항 회귀의 기본 수식은 다음과 같습니다다항 회귀의 기본 수식은 다음과 같습니다다항 회귀의 기본 수식은 다음과 같습니다 yβ0β1xβ2x2βnxnϵyβ0β1xβ2x2βnxnϵyβ0β1xβ2x2βnxnϵ 여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다여기서 y는 종속변수 x1x2xn 은 독립변수 b0 는 절편 b1b2bn은 회귀계수 e는 오차입니다 다항 회귀 차수 선택다항회귀 차수degree  독립 변수의 최대 차수차수가 높을수록 모델이 더 복잡해지며 과적합overfitting의 위험 존재  적절한 차수 선택 필요과적합이란 학습데이터에 모델이 과도하게 적합fitting되는 현상입니다과적합이란 학습데이터에 모델이 과도하게 적합fitting되는 현상입니다과적합이란 학습데이터에 모델이 과도하게 적합fitting되는 현상입니다 Scikitlearn을 사용한 다항 회귀 모델 구현 및 평가다항 회귀 모델 구현 및 평가 989C9E다항 회귀 모델 구현 및 평가 EAE9FE270px5px다항 회귀 모델 구현 및 평가 Python복사import numpy as np import pandas as pd from sklearnmodel_selection import train_test_split from sklearnpreprocessing import PolynomialFeatures from sklearnlinear_model import LinearRegression from sklearnmetrics import mean_squared_error r2_score  데이터 생성 X  nparray1 2 3 4 5 6 y  nparray1 4 9 16 25 36  다항 특징 생성 차수 2 poly  PolynomialFeaturesdegree2 X_poly  polyfit_transformX  데이터 분할 훈련 데이터와 테스트 데이터 X_train X_test y_train y_test  train_test_splitX_poly y test_size02 random_state42  다항 회귀 모델 생성 및 학습 model  LinearRegression modelfitX_train y_train  예측 y_pred  modelpredictX_test  모델 평가 mse  mean_squared_errory_test y_pred r2  r2_scorey_test y_pred printfMean Squared Error mse printfR2 Score r2 3 리지 회귀 리지 회귀리지 회귀Ridge Regression는 선형 회귀의 일종회귀 계수의 크기를 제어하여 과적합을 방지하는 정규화 기법L2 정규화regularization를 사용하여 회귀 계수의 제곱합을 최소화 합니다리지 회귀의 기본 수식은 다음과 같습니다리지 회귀의 기본 수식은 다음과 같습니다리지 회귀의 기본 수식은 다음과 같습니다 Jβi1nyiyi2λj1pβj2J  _i1n y_i  y_i2  _j1p _j2Jβi1nyiyi2λj1pβj2 여기서λ는 정규화 강도를 조절하는 하이퍼파라미터 입니다여기서 는 정규화 강도를 조절하는 하이퍼파라미터 입니다여기서λ는 정규화 강도를 조절하는 하이퍼파라미터 입니다 L2 정규화 L2 정규화는 모든 가중치를 작게 만들어 모델의 복잡도를 줄입니다손실 함수에 제곱항을 추가하여 매끄러운 최적화가 가능합니다정규화는 모델의 복잡도를 제어하여 과적합을 방지하는 데 필요합니다 Scikitlearn을 사용한 리지 회귀 모델 구현 및 평가리지 회귀 모델 구현 및 평가 989C9E리지 회귀 모델 구현 및 평가 EAE9FE270px5px리지 회귀 모델 구현 및 평가 Python복사import numpy as np import pandas as pd from sklearnmodel_selection import train_test_split from sklearnlinear_model import Ridge from sklearnmetrics import mean_squared_error r2_score  데이터 생성 X  nparray1 1 2 2 3 3 4 4 5 5 6 6 y  nparray1 2 3 4 5 6  데이터 분할 훈련 데이터와 테스트 데이터 X_train X_test y_train y_test  train_test_splitX y test_size02 random_state42  리지 회귀 모델 생성 및 학습 model  Ridgealpha10 modelfitX_train y_train  예측 y_pred  modelpredictX_test  모델 평가 mse  mean_squared_errory_test y_pred r2  r2_scorey_test y_pred printfMean Squared Error mse printfR2 Score r2 4 라쏘 회귀 라쏘 회귀라쏘 회귀Lasso Regression는 선형 회귀의 일종회귀 계수의 크기를 제어하여 과적합을 방지하는 정규화 기법L1 정규화regularization를 사용하여 회귀 계수의 절대값 합을 최소화 합니다라쏘 회귀의 기본 수식은 다음과 같습니다라쏘 회귀의 기본 수식은 다음과 같습니다라쏘 회귀의 기본 수식은 다음과 같습니다 Jβi1nyiyi2λj1pβjJ  _i1n y_i  y_i2  _j1p _jJβi1nyiyi2λj1pβj 여기서λ는 정규화 강도를 조절하는 하이퍼파라미터 입니다여기서 는 정규화 강도를 조절하는 하이퍼파라미터 입니다여기서λ는 정규화 강도를 조절하는 하이퍼파라미터 입니다 L1 정규화와 특징 선택L1 정규화는 일부 회귀 계수를 0으로 만들어 특징 선택feature selection을 수행모델의 해석 가능성을 높이고 불필요한 특징을 제거하는 데 유용합니다 Scikitlearn을 사용한 라쏘 회귀 모델 구현 및 평가라쏘 회귀 모델 구현 및 평가 989C9E라쏘 회귀 모델 구현 및 평가 EAE9FE270px5px라쏘 회귀 모델 구현 및 평가 Python복사import numpy as np import pandas as pd from sklearnmodel_selection import train_test_split from sklearnlinear_model import Lasso from sklearnmetrics import mean_squared_error r2_score  데이터 생성 X  nparray1 1 2 2 3 3 4 4 5 5 66 y  nparray1 2 3 4 5 6  데이터 분할 훈련 데이터와 테스트 데이터 X_train X_test y_train y_test  train_test_splitX y test_size02 random_state42  라쏘 회귀 모델 생성 및 학습 model  Lassoalpha10 modelfitX_train y_train  예측 y_pred  modelpredictX_test  모델 평가 mse  mean_squared_errory_test y_pred r2  r2_scorey_test y_pred printfMean Squared Error mse printfR2 Score r2