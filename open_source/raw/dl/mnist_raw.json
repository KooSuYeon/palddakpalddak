[
    "<a href=\"https://colab.research.google.com/github/happy-jihye/GAN/blob/main/1_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
    "# 1 - Generative Adversarial Networks(GAN)\n\n- [Generative Adversarial Networks (NIPS 2014)](https://arxiv.org/abs/1406.2661)\n\n> - 2021/03/12 Happy-jihye\n> - **Reference** : [eriklindernoren/PyTorch-GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n\n---\n",
    "## **GAN - minimax two player game**\n- Generative Adversarial Networks(GAN)은 adversarial process를 적용한 생성모델입니다. 주어진 입력 데이터와 유사한 데이터를 생성하는 것을 목표로 하며, Generator model과 Discriminative model이 경쟁하며 서로의 성능을 높여가는 재미있는 모델입니다. \n  - paper에서 나온 예시를 들면, `Generator(G)` 모델은 위조 지폐를 만드는 사람들과 유사하며, `Discriminator(D)` 모델은 위조지폐를 발견하는 경찰과 유사합니다. 생성자는 최대한 기존의 데이터(실제 지폐)와 유사한 지폐를 만들려고 노력하고, 판별자는 데이터 샘플이 모델 분포에서 왔는지(위조지폐), 실제 데이터 분포에서 왔는지(실제 지폐) 판별합니다.\n  ![](https://github.com/happy-jihye/GAN/blob/main/images/gan3.png?raw=1)\n  - 즉, **G**는 **가짜 Data를 잘 만들어서 D가 진짜와 가짜를 구별 못하게 하는 것**이 목적이고, **D**는 **진짜 Data와 G가 만들어낸 가짜 Data를 잘 구별하는 것**이 목적입니다.\n  - 이렇게 D와 G가 서로 **경쟁적으로(Adversarially)** 학습을 하다보면, 실제로 서로에게 학습의 방향성을 제시해주게 되어 `Unsupervised Learning`이 가능해집니다.\n\n![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/gan3.jpg?raw=1)\n\n### Generator \n\n- **G**는 **random noise**를 input으로 받습니다. 보통 이 random noise `z`는 Gaussian과 같은 정규 분포에서 무작위로 추출되며, z vector가 존재하던 공간을 `latent space`라고 부릅니다.\n- **G**에 latent $z$를 입력하고 나면 **Neural Network**를 거쳐 **Fake image**인 $G(z)$를 생성하게 됩니다. 이때, $x = G(z)$는 $P_g(x)$라는 확률 분포에서 추출된 $x$라고 생각해도 무방합니다. \n\n### Discriminator\n\n- **G**가 fake image를 생성하고 나면, **D**는 **Fake Image**와 **Real Image**를 input으로 받은 후 **Neural Network**를 거쳐 0과 1사이의 값을 출력하게 됩니다. \n- **D**가 가짜 이미지라고 판별을 하면 0과 가까운 숫자를 출력하고, 진짜 이미지라고 판별을 하면 1과 가까운 숫자를 출력하게 됩니다.\n\n### Object Functions\n\n![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/gan4.png?raw=1)\n\n- GAN을 수식으로 표현하면 다음과 같으며, `minimax game`의 global optimum에 도달하면 **D**는 $D^*_G(x)=\\frac{p_{data}(x)}{p_{data}(x)+p_{g}(x)}$가 되며, **G**는 $p_{data}(x)=p_{g}(x)$ 가 됩니다.\n",
    "*import torch\nimport torch.nn as nn\n\nimport numpy as np\n\n# for MNIST data\nimport torchvision\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable\n\n\nimport matplotlib.pyplot as plt",
    "## Preparing data\n### **Loading MNIST Data**",
    "- 이번 예제에서는 실제 MNIST training images를 활용하여 MNIST 숫자를 생성하는 GAN model을 만들 예정입니다.\n- [How to Build a Streaming DataLoader with PyTorch](https://medium.com/speechmatics/how-to-build-a-streaming-dataloader-with-pytorch-a66dd891d9dd)",
    "# download the MINST data\n\nbatch_size = 64\n\ntransforms_train = transforms.Compose([\n    transforms.Resize(28),\n    transforms.ToTensor(), # data를 pytorch의 tensor형식으로 바꿉니다\n    transforms.Normalize([0.5], [0.5]) # 픽셀값을 0 ~ 1에서 -1 ~ 1 로 바꿔줍니다.\n])\n\ntrain_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n\n# data를 batch size만큼만 가져오는 dataloader를 만듭니다.\ndataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)",
    "- 하나의 batch에 들어있는 mnist data를 출력해보았습니다.",
    "images, labels = next(iter(dataloader))\nimg = torchvision.utils.make_grid(images)\n\nimg = img.numpy().transpose(1,2,0)\nstd = [0.5,0.5,0.5]\nmean = [0.5,0.5,0.5]\nimg = img*std+mean\nprint([labels[i] for i in range(64)])\nplt.imshow(img)",
    "# image \n\nchannels = 1\nimg_size = 28\n\nimg_shape = (channels, img_size, img_size)",
    "## Build Model\n### Generator\n",
    "- 생성자는 random vector `z`를 입력받아 가짜 이미지를 출력하는 함수입니다. 여기서 **z**는 정규분포(Normal Distribution)에서 무작위로 추출한 값으로, z vector가 존재하는 공간을 잠재공간(latent space)라고 부릅니다.\n  - 이 튜토리얼에서는 잠재공간의 크기를 100으로 뒀으며, 잠재공간의 크기에는 제한이 없으나 나타내려고 하는 대상의 정보를 충분히 담을 수 있을 만큼 커야합니다.\n- 즉, 생성자는 단순한 분포에서 사람 얼굴 이미지와 같은 복잡한 분포로 mapping하는 함수라고 볼 수 있습니다.\n![](https://github.com/happy-jihye/GAN/blob/main/images/gan4.png?raw=1)\n\n- 생성자에 충분히 많은 매개변수를 확보하기 위해 여러개의 layer를 쌓아서 생성자를 만들었습니다.\n- [참고](https://dreamgonfly.github.io/blog/gan-explained/)",
    "# dimensionality of the latent space\n# latent vector를 추출하기 위한 noise 분포의 dimension (정규분포를 따름)\nlatent_dim = 100\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        def block(input_dim, output_dim, normalize=True):\n            layers = [nn.Linear(input_dim, output_dim)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        # generater의 model은 여러개의 block을 쌓아서 만들어짐\n        self.model = nn.Sequential(\n            *block(latent_dim, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh() \n        )\n\n    def forward(self, z): \n        # z : input noise vector \n        img = self.model(z)\n        img = img.view(img.size(0), *img_shape)\n        return img",
    "### Discriminator",
    "![](https://github.com/happy-jihye/GAN/blob/main/images/gan2.png?raw=1)",
    "class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid(),\n        )\n\n    # 이미지에 대한 판별 결과를 반환\n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n\n        return validity",
    "### Loss Function & Optimizer\n\n- 손실 함수로는 Binary Cross Entropy를, 최적화 함수로는 Adam을 사용합니다.",
    "''' Hyper parameter '''\n# learning rate\nlr = 0.0002\n\n# decay of first order momentum of gradient\nb1 = 0.5\nb2 = 0.999\n\n\n# Initialize generator and discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n# Loss function\nadversarial_loss = nn.BCELoss()\n\n# Adam Optimizer\noptimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))",
    "# GPU\ncuda = True if torch.cuda.is_available() else False\n\nif cuda : \n  generator.cuda()\n  discriminator.cuda()\n  adversarial_loss.cuda()",
    "## Training",
    "- GAN model에서는 근사적인 추론이나 Markov chains을 사용하지 않고, back-propagation만을 이용하여 gradient를 업데이트합니다.",
    "import time\n\n# number of epochs of training\nn_epochs = 200 \n\n# interval between image samples\nsample_interval = 2000 \n\nstart_time = time.time()\n\nTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n\n\nfor epoch in range(n_epochs):\n    for i, (imgs, _) in enumerate(dataloader):\n\n        # Adversarial ground truths\n        ## 실제 이미지는 1로, 가짜 이미지는 0으로 label됩니다. \n        real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n\n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n\n        # -----------------\n        #  Train Generator\n        # -----------------\n\n        optimizer_G.zero_grad()\n\n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n\n        # Generate a batch of images\n        ## random sampling한 값인 z를 생성자에 넣어 이미지를 생성합니다.\n        generated_imgs = generator(z)\n\n        # Loss measures generator's ability to fool the discriminator\n        ## 생성된 이미지를 discriminator가 판별하게 한 후, loss값을 계산합니다.\n        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n\n        # 생성자(generator) 업데이트\n        g_loss.backward()\n        optimizer_G.step()\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        optimizer_D.zero_grad()\n\n        # Measure discriminator's ability to classify real from generated samples\n        ## 실제 이미지는 real(1)로, 가짜 이미지는 fake(0)으로 판별하도록 계산합니다.\n        real_loss = adversarial_loss(discriminator(real_imgs), real)\n        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n\n        # 판별자(discriminator) 업데이트\n        d_loss.backward()\n        optimizer_D.step()\n\n        done = epoch * len(dataloader) + i\n        if done % sample_interval == 0:\n            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n            save_image(generated_imgs.data[:25], f\"data{epoch}.png\", nrow=5, normalize=True)\n\n    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")",
    "## Image\n|epoch 0| epoch 51 | epoch 100 | epoch 151 | epoch 198 |\n|---|---|---|---|---|\n| ![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/data0.png?raw=1) | ![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/data51.png?raw=1) | ![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/data100.png?raw=1) | ![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/data151.png?raw=1) | ![](https://github.com/happy-jihye/happy-jihye.github.io/blob/master/_posts/images/1_GAN_files/data198.png?raw=1) |",
    "![](/content/data0.png)",
    "## Reference\n- https://hyeongminlee.github.io/post/gan001_gan/"
]