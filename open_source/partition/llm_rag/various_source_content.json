[
    "\n\n\nWhat is RAG\n\nSimple RAG\nIndexing phase\n\nRetrieval phrase\n\n\nLet's code it\nDownload ollama and models\n\nLoading the dataset\n\nImplement the vector database\n\nImplement the retrieval function\n\nGeneration phrase\n\nPutting it all together\n\n\nRooms for improvement\n\nOther types of RAG\n\nConclusion\n\nReferences\n\n",
    "Recently, Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm in the field of AI and Large Language Models (LLMs). RAG combines information retrieval with text generation to enhance language models' performance by incorporating external knowledge sources. This approach has shown promising results in various applications, such as question answering, dialogue systems, and content generation.",
    "In this blog post, we'll explore RAG and build a simple RAG system from scratch using Python and ollama. This project will help you understand the key components of RAG systems and how they can be implemented using fundamental programming concepts.",
    "To begin, let's examine a simple chatbot system without RAG:",
    "While the chatbot can respond to common questions based on its training dataset, it may lack access to the most up-to-date or domain-specific knowledge.",
    "A real-world example would be asking ChatGPT \"What is my mother's name?\". ChatGPT cannot answer this question because it doesn't have access to external knowledge, such as your family members' information.",
    "",
    "To address this limitation, we need to provide external knowledge to the model (in this example, a list of family members' names):",
    "A RAG system consists of two key components:",
    "There are several ways to implement RAG, including Graph RAG, Hybrid RAG, and Hierarchical RAG, which we'll discuss at the end of this post.",
    "Let's create a simple RAG system that retrieves information from a predefined dataset and generates responses based on the retrieved knowledge. The system will comprise the following components:",
    "The indexing phase is the first step in creating a RAG system. It involves breaking the dataset (or documents) into small chunks and calculating a vector representation for each chunk that can be efficiently searched during generation.",
    "The size of each chunk can vary depending on the dataset and the application. For example, in a document retrieval system, each chunk can be a paragraph or a sentence. In a dialogue system, each chunk can be a conversation turn.",
    "After the indexing phrase, each chunk with its corresponding embedding vector will be stored in the vector database. Here is an example of how the vector database might look like after indexing:",
    "The embedding vectors can be later used to retrieve relevant information based on a given query. Think of it as SQL WHERE clause, but instead of querying by exact text matching, we can now query a set of chunks based on their vector representations.",
    "To compare the similarity between two vectors, we can use cosine similarity, Euclidean distance, or other distance metrics. In this example, we will use cosine similarity. Here is the formula for cosine similarity between two vectors A and B:",
    "",
    "Don't worry if you are not familiar with the formula above, we will implement it in the next section.",
    "In the diagram below, we will take an example of a given Input Query from User. We then calculate the Query Vector to represent the query, and compare it against the vectors in the database to find the most relevant chunks.",
    "The result returned by The Vector Database will contains top N most relevant chunks to the query. These chunks will be used by the Chatbot to generate a response.",
    "In this example, we will write a simple Python implement of RAG.",
    "To run the models, we will use ollama, a command line tool that allows you to run models from Hugging Face. With ollama, you don't need to have access to a server or cloud service to run the models. You can run the models directly on your computer.",
    "For the models, let's use the following:",
    "And for the dataset, we will use a simple list of facts about cat. Each fact will be considered as a chunk in the indexing phrase.",
    "First, let's start by installing ollama from project's website: ollama.com",
    "After installed, open a terminal and run the following command to download the required models:",
    "If you see the following output, it means the models are successfully downloaded:",
    "Before continuing, to use ollama in python, let's also install the ollama package:",
    "Next, create a Python script and load the dataset into memory. The dataset contains a list of cat facts that will be used as chunks in the indexing phrase.",
    "You can download the example dataset from here. Here is an example code to load the dataset:",
    "Now, let's implement the vector database.",
    "We will use the embedding model from ollama to convert each chunk into an embedding vector, then store the chunk and its corresponding vector in a list.",
    "Here is an example function to calculate the embedding vector for a given text:",
    "In this example, we will consider each line in the dataset as a chunk for simplicity.",
    "Next, let's implement the retrieval function that takes a query and returns the top N most relevant chunks based on cosine similarity. We can imagine that the higher the cosine similarity between the two vectors, the \"closer\" they are in the vector space. This means they are more similar in terms of meaning.",
    "Here is an example function to calculate the cosine similarity between two vectors:",
    "Now, let's implement the retrieval function:",
    "In this phrase, the chatbot will generate a response based on the retrieved knowledge from the step above. This is done by simply add the chunks into the prompt that will be taken as input for the chatbot.",
    "For example, a prompt can be constructed as follows:",
    "We then use the ollama to generate the response. In this example, we will use instruction_prompt as system message:",
    "You can find the final code in this file. To run the code, save it to a file named demo.py and run the following command:",
    "You can now ask the chatbot questions, and it will generate responses based on the retrieved knowledge from the dataset.",
    "So far, we have implemented a simple RAG system using a small dataset. However, there are still many limitations:",
    "In practice, there are many ways to implement RAG systems. Here are some common types of RAG systems:",
    "For other types of RAG, you can refer to the this post by Rajeev Sharma.",
    "RAG represents a significant advancement in making language models more knowledgeable and accurate. By implementing a simple RAG system from scratch, we've explored the fundamental concepts of embedding, retrieval, and generation. While our implementation is basic, it demonstrates the core principles that power more sophisticated RAG systems used in production environments.",
    "The possibilities for extending and improving RAG systems are vast, from implementing more efficient vector databases to exploring advanced architectures like Graph RAG and Hybrid RAG. As the field continues to evolve, RAG remains a crucial technique for enhancing AI systems with external knowledge while maintaining their generative capabilities."
]