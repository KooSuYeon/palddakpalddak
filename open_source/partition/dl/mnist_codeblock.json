[
    "*import torch\nimport torch.nn as nn\n\nimport numpy as np\n\n# for MNIST data\nimport torchvision\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\nfrom torchvision.utils import save_image\nfrom torch.autograd import Variable\n\n\nimport matplotlib.pyplot as plt",
    "# download the MINST data\n\nbatch_size = 64\n\ntransforms_train = transforms.Compose([\n    transforms.Resize(28),\n    transforms.ToTensor(), # data를 pytorch의 tensor형식으로 바꿉니다\n    transforms.Normalize([0.5], [0.5]) # 픽셀값을 0 ~ 1에서 -1 ~ 1 로 바꿔줍니다.\n])\n\ntrain_dataset = datasets.MNIST(root=\"./dataset\", train=True, download=True, transform=transforms_train)\n\n# data를 batch size만큼만 가져오는 dataloader를 만듭니다.\ndataloader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True, num_workers=4)",
    "images, labels = next(iter(dataloader))\nimg = torchvision.utils.make_grid(images)\n\nimg = img.numpy().transpose(1,2,0)\nstd = [0.5,0.5,0.5]\nmean = [0.5,0.5,0.5]\nimg = img*std+mean\nprint([labels[i] for i in range(64)])\nplt.imshow(img)",
    "# image \n\nchannels = 1\nimg_size = 28\n\nimg_shape = (channels, img_size, img_size)",
    "# dimensionality of the latent space\n# latent vector를 추출하기 위한 noise 분포의 dimension (정규분포를 따름)\nlatent_dim = 100\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n\n        def block(input_dim, output_dim, normalize=True):\n            layers = [nn.Linear(input_dim, output_dim)]\n            if normalize:\n                layers.append(nn.BatchNorm1d(output_dim, 0.8))\n            layers.append(nn.LeakyReLU(0.2, inplace=True))\n            return layers\n\n        # generater의 model은 여러개의 block을 쌓아서 만들어짐\n        self.model = nn.Sequential(\n            *block(latent_dim, 128, normalize=False),\n            *block(128, 256),\n            *block(256, 512),\n            *block(512, 1024),\n            nn.Linear(1024, int(np.prod(img_shape))),\n            nn.Tanh() \n        )\n\n    def forward(self, z): \n        # z : input noise vector \n        img = self.model(z)\n        img = img.view(img.size(0), *img_shape)\n        return img",
    "class Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.model = nn.Sequential(\n            nn.Linear(int(np.prod(img_shape)), 512),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(512, 256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Linear(256, 1),\n            nn.Sigmoid(),\n        )\n\n    # 이미지에 대한 판별 결과를 반환\n    def forward(self, img):\n        img_flat = img.view(img.size(0), -1)\n        validity = self.model(img_flat)\n\n        return validity",
    "''' Hyper parameter '''\n# learning rate\nlr = 0.0002\n\n# decay of first order momentum of gradient\nb1 = 0.5\nb2 = 0.999\n\n\n# Initialize generator and discriminator\ngenerator = Generator()\ndiscriminator = Discriminator()\n\n# Loss function\nadversarial_loss = nn.BCELoss()\n\n# Adam Optimizer\noptimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\noptimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))",
    "# GPU\ncuda = True if torch.cuda.is_available() else False\n\nif cuda : \n  generator.cuda()\n  discriminator.cuda()\n  adversarial_loss.cuda()",
    "import time\n\n# number of epochs of training\nn_epochs = 200 \n\n# interval between image samples\nsample_interval = 2000 \n\nstart_time = time.time()\n\nTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n\n\nfor epoch in range(n_epochs):\n    for i, (imgs, _) in enumerate(dataloader):\n\n        # Adversarial ground truths\n        ## 실제 이미지는 1로, 가짜 이미지는 0으로 label됩니다. \n        real = Variable(Tensor(imgs.size(0), 1).fill_(1.0), requires_grad=False)\n        fake = Variable(Tensor(imgs.size(0), 1).fill_(0.0), requires_grad=False)\n\n        # Configure input\n        real_imgs = Variable(imgs.type(Tensor))\n\n        # -----------------\n        #  Train Generator\n        # -----------------\n\n        optimizer_G.zero_grad()\n\n        # Sample noise as generator input\n        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n\n        # Generate a batch of images\n        ## random sampling한 값인 z를 생성자에 넣어 이미지를 생성합니다.\n        generated_imgs = generator(z)\n\n        # Loss measures generator's ability to fool the discriminator\n        ## 생성된 이미지를 discriminator가 판별하게 한 후, loss값을 계산합니다.\n        g_loss = adversarial_loss(discriminator(generated_imgs), real)\n\n        # 생성자(generator) 업데이트\n        g_loss.backward()\n        optimizer_G.step()\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        optimizer_D.zero_grad()\n\n        # Measure discriminator's ability to classify real from generated samples\n        ## 실제 이미지는 real(1)로, 가짜 이미지는 fake(0)으로 판별하도록 계산합니다.\n        real_loss = adversarial_loss(discriminator(real_imgs), real)\n        fake_loss = adversarial_loss(discriminator(generated_imgs.detach()), fake)\n        d_loss = (real_loss + fake_loss) / 2\n\n        # 판별자(discriminator) 업데이트\n        d_loss.backward()\n        optimizer_D.step()\n\n        done = epoch * len(dataloader) + i\n        if done % sample_interval == 0:\n            # 생성된 이미지 중에서 25개만 선택하여 5 X 5 격자 이미지에 출력\n            save_image(generated_imgs.data[:25], f\"data{epoch}.png\", nrow=5, normalize=True)\n\n    # 하나의 epoch이 끝날 때마다 로그(log) 출력\n    print(f\"[Epoch {epoch}/{n_epochs}] [D loss: {d_loss.item():.6f}] [G loss: {g_loss.item():.6f}] [Elapsed time: {time.time() - start_time:.2f}s]\")"
]