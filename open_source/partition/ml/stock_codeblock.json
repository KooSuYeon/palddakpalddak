[
    "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)",
    "!sudo apt-get install -y fonts-nanum\n!sudo fc-cache -fv\n!rm ~/.cache/matplotlib -rf\nimport matplotlib as mpl\nimport matplotlib.font_manager as fm\nimport matplotlib.pyplot as plt\n#plt.rc('font', family='NanumSquareRound') ",
    "import matplotlib.pyplot as plt\n\nplt.rc('font', family='NanumSquareRound') ",
    "import pandas_datareader.data as web\nfrom datetime import datetime\n\nkospi200 = web.DataReader('KPI200', 'naver', start='2011-02-01', end='2021-02-23')\nkospi200",
    "!pip install --upgrade mplfinance",
    "kospi200daily = kospi200[['Open','High','Low','Close','Volume']].iloc[-250:]\nkospi200daily = kospi200daily.astype('float')",
    "import mplfinance as mpf\nmpf.plot(kospi200daily,type='candle',mav=(5,20, 60),\n         style='charles', \n         title='Kospi200, Feb 2020 to Feb 2021',\n         figratio=(29,14),volume=True)",
    "import pandas_datareader.data as web\nfrom datetime import datetime\n\nkodex200  = web.DataReader('069500', 'naver', start='2011-02-01', end='2021-02-23')\nkodex200",
    "kodex200.info()",
    "kodex200 = kodex200.astype('float')\nfig = plt.figure(figsize=(10,5))\nax1 = fig.add_subplot(1, 2, 1)\nax1 = sns.boxplot(kodex200['Close']);\n\nax2 = fig.add_subplot(1, 2, 2)\n\n#ax1.plot(x, y)\n#ax2.bar(x, y)\n\nax2=sns.boxplot(kodex200['Volume']);\n\nplt.show()\n",
    "kodex200daily = kodex200[-250:]\nkodex200daily = kodex200daily.astype('float')",
    "mpf.plot(kodex200daily,type='candle',mav=(5,20, 60),\n         style='charles', \n         title='Kodex200, Feb 2020 to Feb 2021',\n         figratio=(15,8),volume=True)\n",
    "sns.set_style('white')\nsns.set_palette('cividis')\nkodex200 = kodex200.astype('float')\nplt.title(\"Kodex200, Feb 2011 to Feb 2021\")\nkodex200['Close'].plot();",
    "from statsmodels.tsa.stattools import kpss\nprint(kpss(kodex200['Close'], regression='ct') )",
    "#차분 구하기\nkodex200 = kodex200.astype('float')\nkodex200['Diff'] =  np.r_[0, np.diff(kodex200['Close'])]\nkodex200",
    "import seaborn as sns\nimport matplotlib\nmatplotlib.rcParams['axes.unicode_minus'] = False\nsns.set_palette('cividis')\nkodex200['Diff'].plot();",
    "from statsmodels.tsa.stattools import kpss\nprint(kpss(kodex200['Diff'], regression='ct') )",
    "import matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplot_acf(kodex200['Close'])\nplot_pacf(kodex200['Close'])\nplt.show()",
    "import matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplot_acf(kodex200['Diff'])\nplot_pacf(kodex200['Diff'])\nplt.show()",
    "kodex200['return'] = kodex200['Close'].pct_change() * 100  #pct_change(5) 5일간 수익률\nkodex200 = kodex200.dropna()",
    "print(kpss(kodex200['return'], regression='ct') )",
    "import matplotlib.pyplot as plt\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nplot_acf(kodex200['return'])\nplot_pacf(kodex200['return'])\nplt.show()",
    "def engineer(df):\n  df = df.astype('float')\n  \n  #5일 단순이동평균(sma)\n  df['sma5'] = df['Close'].rolling(window=5, min_periods=1).mean()\n\n  \n  #5일 지수이동평균(ema)\n  df['ema5'] = df['Close'].ewm(5).mean()\n  #20일 지수이동평균\n  df['ema20'] = df['Close'].ewm(20).mean()\n\n  #이격도\n  df['disparity'] = df['Close'] - df['sma5']\n  \n  #Stochastic K, D : Fast %K의 m기간 이동평균(SMA)\n  df['fast_k'] = ((df['Close'] - df['Low'].rolling(5).min()) / (df['High'].rolling(5).max() - df['Low'].rolling(5).min())) * 100\n  df['Slow_k'] = df['fast_k'].rolling(3).mean()\n  df['Slow_d'] = df['Slow_k'].rolling(3).mean()\n\n  #MACD\n  df['EMAFast'] = df['Close'].ewm( span = 5, min_periods = 4).mean()\n  df['EMASlow'] = df['Close'].ewm( span = 20, min_periods = 19).mean()\n  df['MACD'] = df['EMAFast'] - df['EMASlow']\n  #df['MACDSignal'] = df['MACD'].ewm( span = 9, min_periods = 8).mean()\n  #df['MACDDiff'] = df['MACD'] - df['MACDSignal']\n\n  #RSI\n  delta = df['Close'].diff(5)\n  delta = delta.dropna()\n\n  up = delta.copy()\n  down = delta.copy()\n\n  up[up<0] = 0\n  down[down>0] = 0\n\n  df['up'] = up\n  df['down'] = down\n\n  AVG_Gain = df['up'].rolling(window = 5).mean()\n  AVG_Loss = abs(df['down'].rolling(window = 5).mean())\n  RS = AVG_Gain/AVG_Loss\n\n  RSI = 100.0 - (100.0/(1+RS))\n  df['RSI'] = RSI \n\n  df['Diff'] =  np.r_[0, np.diff(df['Close'])]\n\n  df = df.drop(columns=['Open', 'Close', 'High','Low', 'fast_k', 'EMAFast', 'EMASlow', 'up', 'down'])\n  df = df.dropna()\n\n  df = df.reset_index() #time_series_split할 때 필요\n\n\n  return df",
    "len(kodex200)*0.2",
    "kodex200test = kodex200[-495:]\nkodex200train = kodex200.drop(index=kodex200test.index)\nkodex200train.shape, kodex200test.shape",
    "#특성 공학\nkodex200train = engineer(kodex200train)\nkodex200test = engineer(kodex200test)",
    "kodex200train = kodex200train.drop(columns=['return'])\nkodex200test = kodex200test.drop(columns=['return'])",
    "from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.metrics import mean_squared_error\n\ntscv = TimeSeriesSplit(n_splits=10)\n\ntarget = 'Diff'\ny =kodex200train[target]\nX =kodex200train.drop(columns = target)\n\nX = X.dropna()\ny= y.dropna()\n\nX = X.drop(columns='Date')\n\npred1 = []\nscores = []\nmses = []\nfor train_index, val_index in tscv.split(kodex200train):\n\n    X_train   = X.iloc[train_index] #drop('Date', axis=1)\n    y_train = y.iloc[train_index]\n\n    X_val    = X.iloc[val_index] \n    y_val  = y.iloc[val_index]\n\n\n    ols = LinearRegression()\n    ols.fit(X_train,y_train)\n\n    preds = ols.predict(X_val)\n    pred1.append(preds)\n    mse = mean_squared_error(y_val, preds)\n    r2score = ols.score(X_val,y_val)\n    mses.append(mse)\n    scores.append(r2score)\n\naverage_r2score = np.mean(scores)\nprint(average_r2score)\nprint(np.mean(mses))",
    "print(\"평균 r2 점수: \", average_r2score)\nprint(\"평균 mse:\",np.mean(mses))",
    "scores",
    "y_val.plot();",
    "new_df1 = kodex200[(kodex200.index >= '2018-05-29')&(kodex200.index <= '2019-02-20')]\nnew_df1",
    "new_df2 = new_df1.drop(columns=['Open','High','Low','Volume','Diff','return'])",
    "val_pred = pd.DataFrame(pred1).T\nval_pred",
    "val_pred.iloc[0,:] = val_pred.iloc[0,:] + 30130.0\nval_pred",
    "val_pred2 = val_pred.cumsum()",
    "val_pred2 = round(val_pred2, 1)\nval_pred2",
    "val_pred2['avg'] = val_pred2.mean(axis=1)\nval_pred2",
    "val_pred2.iloc[:,0].plot()\nval_pred2.iloc[:,1].plot()\nval_pred2.iloc[:,2].plot()\nval_pred2.iloc[:,3].plot()\nval_pred2.iloc[:,4].plot()\nval_pred2.iloc[:,5].plot()\nval_pred2.iloc[:,6].plot()\nval_pred2.iloc[:,7].plot()\nval_pred2.iloc[:,8].plot()\nval_pred2.iloc[:,9].plot()\nval_pred2.iloc[:, 10].plot()\nnew_df2.plot()",
    "val_pred2.index = new_df2.index\n",
    "plot_df = pd.concat([new_df2['Close'], val_pred2['avg']], axis=1)\nplot_df",
    "sns.set_palette('PuRd')\nplot_df.plot()",
    "!pip install eli5",
    "import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport eli5\nfrom eli5.sklearn import PermutationImportance\n\n# permuter 정의\npermuter = PermutationImportance(\n    ols,\n    scoring='r2', # metric\n    n_iter=5, # 다른 random seed를 사용하여 5번 반복\n    random_state=2\n)\n\n\npermuter.fit(X_val, y_val);",
    "feature_names = X_val.columns.tolist()\neli5.show_weights(\n    permuter, \n    top=None, # top n 지정 가능, None 일 경우 모든 특성 \n    feature_names=feature_names # list 형식으로 넣어야 합니다\n)",
    "from xgboost import XGBRegressor\n'''\ntarget = 'Diff'\ny =kodex200train[target]\nX =kodex200train.drop(columns = target)\n\nX = X.dropna()\ny= y.dropna()\n\nX = X.drop(columns='Date')\n'''\nscores_xgb = []\nmse_xgb = []\npreds_xgb = []\n\nfor train_index, val_index in tscv.split(kodex200train):\n\n    X_train2   = X.iloc[train_index] #drop('Date', axis=1)\n    y_train2 = y.iloc[train_index]\n\n    X_val2  = X.iloc[val_index] #.drop('record_date', axis=1)\n    y_val2  = y.iloc[val_index]\n\n    # if needed, do preprocessing here\n\n    xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.08, gamma=0,\n                            max_depth=7)\n    xgb_model.fit(X_train2, y_train2)\n\n    pred_xgb = xgb_model.predict(X_val2)\n    preds_xgb.append(pred_xgb)\n\n    r2score_xgb = xgb_model.score(X_val2,y_val2)\n    scores_xgb.append(r2score_xgb)\n\n    mse_xg = mean_squared_error(y_val2, pred_xgb)\n    mse_xgb.append(mse_xg)\naverage_r2score_xgb = np.mean(scores_xgb)\nprint(\"평균 r2 score: \",average_r2score_xgb)\nprint(\"평균 mse: \",np.mean(mse_xgb))",
    "import eli5\nfrom eli5.sklearn import PermutationImportance\n\n# permuter 정의\npermuter2 = PermutationImportance(\n    xgb_model,\n    scoring='r2', # metric\n    n_iter=5, \n    random_state=2\n)\n\n\npermuter2.fit(X_val2, y_val2);",
    "feature_names2 = X_val2.columns.tolist()\neli5.show_weights(\n    permuter2, \n    top=None, \n    feature_names=feature_names2 \n)",
    "#모델1,2에서 사용된 훈련 데이터 + 검증 데이터\narima_df = kodex200[(kodex200.index<='2019-02-21') & (kodex200.index>'2011-03-15')] ",
    "from statsmodels.tsa.arima_model import ARIMA\nmod = ARIMA(arima_df['Diff'], order=(1, 1, 0)) \nres = mod.fit(trend='c',full_output=True, disp=0)\nprint(res.summary())",
    "residuals = pd.DataFrame(res.resid)\nfig = plt.figure(figsize=(10,5))\n\n#ax1 = fig.add_subplot(1, 2, 1)\nax1 = residuals.plot(title=\"Residuals\")\n\n#ax2 = fig.add_subplot(1, 2, 2)\nax2 = residuals.plot(kind='kde', title='Density')\n\nplt.show()",
    "plt.style.use('ggplot')\nres.plot_predict(dynamic=False)\nplt.show()",
    "def engineer2(df):\n  df = df.astype('float')\n  \n  #5일 단순이동평균(sma)\n  df['sma5'] = df['Close'].rolling(window=5, min_periods=1).mean()\n\n  \n  #5일 지수이동평균(ema)\n  df['ema5'] = df['Close'].ewm(5).mean()\n  #20일 지수이동평균\n  df['ema20'] = df['Close'].ewm(20).mean()\n\n  #이격도\n  df['disparity'] = df['Close'] - df['sma5']\n  \n  #Stochastic K, D : Fast %K의 m기간 이동평균(SMA)\n  df['fast_k'] = ((df['Close'] - df['Low'].rolling(5).min()) / (df['High'].rolling(5).max() - df['Low'].rolling(5).min())) * 100\n  df['Slow_k'] = df['fast_k'].rolling(3).mean()\n  df['Slow_d'] = df['Slow_k'].rolling(3).mean()\n\n  #MACD\n  df['EMAFast'] = df['Close'].ewm( span = 5, min_periods = 4).mean()\n  df['EMASlow'] = df['Close'].ewm( span = 20, min_periods = 19).mean()\n  df['MACD'] = df['EMAFast'] - df['EMASlow']\n  #df['MACDSignal'] = df['MACD'].ewm( span = 9, min_periods = 8).mean()\n  #df['MACDDiff'] = df['MACD'] - df['MACDSignal']\n\n  #RSI\n  delta = df['Close'].diff(5)\n  delta = delta.dropna()\n\n  up = delta.copy()\n  down = delta.copy()\n\n  up[up<0] = 0\n  down[down>0] = 0\n\n  df['up'] = up\n  df['down'] = down\n\n  AVG_Gain = df['up'].rolling(window = 5).mean()\n  AVG_Loss = abs(df['down'].rolling(window = 5).mean())\n  RS = AVG_Gain/AVG_Loss\n\n  RSI = 100.0 - (100.0/(1+RS))\n  df['RSI'] = RSI \n\n  df['Diff'] =  np.r_[0, np.diff(df['Close'])]\n\n  df = df.drop(columns=['Open', 'High','Low', 'fast_k', 'EMAFast', 'EMASlow', 'up', 'down'])\n  df = df.dropna()\n\n  df = df.reset_index() #time_series_split할 때 필요\n\n\n  return df",
    "#타겟값 만들기\ndef define_target_condition(df):\n \n    # price above trend multiple days later\n    df['target_cls'] = np.where(df['Close'].shift(-20) > df.ema20.shift(-20), 1, 0)\n\n    # important, remove NaN values\n    df=df.fillna(0).copy()\n    \n    df.tail()\n    \n    return df",
    "kodex200test2 = kodex200[-495:]\nkodex200train2 = kodex200.drop(index=kodex200test2.index)\nkodex200train2.shape, kodex200test2.shape",
    "kodex200train2 = engineer2(kodex200train2)\nkodex200test2 = engineer2(kodex200test2)\nkodex200train2 =define_target_condition(kodex200train2)\nkodex200test2 = define_target_condition(kodex200test2)",
    "kodex200train2",
    "kodex200train2['target_cls'].value_counts(normalize=True)",
    "print('베이스라인 모델 검증 정확도: ', 0.543556)",
    "eval_set = [(X_train2, y_train2), \n            (X_val2, y_val2)]\n\nmodel.fit(X_train2, y_train2, \n          eval_set=eval_set,\n          eval_metric='error', # #(wrong cases)/#(all cases)\n          early_stopping_rounds=50\n         ) # 50 rounds 동안 스코어의 개선이 없으면 멈춤",
    "kodex200train2 = kodex200train2.drop(columns = ['return','Diff'])",
    "from xgboost import XGBClassifier\n#from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report, f1_score, precision_score, recall_score\n\ntarget2 = 'target_cls'\n\ny2 =kodex200train2[target2]\nX2 =kodex200train2.drop(columns = target2)\n\nX2 = X2.dropna()\ny2= y2.dropna()\n\nX2 = X2.drop(columns='Date')\n\nscores_xgbc = []\npreds_xgbc = []\nf1_score1 = []\nprec_score = []\nrec_score = []\n\nfor train_index, val_index in tscv.split(kodex200train2):\n\n    X2_train   = X2.iloc[train_index] #drop('Date', axis=1)\n    y2_train = y2.iloc[train_index]\n\n    X2_val  = X2.iloc[val_index] #.drop('record_date', axis=1)\n    y2_val  = y2.iloc[val_index]\n\n    # if needed, do preprocessing here\n\n    xgb = XGBClassifier(n_estimators=1000, learning_rate=0.08, gamma=0,\n                            max_depth=7)\n    #xgb.fit(X2_train, y2_train, eval_metric='error', early_stopping_rounds=50)\n    eval_set = [(X2_train, y2_train), \n            (X2_val, y2_val)]\n\n    xgb.fit(X2_train, y2_train, \n          eval_set=eval_set,\n          eval_metric='error', # #(wrong cases)/#(all cases)\n          early_stopping_rounds=50\n         ) \n\n    pred_xgbc = xgb.predict(X2_val)\n    preds_xgbc.append(pred_xgbc)\n\n    score_xgbc = xgb.score(X2_val,y2_val)\n    scores_xgbc.append(score_xgbc)\n\n   # preci = precision_score(X2_val,pred_xgbc)\n    #prec_score.append(preci)\n\n    #recall_s = recall_score(X2_val, pred_xgbc)\n    #rec_score.append(recall_s)\n\n    #f1 = f1_score(X2_val, pred_xgbc)\n    #f1_score1.append(f1)\n\naverage_score_xgbc = np.mean(scores_xgbc)\n#average_f1_score = np.mean(f1_score1)\nprint(\"평균 accuracy score: \",average_score_xgbc)\n#print(\"평균 f1: \",np.mean(average_f1_score))",
    "from xgboost import XGBClassifier\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV\nimport numpy as np\n\nxgb_f = xgb.XGBClassifier()\nparam_search = {'booster' :['gbtree'],\n                'max_depth' : [3, 5, 10],\n                'gamma':[0,1,2,3],\n                'n_estimators':[50, 100, 1000],\n                'objective':['binary:logistic'],\n                'random_state':[2]}\n\n#tscv = TimeSeriesSplit(n_splits=10)\ngsearch = GridSearchCV(estimator=xgb_f, cv=tscv,\n                        param_grid=param_search, scoring ='f1', verbose=1, n_jobs=-1)\n\ngsearch.fit(X2_train, y2_train)\n            ",
    "print('최적 하이퍼파라미터: ', gsearch.best_params_)\nprint('f1: ', gsearch.best_score_)",
    "xgb_f = xgb.XGBClassifier()\nparam_search = {'booster' :['gbtree'],\n                'max_depth' : [5, 7],\n                'gamma':[3, 4,5],\n                'n_estimators':[100, 150, 200],\n                'objective':['binary:logistic'],\n                'random_state':[2]}\n\n\ngsearch = GridSearchCV(estimator=xgb_f, cv=tscv,      #모델 1부터 쓰던 timeseries cv를 사용\n                        param_grid=param_search, scoring ='f1', verbose=1, n_jobs=-1)\n\ngsearch.fit(X2_train, y2_train)\n\nprint('최적 하이퍼파라미터: ', gsearch.best_params_)\nprint('f1: ', gsearch.best_score_)",
    "pipe = gsearch.best_estimator_",
    "y_pred_v = pipe.predict(X2_val)\naccu_grid = accuracy_score(y2_val, y_pred_v)\nf1_grid = f1_score(y2_val, y_pred_v)\nprint(f'검증세트 정확도: {accu_grid:,.3f}')\nprint(f'검증세트 f1 score: {f1_grid:,.3f}')",
    "X2_train.columns",
    "X_train3 = kodex200train2.drop(columns=['Date','target_cls'])\ny_train3 = kodex200train2['target_cls']\nX_train3.shape, y_train3.shape",
    "from xgboost import XGBClassifier\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV\nimport numpy as np\n\nxgb_f = xgb.XGBClassifier()\nparam_search = {'booster' :['gbtree'],\n                'max_depth' : [3, 5, 10],\n                'gamma':[0,1,2,3],\n                'n_estimators':[50, 100, 1000],\n                'objective':['binary:logistic'],\n                'random_state':[2]}\n\n#tscv = TimeSeriesSplit(n_splits=10)\ngsearch = GridSearchCV(estimator=xgb_f, cv=tscv,\n                        param_grid=param_search, scoring ='f1', verbose=1, n_jobs=-1)\n\ngsearch.fit(X_train3, y_train3)",
    "kodex200test2\n\nX_test = kodex200test2.drop(columns=['Date','target_cls'])\ny_test = kodex200test2['target_cls']\nX_test.shape, y_test.shape",
    "X_test = X_test.drop(columns=['Diff','return'])",
    "pipe2 = gsearch.best_estimator_",
    "y_pred = pipe2.predict(X_test)\naccu_grid2 = accuracy_score(y_test, y_pred)\nf1_grid2 = f1_score(y_test, y_pred)\nprint(f'테스트세트 정확도: {accu_grid2:,.3f}')\nprint(f'테스트세트 f1 score: {f1_grid2:,.3f}')",
    "#ROC curve\nfrom sklearn.metrics import roc_curve\nimport matplotlib.pyplot as plt\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n\nplt.scatter(fpr, tpr, color='#413c69')\nplt.plot(fpr, tpr, color='#bd2000')\nplt.title('ROC curve')\nplt.xlabel('FPR')\nplt.ylabel('TPR')",
    "from sklearn.metrics import roc_auc_score\n\ny_pred_proba = pipe2.predict_proba(X_test)[:, -1]\nprint('AUC score: ', roc_auc_score(y_test, y_pred_proba))",
    "# permuter 정의\npermuter_f = PermutationImportance(\n    pipe2, # model\n    scoring='f1', # metric\n    n_iter=5, # 다른 random seed를 사용하여 5번 반복\n    random_state=2\n)\n\npermuter_f.fit(X_test, y_test);",
    "feature_names_f = X_test.columns.tolist()\npd.Series(permuter_f.feature_importances_, feature_names_f).sort_values()\n\n# 특성별 score 확인  #여러 번 섞은 결과임\neli5.show_weights(\n    permuter_f, \n    # top n 지정 가능, None 일 경우 모든 특성 \n    feature_names=feature_names_f # list 형식으로 넣어야 합니다\n)",
    "X_test.tail(5)",
    "!pip install shap",
    "row = X_test.iloc[[-1]]\npipe2.predict(row)",
    "import shap\n\nexplainer = shap.TreeExplainer(pipe2)\nshap_values = explainer.shap_values(row)\n\nshap.initjs()\nshap.force_plot(\n    base_value=explainer.expected_value, \n    shap_values=shap_values,       \n    features=row\n)",
    "tiger200  = web.DataReader('102110', 'naver', start='2011-02-01', end='2021-02-23')\ntiger200\n",
    "kodex_samsung = web.DataReader('102780', 'naver', start='2016-12-27', end='2021-02-23')\nkodex_samsung",
    "kodex200_lev2 = web.DataReader('122630', 'naver', start='2011-02-01', end='2021-02-23')\nkodex200_lev2",
    "tiger_nasdaq100 = web.DataReader('133690', 'naver', start='2011-02-01', end='2021-02-23')\ntiger_nasdaq100",
    "kodex_gold = web.DataReader('132030', 'naver', start='2011-02-01', end='2021-02-23')\nkodex_gold",
    "kodex_bond_short = web.DataReader('153130', 'naver', start='2011-02-01', end='2021-02-23')\nkodex_bond_short",
    "assets = [ 'KODEX200', 'KODEX_Samsung', 'KODEX_WTI', 'KODEX_Bond_Short', 'TIGER_Nasdaq', 'KODEX_LEV']",
    "weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2]) #여기 일단 다섯개",
    "#각 etf별 종가 df로 만들기\ndf = pd.concat([kodex_gold['Close'], tiger_nasdaq100['Close'], kodex200_lev2['Close'], kodex_samsung['Close'], tiger200['Close']],\n               keys=['Kodex_gold','Tiger_nasdaq','Kodex200_lev2','Kodex_samsung','Tiger200'],axis =1)\ndf",
    "df = df.dropna()\ndf",
    "df = df.astype('float')",
    "#시각화\ntitle = 'Portfolio'\n\nmy_etf = df\nplt.figure(figsize=(12,5))\n\nfor c in my_etf.columns.values:\n  plt.plot(my_etf[c], label=c)\n\nplt.title(title)\nplt.xlabel('Date', fontsize=15)\nplt.ylabel('Close price')\nplt.legend(my_etf.columns.values, loc = 'upper left')\nplt.show()",
    "#일일수익률\nreturns = df.pct_change()\nreturns",
    "returns = returns.dropna()",
    "#연간 공분산 행렬\ncov_matrix_annual = returns.cov() * 251\ncov_matrix_annual",
    "#포트폴리오 분산의 기댓값 = weight.T dot (공분산행렬) dot weight\nport_variance = np.dot(weights.T, np.dot(cov_matrix_annual, weights))\nport_variance",
    "#포트폴리오 변동성의 기댓값 = 분산의 기댓값의 제곱근(표준편차)\nport_volatility = np.sqrt(port_variance)\nport_volatility",
    "#포트폴리오 연간 단순 수익률\nport_annual_return = np.sum(returns.mean()*weights)*251",
    "#예상 연간 수익, 변동성 또는 위험 및 분산\npercent_var = str(round(port_variance, 2) * 100)\npercent_vols = str(round(port_volatility, 2) * 100)\npercent_ret = str(round(port_annual_return, 2)* 100)\nprint(\"예상 연간수익률: \", percent_ret, '%')\nprint(\"예상 변동성: \", percent_vols, '%')\nprint(\"예상 분산: \", percent_var, '%')",
    "!pip install PyPortfolioOpt",
    "#포트폴리오 최적화\nfrom pypfopt.efficient_frontier import EfficientFrontier \nfrom pypfopt import risk_models\nfrom pypfopt import expected_returns",
    "mu = expected_returns.mean_historical_return(df)\ns = risk_models.sample_cov(df)",
    "ef = EfficientFrontier(mu,s)\nweights = ef.max_sharpe()\ncleaned_weights = ef.clean_weights()\nprint(cleaned_weights)\nef.portfolio_performance(verbose=True)",
    "#개별 종목 할당\n!pip install pulp",
    "from pypfopt.discrete_allocation import DiscreteAllocation, get_latest_prices\n\nlatest_prices = get_latest_prices(df)\nweights = cleaned_weights\n\nda = DiscreteAllocation(weights, latest_prices, total_portfolio_value=1000000)\nallocation, leftover = da.lp_portfolio()\n\nprint(\"자산 분배: \", allocation)\nprint(\"남은 계좌 잔액: \\{:.2f}\".format(leftover))"
]