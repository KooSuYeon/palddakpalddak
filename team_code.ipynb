{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëŒ€í™” ë‚´ìš©ì„ txt íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , txt íŒŒì¼ì„ ë¶ˆëŸ¬ì™€ì„œ í”¼ë“œë°±ì— ì ìš©í•˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "##### 1.ëŒ€í™” ë‚´ìš© ì €ì¥\n",
    "ì‚¬ìš©ìê°€ ì…ë ¥í•œ í€´ì¦ˆ(quiz)ì™€ ë‹µë³€(answer), ê·¸ë¦¬ê³  AIê°€ ì œê³µí•œ í”¼ë“œë°±(feedback)ì„ íŒŒì¼ì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "- previous_conversationë¼ëŠ” í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- ëŒ€í™” ë‚´ìš©ì„ ì €ì¥í•  íŒŒì¼ ì´ë¦„ì€ í˜„ì¬ ì‹œê°(timestamp)ì„ ê¸°ì¤€ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.\n",
    "- ê° ëŒ€í™”ê°€ ëë‚  ë•Œë§ˆë‹¤ íŒŒì¼ì„ ì—´ê³ , í€´ì¦ˆ, ì‚¬ìš©ì ë‹µë³€, í”¼ë“œë°±ì„ ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "- íŒŒì¼ ì—´ ë•ŒëŠ” \"a\" ëª¨ë“œ(append)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ ë‚´ìš©ì— ìƒˆ ëŒ€í™”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "# ëŒ€í™” ë‚´ìš© ì €ì¥(íŒŒì¼ì— ê¸°ë¡)\n",
    "with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"Quiz: {quiz}\\n\")               # ìƒì„±ëœ í€´ì¦ˆ ì €ì¥\n",
    "    f.write(f\"User Answer: {user_answer}\\n\") # ì‚¬ìš©ì ë‹µë³€ ì €ì¥\n",
    "    f.write(f\"Feedback: {feedback}\\n\")       # AI í”¼ë“œë°± ì €ì¥\n",
    "    f.write(\"-\" * 50 + \"\\n\")                 # êµ¬ë¶„ì„  ì¶”ê°€\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "ì´ì „ ëŒ€í™” ê¸°ë¡ì„ íŒŒì¼ì—ì„œ ì½ì–´ì™€ í˜„ì¬ ëŒ€í™”ì— í™œìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "- íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ë‚´ìš©ì„ ì½ì–´ì˜µë‹ˆë‹¤.\n",
    "- íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´(\"\")ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "- \"r\" ëª¨ë“œ(read)ë¡œ íŒŒì¼ì„ ì—´ì–´ ëª¨ë“  ë‚´ìš©ì„ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        previous_conversation = f.read()  # ì´ì „ ëŒ€í™” ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "else:\n",
    "    previous_conversation = \"\"           # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì´ˆê¸°í™”\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë¬¸ì œì \n",
    "#### ë¬¸ì œ 1\n",
    "feedback_promptì— ë¶ˆëŸ¬ì˜¨ txt íŒŒì¼ì„ ì ìš©í•˜ëŠ” ê³¼ì •ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.   \n",
    "    \n",
    "ì˜¤ë¥˜ : KeyError: 'Input to ChatPromptTemplate is missing variables {\"\\'refusal\\'\", \"\\'input_tokens\\'\", \"\\'token_usage\\'\"}.  Expected: [\"\\'input_tokens\\'\", \"\\'refusal\\'\", \"\\'token_usage\\'\"] Received: [\\'quiz\\', \\'answer\\']\\nNote: if you intended {\\'refusal\\'} to be part of the string and not a variable, please escape it with double curly braces like: \\'{{\\'refusal\\'}}\\'.\\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/INVALID_PROMPT_INPUT '   \n",
    "   \n",
    "ChatPromptTemplateì´ ê¸°ëŒ€í•˜ëŠ” ì…ë ¥ ë³€ìˆ˜ì™€ ì‹¤ì œë¡œ ì œê³µëœ ì…ë ¥ ê°„ì˜ ë¶ˆì¼ì¹˜ë•Œë¬¸ì— ë°œìƒí•œ ì˜¤ë¥˜ë¼ê³  í•©ë‹ˆë‹¤.   \n",
    "input_dataì— í•„ìš”í•œ ë³€ìˆ˜ë“¤ì„ ë„£ì–´ì£¼ê³ , í”¼ë“œë°± ì²´ì¸ì„ í˜¸ì¶œí•  ë•Œ input_dataë¥¼ ë„£ì–´ì£¼ì—ˆìŠµë‹ˆë‹¤.\n",
    "```python\n",
    "# í•„ìš”í•œ ë³€ìˆ˜ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì¶”ê°€\n",
    "    input_data = {\n",
    "        \"quiz\": quiz,\n",
    "        \"answer\": user_answer,\n",
    "        \"previous_conversation\": previous_conversation,\n",
    "        \"refusal\": \"\",  # ê¸°ë³¸ê°’ ì„¤ì •\n",
    "    }\n",
    "\n",
    "    # í”¼ë“œë°± ì²´ì¸ í˜¸ì¶œ\n",
    "    feedback_chain = feedback_prompt | llm\n",
    "    feedback = feedback_chain.invoke(input_data)\n",
    "```  \n",
    "ì˜¤ë¥˜ ì½”ë“œì—ì„œëŠ” 'input_tokens', 'token_usage', 'refusal'ê°€ í•„ìš”í•˜ë‹¤ê³  ë‚˜ì™€ìˆì—ˆìŠµë‹ˆë‹¤.   \n",
    "'input_tokens'ì™€ 'token_usage'ëŠ” ì¶”ê°€í•˜ì§€ ì•Šì•„ë„ ì½”ë“œê°€ ì˜ ì‹¤í–‰ë¼ì„œ ë”°ë¡œ ì¶”ê°€í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.   \n",
    "ê·¸ëŸ¬ë‚˜ 'refusal'ë¥¼ ì¶”ê°€í•˜ì§€ ì•Šìœ¼ë©´ ê³„ì† KeyErrorê°€ ë°œìƒí•´ì„œ refusal=\"None\" ë³€ìˆ˜ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ë¬¸ì œ 2\n",
    "ë³€ìˆ˜ë¥¼ ì¶”ê°€í•œ í›„ì—ë„ TypeError, ValueErrorê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.   \n",
    "ìµœì¢…ì ìœ¼ë¡œ feedback_promptë¥¼ ìˆ˜ì •í•˜ê³ , invoke í˜¸ì¶œ ë°©ì‹ì„ ë³€ê²½í•˜ê³ , input_dataë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.   \n",
    "```python\n",
    "# 3. ì‚¬ìš©ì ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "    AI ê°•ì‚¬ë¡œì„œ ë‹¤ìŒ í€´ì¦ˆì˜ ì •ë‹µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "    í€´ì¦ˆ: {{quiz}}\n",
    "    ë‹µë³€: {{answer}}\n",
    "    ëŒ€í™” ê¸°ë¡: {{previous_conversation}}\n",
    "    ê±°ì ˆ ì‚¬ìœ : {{refusal}}\n",
    "    \"\"\")\n",
    "    ])\n",
    "\n",
    "    # í”¼ë“œë°± ìƒì„± - í‚¤ì›Œë“œ ì¸ìˆ˜ë¡œ ì „ë‹¬\n",
    "    feedback_data = feedback_prompt.format(\n",
    "        quiz=quiz,\n",
    "        answer=user_answer,\n",
    "        previous_conversation=previous_conversation,\n",
    "        refusal=\"None\"\n",
    "    )\n",
    "\n",
    "    # í”¼ë“œë°± ì²´ì¸ í˜¸ì¶œ\n",
    "    feedback = llm.invoke(feedback_data)   # LLMì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í”¼ë“œë°± ìƒì„±\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì½”ë“œ ì‹¤í–‰í•˜ê¸°\n",
    "ê¸°ë³¸ ì½”ë“œ : KooSuYeon/palddakpalddak/8ì¡°_ChatBot_Teamtask.ipynb   \n",
    "ê¸°ë³¸ ì½”ë“œì—ì„œ ì²­í¬ë¥¼ ë‚˜ëˆ„ëŠ” ë¶€ë¶„ê¹Œì§€ëŠ” ë™ì¼í•©ë‹ˆë‹¤.   \n",
    "ì•„ë˜ëŠ” ì‹¤ì œë¡œ ì½”ë“œë¥¼ ì‹¤í–‰í•œ ê²°ê³¼ì…ë‹ˆë‹¤.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ\n",
    "load_dotenv(\"C:/.env\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Selenium ì˜µì…˜ ì„¤ì • (í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰)\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # ë¸Œë¼ìš°ì € ì°½ì„ ë„ìš°ì§€ ì•ŠìŒ\n",
    "chrome_options.add_argument(\"--disable-gpu\")  # GPU ë¹„í™œì„±í™” (ì¼ë¶€ í™˜ê²½ì—ì„œ í•„ìš”)\n",
    "\n",
    "# WebDriver ê²½ë¡œ ì„¤ì • (ìë™ ì„¤ì¹˜)\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "\n",
    "url_list=[]\n",
    "txt_list=[]\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ì— ì €ì¥ëœ URL ë¡œë“œ\n",
    "for i in range(1, 17):  # URL_1 ~ URL_16\n",
    "    url = os.getenv(f\"URL_{i}\")\n",
    "    if url:  # í™˜ê²½ë³€ìˆ˜ê°€ ì¡´ì¬í•˜ë©´ ì¶”ê°€\n",
    "        url_list.append(url)\n",
    "\n",
    "# ì›¹í˜ì´ì§€ ìš”ì²­\n",
    "for url in url_list:\n",
    "    driver.get(url)  # í˜ì´ì§€ ë¡œë“œ\n",
    "\n",
    "    # íŠ¹ì • ìš”ì†Œê°€ ë¡œë“œë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¼ (ì˜ˆ: Notion í˜ì´ì§€ì—ì„œ ì£¼ìš” ì½˜í…ì¸ ê°€ ë‹´ê¸¸ ìš”ì†Œ)\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \".notion-page-content\"))\n",
    "        )\n",
    "    except TimeoutException:\n",
    "        print(f\"í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨: {url}\")\n",
    "        continue\n",
    "    \n",
    "    # í† ê¸€ì´ ë‹«í˜€ ìˆìœ¼ë©´ í† ê¸€ì„ ì—´ê¸°\n",
    "    try:\n",
    "        # ëª¨ë“  í† ê¸€ ë²„íŠ¼ì„ ì°¾ìŒ (Ctrl+Alt+Tì— í•´ë‹¹í•˜ëŠ” í† ê¸€ì„ ì°¾ì•„ì„œ ì—´ê¸°)\n",
    "        toggle_buttons = driver.find_elements(By.XPATH, \"//div[@role='button' and contains(@aria-label, 'ì—´ê¸°')]\")\n",
    "        \n",
    "        # ê° í† ê¸€ì„ í´ë¦­í•˜ì—¬ ì—´ê¸°\n",
    "        for button in toggle_buttons:\n",
    "            button.click()\n",
    "            time.sleep(1)  # í† ê¸€ì´ ì—´ë¦¬ê¸° ì „ì— ì ê¹ ëŒ€ê¸°\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"í† ê¸€ì„ ì—¬ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}\")\n",
    "\n",
    "    # í˜ì´ì§€ì˜ HTML ê°€ì ¸ì˜¤ê¸°\n",
    "    html_code = driver.page_source\n",
    "\n",
    "    # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±\n",
    "    soup = BeautifulSoup(html_code, 'html.parser')\n",
    "\n",
    "    txt = soup.get_text()\n",
    "\n",
    "    # 1. \\xa0ë¥¼ ê³µë°±ìœ¼ë¡œ ë³€í™˜\n",
    "    txt = txt.replace('\\xa0', ' ')\n",
    "\n",
    "    # 2. ì •ê·œì‹ì„ ì‚¬ìš©í•´ \\\\ë¡œ ì‹œì‘í•˜ëŠ” LaTeX ëª…ë ¹ì–´ ì œê±°\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+\\{.*?\\}', '', txt)  # \\command{...} í˜•ì‹ ì œê±°\n",
    "    txt = re.sub(r'\\\\[a-zA-Z]+', '', txt)        # \\command í˜•ì‹ ì œê±°\n",
    "\n",
    "    # 3. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±° (ì½”ë“œ ê°œí–‰ ìœ ì§€ë¥¼ ìœ„í•´ ì£¼ì„ì²˜ë¦¬)\n",
    "    # txt = re.sub(r'\\s+', ' ', txt).strip()\n",
    "\n",
    "    # í…ìŠ¤íŠ¸ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
    "    txt_list.append(txt)\n",
    "\n",
    "\n",
    "driver.quit()  # ë¸Œë¼ìš°ì € ì¢…ë£Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - SVM[SCC] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” ë¨¸ì‹ ëŸ¬ë‹/[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] ë°”ë‹¥ë¶€í„° ì‹œì‘í•˜ëŠ” '\n",
      " 'ë¨¸ì‹ ëŸ¬ë‹ - 3ì£¼ì°¨/[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - SVMì œì‘:[ìŠ¤íŒŒë¥´íƒ€ì½”ë”©í´ëŸ½] 10ê°•. ì§€ë„í•™ìŠµ : ë¶„ë¥˜ëª¨ë¸ - '\n",
      " 'SVM[ìˆ˜ì—… ëª©í‘œ]SVM(Support Vector Machine)ì— ëŒ€í•œ ê°œë…ì„ ë°°ìš°ê³ , ë°ì´í„°ë¥¼ ì´ìš©í•´ ì‹¤ìŠµí•´ ë´…ë‹ˆë‹¤[ëª©ì°¨]01. '\n",
      " 'SVM ê°œë…02. SVM ì‹¤ìŠµğŸ’¡ëª¨ë“  í† ê¸€ì„ ì—´ê³  ë‹«ëŠ” ë‹¨ì¶•í‚¤\\n'\n",
      " 'Windows : Ctrl + alt + t \\n'\n",
      " 'Mac : âŒ˜ + âŒ¥ + t 01. SVM ê°œë…âœ”ï¸SVMì´ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë´…ì‹œë‹¤1) SVM SVMì´ë€?ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (SVM)ì€ ë¶„ë¥˜ì™€ '\n",
      " 'íšŒê·€ ë¶„ì„ì— ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ì§€ë„í•™ìŠµ ëª¨ë¸ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ê¸° ìœ„í•´ ê²°ì • ê²½ê³„(ê²°ì • ì´ˆí‰ë©´, hyperplane)ë¥¼ ì°¾ì•„ ë¶„ë¥˜í•©ë‹ˆë‹¤.ì´ˆí‰ë©´ì€ '\n",
      " 'ë‘ í´ë˜ìŠ¤ ì‚¬ì´ì˜ ìµœëŒ€ ë§ˆì§„ì„ ë³´ì¥í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„ íƒí•©ë‹ˆë‹¤.ALTë§ˆì§„ : ë‘ í´ë˜ìŠ¤ ê°„ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬ë§ˆì§„ : '\n",
      " 'ë‘ í´ë˜ìŠ¤ ê°„ì˜ ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸ ì‚¬ì´ì˜ ê±°ë¦¬\\ufeff\\n'\n",
      " 'ì„œí¬íŠ¸ ë²¡í„° : ê²°ì • ì´ˆí‰ë©´ì— ê°€ì¥ ê°€ê¹Œì´ ìœ„ì¹˜í•œ ë°ì´í„° í¬ì¸íŠ¸ - ê²°ì • ì´ˆí‰ë©´ì„ ì •ì˜í•©ë‹ˆë‹¤ì„œí¬íŠ¸ ë²¡í„° : ê²°ì • ì´ˆí‰ë©´ì— ê°€ì¥ ê°€ê¹Œì´ '\n",
      " 'ìœ„ì¹˜í•œ ë°ì´í„° í¬ì¸íŠ¸ - ê²°ì • ì´ˆí‰ë©´ì„ ì •ì˜í•©ë‹ˆë‹¤\\ufeff\\n'\n",
      " 'ì»¤ë„ í•¨ìˆ˜ : ë°ì´í„°ë¥¼ ë” ë†’ì€ ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê²Œ í•©ë‹ˆë‹¤. ì»¤ë„ í•¨ìˆ˜ : ë°ì´í„°ë¥¼ ë” ë†’ì€ '\n",
      " 'ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜•ì ìœ¼ë¡œ ë¶„ë¦¬ í•  ìˆ˜ ì—†ëŠ” ë°ì´í„°ë¥¼ ë¶„ë¦¬í•˜ê²Œ í•©ë‹ˆë‹¤. \\ufeff\\u200b SVMì˜ ëª©ì SVMì˜ ëª©í‘œëŠ” ë§ˆì§„ì„ '\n",
      " 'ìµœëŒ€í™”í•˜ë©´ì„œ ê²°ì • ì´ˆí‰ë©´ì„ ì°¾ì•„ ë°ì´í„° í¬ì¸íŠ¸ë¥¼ ì •í™•í•˜ê²Œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” ì¼ë°˜í™” ì„±ëŠ¥ì„ ë†’ì´ëŠ” ë° ë„ì›€ì„ '\n",
      " 'ì¤ë‹ˆë‹¤.wâ‹…xâˆ’b=0   - b = 0 wâ‹…xâˆ’b=0ì—¬ê¸°ì„œ wëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, xëŠ” ì…ë ¥ ë²¡í„°, bëŠ” ì ˆí¸ì…ë‹ˆë‹¤.\\\\)ëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, '\n",
      " '\\\\(\\\\)ëŠ” ì…ë ¥ ë²¡í„°, \\\\(b\\\\)ëŠ” ì ˆí¸ì…ë‹ˆë‹¤.}ì—¬ê¸°ì„œ wëŠ” ê°€ì¤‘ì¹˜ ë²¡í„°, xëŠ” ì…ë ¥ ë²¡í„°, bëŠ” '\n",
      " 'ì ˆí¸ì…ë‹ˆë‹¤.\\ufeff\\u200b02. SVM ì‹¤ìŠµâœ”ï¸Scikit-learnì˜ ìœ ë°©ì•”ë°ì´í„°ì™€ Seabornì˜ íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ë¡œ SVM '\n",
      " 'ì‹¤ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤1) ìœ ë°©ì•” ë°ì´í„° ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ìœ ë°©ì•” ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}ìœ ë°©ì•” ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ '\n",
      " '\\ufeff\\u200bPythonë³µì‚¬import numpy as np\\n'\n",
      " 'import pandas as pd\\n'\n",
      " 'from sklearn.datasets import load_breast_cancer\\n'\n",
      " 'from sklearn.model_selection import train_test_split\\n'\n",
      " 'from sklearn.preprocessing import StandardScaler\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¡œë“œ\\n'\n",
      " 'data = load_breast_cancer()\\n'\n",
      " 'X = data.data\\n'\n",
      " 'y = data.target\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¶„í• \\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# ë°ì´í„° ìŠ¤ì¼€ì¼ë§\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bsklearn.datasets.load_breast_cancer: ìœ ë°©ì•” ë°ì´í„°ì…‹ ë¡œë“œreturn_X_y=False: ë°ì´í„°ì™€ '\n",
      " 'íƒ€ê²Ÿì„ í•¨ê»˜ ë°˜í™˜í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ Falseì…ë‹ˆë‹¤._X_y=False: ë°ì´í„°ì™€ íƒ€ê²Ÿì„ í•¨ê»˜ ë°˜í™˜í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ '\n",
      " 'Falseì…ë‹ˆë‹¤.\\ufeff\\u200bsklearn.model_selection.train_test_split: ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸/ '\n",
      " 'í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„í• test_size=0.2: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë¹„ìœ¨ì„ 0.2ë¡œ ì„¤ì •í•©ë‹ˆë‹¤._size=0.2: í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ë¹„ìœ¨ì„ 0.2ë¡œ '\n",
      " 'ì„¤ì •í•©ë‹ˆë‹¤.\\ufeff\\u200brandom_state=42: ëœë¤ ì‹œë“œ ê°’ìœ¼ë¡œ, ë°ì´í„° ë¶„í• ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ '\n",
      " 'ì‚¬ìš©ë©ë‹ˆë‹¤._state=42: ëœë¤ ì‹œë“œ ê°’ìœ¼ë¡œ, ë°ì´í„° ë¶„í• ì˜ ì¬í˜„ì„±ì„ ìœ„í•´ '\n",
      " 'ì‚¬ìš©ë©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.preprocessing.StandardScaler: ë°ì´í„°ì˜ í‰ê· ì„ 0, ë¶„ì‚°ì„ 1ë¡œ '\n",
      " 'ìŠ¤ì¼€ì¼ë§fit_transform(X_train): í›ˆë ¨ ì„¸íŠ¸ë¥¼ ìŠ¤ì¼€ì¼ë§í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤._transform(X_train): í›ˆë ¨ ì„¸íŠ¸ë¥¼ '\n",
      " 'ìŠ¤ì¼€ì¼ë§í•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200btransform(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ ë³€í™˜í•©ë‹ˆë‹¤.(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¥¼ '\n",
      " 'ë³€í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200b ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ {5px}ëª¨ë¸ í•™ìŠµ \\ufeff\\u200bPythonë³µì‚¬from '\n",
      " 'sklearn.svm import SVC\\n'\n",
      " 'from sklearn.metrics import accuracy_score, classification_report, '\n",
      " 'confusion_matrix\\n'\n",
      " '\\n'\n",
      " '# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# ì˜ˆì¸¡\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# í‰ê°€\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bsklearn.svm.SVC: ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  ë¶„ë¥˜ ëª¨ë¸ ìƒì„±kernel=â€™linearâ€™: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ SVMì„ '\n",
      " 'í•™ìŠµí•©ë‹ˆë‹¤.=â€™linearâ€™: ì„ í˜• ì»¤ë„ì„ ì‚¬ìš©í•˜ì—¬ SVMì„ í•™ìŠµí•©ë‹ˆë‹¤.\\ufeff\\u200bfit(X_train, y_train): '\n",
      " 'ëª¨ë¸ì„ í›ˆë ¨ ì„¸íŠ¸ì— ë§ì¶”ì–´ í•™ìŠµì‹œí‚µë‹ˆë‹¤(X_train, y_train): ëª¨ë¸ì„ í›ˆë ¨ ì„¸íŠ¸ì— ë§ì¶”ì–´ '\n",
      " 'í•™ìŠµì‹œí‚µë‹ˆë‹¤\\ufeff\\u200bpredict(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.(X_test): í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì— ëŒ€í•´ '\n",
      " 'ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.accuracy_score: ì •í™•ë„ '\n",
      " 'ê³„ì‚°accuracy_score(y_test, y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤._score(y_test, '\n",
      " 'y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ë¥¼ '\n",
      " 'ë°˜í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.classification_report: ë¶„ë¥˜ ë³´ê³ ì„œ '\n",
      " 'ìƒì„±classification_report(y_test, y_pred): ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ '\n",
      " 'ì¶œë ¥í•©ë‹ˆë‹¤._report(y_test, y_pred): ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ë“±ì˜ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ ë³´ê³ ì„œë¥¼ '\n",
      " 'ì¶œë ¥í•©ë‹ˆë‹¤.\\ufeff\\u200bsklearn.metrics.confusion_matrix: í˜¼ë™ í–‰ë ¬ '\n",
      " 'ìƒì„±confusion_matrix(y_test, y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ í˜¼ë™ í–‰ë ¬ì„ ë°˜í™˜í•©ë‹ˆë‹¤._matrix(y_test, '\n",
      " 'y_pred): ì‹¤ì œ ê°’ê³¼ ì˜ˆì¸¡ ê°’ì˜ í˜¼ë™ í–‰ë ¬ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\\ufeff\\u200b2) íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬íƒ€ì´íƒ€ë‹‰ '\n",
      " 'ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ {5px}íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ \\ufeff\\u200bPythonë³µì‚¬import seaborn as '\n",
      " 'sns\\n'\n",
      " '\\n'\n",
      " '# ë°ì´í„° ë¡œë“œ\\n'\n",
      " \"titanic = sns.load_dataset('titanic')\\n\"\n",
      " '# í•„ìš”í•œ ì—´ ì„ íƒ ë° ê²°ì¸¡ê°’ ì²˜ë¦¬\\n'\n",
      " \"titanic = titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', \"\n",
      " \"'fare', 'embarked']].dropna()\\n\"\n",
      " '# ì„±ë³„ê³¼ íƒ‘ìŠ¹í•œ ê³³ ì¸ì½”ë”©\\n'\n",
      " \"titanic['sex'] = titanic['sex'].map({'male': 0, 'female': 1})\\n\"\n",
      " \"titanic['embarked'] = titanic['embarked'].map({'C': 0, 'Q': 1, 'S': 2})\\n\"\n",
      " '# íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\\n'\n",
      " \"X = titanic.drop('survived', axis=1)\\n\"\n",
      " \"y = titanic['survived']\\n\"\n",
      " '# ë°ì´í„° ë¶„í• \\n'\n",
      " 'X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, '\n",
      " 'random_state=42)\\n'\n",
      " '# ë°ì´í„° ìŠ¤ì¼€ì¼ë§\\n'\n",
      " 'scaler = StandardScaler()\\n'\n",
      " 'X_train = scaler.fit_transform(X_train)\\n'\n",
      " 'X_test = scaler.transform(X_test)\\n'\n",
      " '\\u200bseaborn.load_dataset: seabornì˜ ë‚´ì¥ ë°ì´í„°ì…‹ ë¡œë“œâ€™titanicâ€™: íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ '\n",
      " 'ë¡œë“œí•©ë‹ˆë‹¤.â€™titanicâ€™: íƒ€ì´íƒ€ë‹‰ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤.\\ufeff\\u200b pandas.DataFrame.dropna: ê²°ì¸¡ê°’ì´ '\n",
      " 'ìˆëŠ” í–‰ ì œê±°pandas.DataFrame.map: ë°ì´í„° ê°’ì„ ë‹¤ë¥¸ ê°’ìœ¼ë¡œ ë§¤í•‘â€™maleâ€™: 0, â€™femaleâ€™: 1: ì„±ë³„ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.: ì„±ë³„ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.}â€™maleâ€™: 0, â€™femaleâ€™: 1: ì„±ë³„ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.\\ufeff\\u200bâ€™Câ€™: 0, â€™Qâ€™: 1, â€™Sâ€™: 2: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ '\n",
      " 'ë§¤í•‘í•©ë‹ˆë‹¤.}â€™Câ€™: 0, â€™Qâ€™: 1, â€™Sâ€™: 2: íƒ‘ìŠ¹í•œ ê³³ì„ ìˆ«ìë¡œ ë§¤í•‘í•©ë‹ˆë‹¤.\\ufeff\\u200b ëª¨ë¸ í•™ìŠµëª¨ë¸ í•™ìŠµ '\n",
      " '{5px}ëª¨ë¸ í•™ìŠµ \\ufeff\\u200bPythonë³µì‚¬# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\\n'\n",
      " \"model = SVC(kernel='linear')\\n\"\n",
      " 'model.fit(X_train, y_train)\\n'\n",
      " '# ì˜ˆì¸¡\\n'\n",
      " 'y_pred = model.predict(X_test)\\n'\n",
      " '# í‰ê°€\\n'\n",
      " 'print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\\n'\n",
      " 'print(f\"Classification Report:\")\\n'\n",
      " 'print(f\"Confusion Matrix:\")\\n'\n",
      " '\\u200bCopyright â“’ TeamSparta All rights reserved.')\n"
     ]
    }
   ],
   "source": [
    "# ê²°ê³¼ ì¶œë ¥\n",
    "pprint(txt_list[9])  # ë‘ ë²ˆì§¸ URLì˜ í…ìŠ¤íŠ¸ ë‚´ìš© ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²­í¬ë¡œ ë‚˜ëˆ ì§„ í›„, ì²­í¬ì˜ ê°œìˆ˜: 421\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "# 1. ë¡œë“œëœ ë¬¸ì„œ ì „ì²˜ë¦¬(ì²­í‚¹)\n",
    "docs = ''.join(txt_list)\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "str_splits = text_splitter.split_text(docs)\n",
    "\n",
    "# 2. ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜\n",
    "doc_splits = [Document(page_content=str) for str in str_splits]\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=doc_splits, embedding=OpenAIEmbeddings())\n",
    "print(f\"ì²­í¬ë¡œ ë‚˜ëˆ ì§„ í›„, ì²­í¬ì˜ ê°œìˆ˜: {len(doc_splits)}\")\n",
    "\n",
    "# # ìƒìœ„ 10ê°œì˜ ì²­í¬ ì¶œë ¥\n",
    "# print(\"Top 10 chunks:\")\n",
    "# for i, chunk in enumerate(doc_splits[:10], 1):\n",
    "#     pprint(f\"\\nChunk {i}:\\n{chunk.page_content}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"\"\"\n",
    "    ë‹¹ì‹ ì€ AI ê°•ì‚¬ì…ë‹ˆë‹¤. ì•„ë˜ contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•˜ë‚˜ì˜ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ ê¸°ë‹¤ë¦¬ì„¸ìš”.\n",
    "    í€´ì¦ˆëŠ” ë³´ê¸°ê°€ ìˆëŠ” ê°ê´€ì‹ ë˜ëŠ” O,X í˜•íƒœë¡œ ì¶œì œí•´ì£¼ì„¸ìš”. (ì£¼ë¡œ ì½”ë“œ ë‚´ìš©ê³¼ ê´€ë ¨ëœ ë¬¸ì œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.)\n",
    "    ì´í›„, ì‚¬ìš©ìì˜ ëŒ€ë‹µì„ í™•ì¸í•˜ê³  ì•„ë˜ í˜•ì‹ì„ ë°”íƒ•ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”:\n",
    "    - ì •ë‹µ ì—¬ë¶€: \"Në²ˆ\" ë˜ëŠ” \"ì˜ˆ/ì•„ë‹ˆì˜¤\"\n",
    "    - ì¶”ê°€ ì„¤ëª…: (ì •ë‹µê³¼ ê´€ë ¨ëœ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•˜ì„¸ìš”)\n",
    "    \n",
    "    Context: {context}\n",
    "    \"\"\")])\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "        {\"context\": retriever | format_docs}\n",
    "        | prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Generated Quiz:\n",
      "í€´ì¦ˆ: íšŒê·€ ëª¨ë¸ì— ëŒ€í•œ ë‹¤ìŒ ì„¤ëª… ì¤‘ ì˜¬ë°”ë¥¸ ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "1. íšŒê·€ ëª¨ë¸ì€ ì£¼ë¡œ ì´ì‚°ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n",
      "2. íšŒê·€ ëª¨ë¸ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n",
      "3. íšŒê·€ ëª¨ë¸ì€ ë¶„ë¥˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n",
      "4. íšŒê·€ ëª¨ë¸ì€ ë°ì´í„°ì˜ êµ°ì§‘ì„ ì°¾ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n",
      "\n",
      "ì •ë‹µì„ ì„ íƒí•´ ì£¼ì„¸ìš” (1, 2, 3, 4 ì¤‘ í•˜ë‚˜).\n",
      "2\n",
      "Feedback:\n",
      "AIMessage(content='ì •ë‹µ: 2\\n\\ní”¼ë“œë°±: ì„ íƒí•˜ì‹  2ë²ˆ \"íšŒê·€ ëª¨ë¸ì€ ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\"ëŠ” ì˜¬ë°”ë¥¸ ì„¤ëª…ì…ë‹ˆë‹¤. íšŒê·€ ë¶„ì„ì€ ì£¼ë¡œ ì—°ì†ì ì¸ ëª©í‘œ ë³€ìˆ˜ë¥¼ ì˜ˆì¸¡í•˜ëŠ” ë° ì‚¬ìš©ë˜ë©°, ì˜ˆë¥¼ ë“¤ì–´ ì£¼íƒ ê°€ê²©, ê¸°ì˜¨, íŒë§¤ëŸ‰ ë“±ì˜ ì˜ˆì¸¡ì— í™œìš©ë©ë‹ˆë‹¤. \\n\\n1ë²ˆì€ ì˜ëª»ëœ ì„¤ëª…ìœ¼ë¡œ, íšŒê·€ ëª¨ë¸ì€ ì´ì‚°ì ì¸ ê°’(ì˜ˆ: ë¶„ë¥˜ ë¬¸ì œ)ì— ëŒ€í•œ ì˜ˆì¸¡ì—ëŠ” ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \\n3ë²ˆê³¼ 4ë²ˆë„ ì˜ëª»ëœ ì„¤ëª…ì…ë‹ˆë‹¤. 3ë²ˆì€ íšŒê·€ ëª¨ë¸ì´ ì•„ë‹Œ ë¶„ë¥˜ ëª¨ë¸ì˜ ì˜ì—­ì´ë©°, 4ë²ˆì€ êµ°ì§‘í™”(clustering) ë¬¸ì œì— í•´ë‹¹í•©ë‹ˆë‹¤.\\n\\në”°ë¼ì„œ íšŒê·€ ëª¨ë¸ì— ëŒ€í•œ ì„¤ëª…ìœ¼ë¡œëŠ” 2ë²ˆì´ ì •í™•í•©ë‹ˆë‹¤. ì˜ í•˜ì…¨ìŠµë‹ˆë‹¤!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 180, 'prompt_tokens': 173, 'total_tokens': 353, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-45c82104-0870-448e-9213-08227a81f044-0', usage_metadata={'input_tokens': 173, 'output_tokens': 180, 'total_tokens': 353, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Generated Quiz:\n",
      "í€´ì¦ˆ: SVM(Support Vector Machine) ì•Œê³ ë¦¬ì¦˜ì˜ ì£¼ëœ ëª©ì ì€ ë¬´ì—‡ì¸ê°€ìš”?\n",
      "\n",
      "1. ë°ì´í„°ì˜ í´ëŸ¬ìŠ¤í„°ë§\n",
      "2. ë°ì´í„°ì˜ ë¶„ë¥˜\n",
      "3. ë°ì´í„°ì˜ íšŒê·€ ë¶„ì„\n",
      "4. ë°ì´í„°ì˜ ì°¨ì› ì¶•ì†Œ\n",
      "\n",
      "ì •ë‹µì„ ì„ íƒí•´ì£¼ì„¸ìš”. (1, 2, 3, 4 ì¤‘ í•˜ë‚˜)\n",
      "2\n",
      "Feedback:\n",
      "AIMessage(content='ì •ë‹µ: 2\\n\\ní”¼ë“œë°±: ì„ íƒí•˜ì‹  2ë²ˆ \"ë°ì´í„°ì˜ ë¶„ë¥˜\"ëŠ” SVM(Support Vector Machine) ì•Œê³ ë¦¬ì¦˜ì˜ ì£¼ëœ ëª©ì ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ë‹µë³€ì…ë‹ˆë‹¤. SVMì€ ì£¼ë¡œ ë‘ ê°œ ì´ìƒì˜ í´ë˜ìŠ¤ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. \\n\\n1ë²ˆ \"ë°ì´í„°ì˜ í´ëŸ¬ìŠ¤í„°ë§\"ì€ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì— í•´ë‹¹í•˜ë©°, SVMì˜ ì£¼ëœ ëª©ì ê³¼ëŠ” ë‹¤ë¦…ë‹ˆë‹¤. \\n3ë²ˆ \"ë°ì´í„°ì˜ íšŒê·€ ë¶„ì„\"ì€ SVMì„ íšŒê·€ ë¬¸ì œì— ì ìš©í•  ìˆ˜ ìˆì§€ë§Œ, SVMì˜ ê¸°ë³¸ì ì¸ ëª©ì ì€ ë¶„ë¥˜ì…ë‹ˆë‹¤. \\n4ë²ˆ \"ë°ì´í„°ì˜ ì°¨ì› ì¶•ì†Œ\"ëŠ” ì£¼ë¡œ PCA(ì£¼ì„±ë¶„ ë¶„ì„)ì™€ ê°™ì€ ë‹¤ë¥¸ ê¸°ë²•ì— í•´ë‹¹í•©ë‹ˆë‹¤.\\n\\në”°ë¼ì„œ SVMì˜ ì£¼ëœ ëª©ì ì€ 2ë²ˆ, ì¦‰ ë°ì´í„°ì˜ ë¶„ë¥˜ì…ë‹ˆë‹¤. ì˜ í•˜ì…¨ìŠµë‹ˆë‹¤!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 674, 'total_tokens': 876, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_3de1288069', 'finish_reason': 'stop', 'logprobs': None}, id='run-011a3e65-4ba5-48a2-b090-537f6a7a222a-0', usage_metadata={'input_tokens': 674, 'output_tokens': 202, 'total_tokens': 876, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "\n",
      "Generated Quiz:\n",
      "í€´ì¦ˆ: ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ 'í•™ìŠµ'ì´ë€ ë¬´ì—‡ì„ ì˜ë¯¸í• ê¹Œìš”? ë‹¤ìŒ ì¤‘ ì˜¬ë°”ë¥¸ ì„¤ëª…ì„ ì„ íƒí•˜ì„¸ìš”.\n",
      "\n",
      "1. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ì£¼ì–´ì§„ ë°ì´í„°ë¥¼ í†µí•´ íŒ¨í„´ì„ ì¸ì‹í•˜ê³ , ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n",
      "2. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ë¬´ì‘ìœ„ë¡œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n",
      "3. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ë‹¨ìˆœíˆ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n",
      "4. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì´ ëª¨ë“  ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì´ë‹¤.\n",
      "\n",
      "ì •ë‹µì„ ì„ íƒí•´ ì£¼ì„¸ìš”! (1, 2, 3, 4 ì¤‘ ë²ˆí˜¸ë¡œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.)\n",
      "1\n",
      "Feedback:\n",
      "AIMessage(content='ì •ë‹µ: 2\\n\\ní”¼ë“œë°±: ì„ íƒí•˜ì‹  2ë²ˆ \"ë°ì´í„°ì˜ ë¶„ë¥˜\"ëŠ” SVM(Support Vector Machine) ì•Œê³ ë¦¬ì¦˜ì˜ ì£¼ëœ ëª©ì ì— ëŒ€í•œ ì˜¬ë°”ë¥¸ ë‹µë³€ì…ë‹ˆë‹¤. SVMì€ ì£¼ë¡œ ë‘ ê°œ ì´ìƒì˜ í´ë˜ìŠ¤ë¡œ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ê°•ë ¥í•œ ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\\n\\n1ë²ˆ \"ë°ì´í„°ì˜ í´ëŸ¬ìŠ¤í„°ë§\"ì€ êµ°ì§‘í™” ì•Œê³ ë¦¬ì¦˜ì— í•´ë‹¹í•˜ë©°, SVMì˜ ì£¼ëœ ëª©ì ê³¼ëŠ” ë‹¤ë¦…ë‹ˆë‹¤. 3ë²ˆ \"ë°ì´í„°ì˜ íšŒê·€ ë¶„ì„\"ì€ SVMì„ íšŒê·€ ë¬¸ì œì— ì ìš©í•  ìˆ˜ ìˆì§€ë§Œ, SVMì˜ ê¸°ë³¸ì ì¸ ëª©ì ì€ ë¶„ë¥˜ì…ë‹ˆë‹¤. 4ë²ˆ \"ë°ì´í„°ì˜ ì°¨ì› ì¶•ì†Œ\"ëŠ” ì£¼ë¡œ PCA(ì£¼ì„±ë¶„ ë¶„ì„)ì™€ ê°™ì€ ë‹¤ë¥¸ ê¸°ë²•ì— í•´ë‹¹í•©ë‹ˆë‹¤.\\n\\në”°ë¼ì„œ SVMì˜ ì£¼ëœ ëª©ì ì€ 2ë²ˆ, ì¦‰ ë°ì´í„°ì˜ ë¶„ë¥˜ì…ë‹ˆë‹¤. ì˜ í•˜ì…¨ìŠµë‹ˆë‹¤!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 1268, 'total_tokens': 1469, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0705bf87c0', 'finish_reason': 'stop', 'logprobs': None}, id='run-22b7c23a-e236-41da-be2f-a7048f851e1a-0', usage_metadata={'input_tokens': 1268, 'output_tokens': 201, 'total_tokens': 1469, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
      "ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# í´ë” ì´ë¦„\n",
    "folder_name = \"previous_conversation\"\n",
    "\n",
    "# í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# íŒŒì¼ ì´ë¦„ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")  # \"20241126_153045\" í˜•ì‹\n",
    "file_name = f\"conversation_log_{timestamp}.txt\"\n",
    "file_path = os.path.join(folder_name, file_name)\n",
    "\n",
    "# ëŒ€í™” ì§„í–‰\n",
    "while True:\n",
    "    query = input(\"ì–´ë–¤ í€´ì¦ˆë¥¼ ë‚¼ê¹Œìš”?: \")\n",
    "\n",
    "    if query.strip().lower() == \"exit\":\n",
    "        print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "    \n",
    "    # 1. í€´ì¦ˆ ìƒì„±\n",
    "    quiz = rag_chain.invoke(query)\n",
    "    print(\"-\" * 50)\n",
    "    print(\"Generated Quiz:\")\n",
    "    print(quiz)\n",
    "    \n",
    "    # 2. ì‚¬ìš©ì ë‹µë³€ ìˆ˜ì§‘\n",
    "    user_answer = input(\"ë‹µë³€ì„ ì…ë ¥í•˜ì„¸ìš”: \")\n",
    "    if user_answer.strip().lower() == \"exit\":\n",
    "        print(\"ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "        break\n",
    "    print(user_answer)\n",
    "\n",
    "    # ëŒ€í™” ë‚´ìš© ë¶ˆëŸ¬ì˜¤ê¸° (ì´ì „ ëŒ€í™” ë‚´ìš©)\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            previous_conversation = f.read()\n",
    "    else:\n",
    "        previous_conversation = \"\"  # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ë¡œ ì‹œì‘\n",
    "    \n",
    "    # ì‚¬ìš©ì ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„± ì „ì— ì´ì „ ëŒ€í™” ë‚´ìš© í™•ì¸\n",
    "    # print(f\"Previous conversation: {previous_conversation}\")\n",
    "    \n",
    "    # 3. ì‚¬ìš©ì ë‹µë³€ì— ëŒ€í•œ í”¼ë“œë°± ìƒì„±\n",
    "    feedback_prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", f\"\"\"\n",
    "    AI ê°•ì‚¬ë¡œì„œ ë‹¤ìŒ í€´ì¦ˆì˜ ì •ë‹µ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í”¼ë“œë°±ì„ ì œê³µí•˜ì„¸ìš”.\n",
    "    í€´ì¦ˆ: {{quiz}}\n",
    "    ë‹µë³€: {{answer}}\n",
    "    ëŒ€í™” ê¸°ë¡: {{previous_conversation}}\n",
    "    ê±°ì ˆ ì‚¬ìœ : {{refusal}}\n",
    "    \"\"\")\n",
    "    ])\n",
    "\n",
    "    # í”¼ë“œë°± ìƒì„± - í‚¤ì›Œë“œ ì¸ìˆ˜ë¡œ ì „ë‹¬\n",
    "    feedback_data = feedback_prompt.format(\n",
    "        quiz=quiz,\n",
    "        answer=user_answer,\n",
    "        previous_conversation=previous_conversation,\n",
    "        refusal=\"None\"\n",
    "    )\n",
    "\n",
    "    # í”¼ë“œë°± ì²´ì¸ í˜¸ì¶œ\n",
    "    feedback = llm.invoke(feedback_data)   # LLMì„ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ í”¼ë“œë°± ìƒì„±\n",
    "    \n",
    "    print(\"Feedback:\")\n",
    "    pprint(feedback)\n",
    "    \n",
    "    # ëŒ€í™” ë‚´ìš© ì €ì¥(íŒŒì¼ì— ê¸°ë¡)\n",
    "    with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Quiz: {quiz}\\n\")\n",
    "        f.write(f\"User Answer: {user_answer}\\n\")\n",
    "        f.write(f\"Feedback: {feedback}\\n\")\n",
    "        f.write(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_boot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
